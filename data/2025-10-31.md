<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 14]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Critical Roadmap to Driver Authentication via CAN Bus: Dataset Review, Introduction of the Kidmose CANid Dataset (KCID), and Proof of Concept](https://arxiv.org/abs/2510.25856)
*Brooke Elizabeth Kidmose,Andreas Brasen Kidmose,Cliff C. Zou*

Main category: cs.CR

TL;DR: 论文总结了现有公开驾驶员指纹识别数据集的优缺点，介绍了新的Kidmose CANid数据集（KCID），该数据集包含原始CAN总线数据、驾驶员人口统计信息和多样化驾驶场景。作者提出了一个基于CAN总线的驾驶员认证防盗框架，并验证了其可行性，同时探索了KCID在多个领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统车辆防盗技术存在漏洞，罪犯可能通过CAN总线漏洞绕过认证。而现有公开驾驶员指纹数据集存在严重局限性，无法支撑高效认证技术研发。需要更完善的数据集和系统以提高车辆防盗安全性。

Method: 1）综述现有数据集优缺点；2）提出新数据集KCID，包含16名驾驶员在4种车辆上的原始CAN总线数据，涵盖日常驾驶和固定路线场景；3）建立驾驶员认证防盗框架，并在树莓派上实现原型系统；4）通过实车道路试验验证可行性。

Result: 成功创建了更全面的KCID数据集，填补了现有数据集的不足。原型系统在实车环境下证明了基于CAN总线的驾驶员认证防盗系统具有实际可行性。实验数据显示系统能有效区分不同驾驶员行为模式。

Conclusion: KCID数据集为驾驶员认证研究提供了重要基础资源。基于CAN总线的实时认证防盗系统可部署性强，且数据集还能扩展应用于驾驶行为分析、机械故障检测、青少年驾驶监控等多元场景。

Abstract: Modern vehicles remain vulnerable to unauthorized use and theft despite
traditional security measures including immobilizers and keyless entry systems.
Criminals exploit vulnerabilities in Controller Area Network (CAN) bus systems
to bypass authentication mechanisms, while social media trends have expanded
auto theft to include recreational joyriding by underage drivers. Driver
authentication via CAN bus data offers a promising additional layer of
defense-in-depth protection, but existing open-access driver fingerprinting
datasets suffer from critical limitations including reliance on decoded
diagnostic data rather than raw CAN traffic, artificial fixed-route
experimental designs, insufficient sampling rates, and lack of demographic
information.
  This paper provides a comprehensive review of existing open-access driver
fingerprinting datasets, analyzing their strengths and limitations to guide
practitioners in dataset selection. We introduce the Kidmose CANid Dataset
(KCID), which addresses these fundamental shortcomings by providing raw CAN bus
data from 16 drivers across four vehicles, including essential demographic
information and both daily driving and controlled fixed-route data. Beyond
dataset contributions, we present a driver authentication anti-theft framework
and implement a proof-of-concept prototype on a single-board computer. Through
live road trials with an unaltered passenger vehicle, we demonstrate the
practical feasibility of CAN bus-based driver authentication anti-theft
systems. Finally, we explore diverse applications of KCID beyond driver
authentication, including driver profiling for insurance and safety
assessments, mechanical anomaly detection, young driver monitoring, and
impaired driving detection. This work provides researchers with both the data
and methodological foundation necessary to develop robust, deployable driver
authentication systems...

</details>


### [2] [Foundations of Fiat-Denominated Loans Collateralized by Cryptocurrencies](https://arxiv.org/abs/2510.25878)
*Pavel Hubáček,Jan Václavek,Michelle Yeo*

Main category: cs.CR

TL;DR: 研究提出一种有限托管协议，支持法币贷款以比特币等加密货币作为抵押品，依赖可信仲裁进行设计并辅以博弈论分析。


<details>
  <summary>Details</summary>
Motivation: 随着加密货币作为金融资产的重要性上升，需要将其从投机对象转变为更接近标准金融工具（如贷款），但现有方案存在托管风险。

Method: 设计了基于可信仲裁的有限托管协议，通过多方协同控制和自动化清算机制降低托管风险，并进行博弈论分析以验证协议公平性。

Result: 协议在保留加密资产所有权的同时实现法币借贷功能，博弈论证明可抑制恶意行为，但需依赖可信第三方仲裁者。

Conclusion: 该框架首次解决加密货币抵押贷款的安全问题，未来研究方向包括优化仲裁机制与支持跨链资产。

Abstract: The rising importance of cryptocurrencies as financial assets pushed their
applicability from an object of speculation closer to standard financial
instruments such as loans. In this work, we initiate the study of secure
protocols that enable fiat-denominated loans collateralized by cryptocurrencies
such as Bitcoin. We provide limited-custodial protocols for such loans relying
only on trusted arbitration and provide their game-theoretical analysis. We
also highlight various interesting directions for future research.

</details>


### [3] [FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X](https://arxiv.org/abs/2510.25932)
*Soufiane Essahli,Oussama Sarsar,Imane Fouad,Anas Motii,Ahmed Bentajer*

Main category: cs.CR

TL;DR: 本文介绍了一种完全在客户端运行的浏览器扩展程序FakeZero，旨在在用户浏览社交媒体平台时实时标记不可靠的信息，通过高效、隐私友好的方法实现假新闻检测。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上信息迅速传播加剧了虚假信息的扩散，威胁公共讨论。

Method: 开发跨平台浏览器扩展，全部计算任务（包括DOM抓取、令牌化、Transformer推理和UI渲染）在本地通过Chromium消息API运行，无需将数据发送到外部。模型分三阶段训练：基准调优、使用焦点损失的领域自适应训练、对抗增强及训练后量化。

Result: 在239,000条帖子的数据集上测试，DistilBERT-Quant模型（67.6MB）达到97.1%宏F1分数和97.4%准确率，AUROC为0.996，中位延迟103毫秒；简化版TinyBERT-Quant（14.7MB）保持95.7%宏F1分数和96.1%准确率，延迟降至40毫秒。

Conclusion: 在有限的资源条件下，进行高质量的假新闻检测是可行的。该工具能够为政策制定者提供可靠线索，并有可能在获取用户同意后成为研究人员收集大规模假新闻数据集的手段。

Abstract: Social platforms distribute information at unprecedented speed, which in turn
accelerates the spread of misinformation and threatens public discourse. We
present FakeZero, a fully client-side, cross-platform browser extension that
flags unreliable posts on Facebook and X (formerly Twitter) while the user
scrolls. All computation, DOM scraping, tokenisation, Transformer inference,
and UI rendering run locally through the Chromium messaging API, so no personal
data leaves the device.FakeZero employs a three-stage training curriculum:
baseline fine-tuning and domain-adaptive training enhanced with focal loss,
adversarial augmentation, and post-training quantisation. Evaluated on a
dataset of 239,000 posts, the DistilBERT-Quant model (67.6 MB) reaches 97.1%
macro-F1, 97.4% accuracy, and an AUROC of 0.996, with a median latency of
approximately 103 ms on a commodity laptop. A memory-efficient TinyBERT-Quant
variant retains 95.7% macro-F1 and 96.1% accuracy while shrinking the model to
14.7 MB and lowering latency to approximately 40 ms, showing that high-quality
fake-news detection is feasible under tight resource budgets with only modest
performance loss.By providing inline credibility cues, the extension can serve
as a valuable tool for policymakers seeking to curb the spread of
misinformation across social networks. With user consent, FakeZero also opens
the door for researchers to collect large-scale datasets of fake news in the
wild, enabling deeper analysis and the development of more robust detection
techniques.

</details>


### [4] [SoK: Honeypots & LLMs, More Than the Sum of Their Parts?](https://arxiv.org/abs/2510.25939)
*Robert A. Bridges,Thomas R. Mitchell,Mauricio Muñoz,Ted Henriksson*

Main category: cs.CR

TL;DR: 本文对基于LLM的蜜罐研究进行了首个系统综述，填补了该领域缺乏统一理解的空白。从蜜罐检测分类、架构评估和日志分析三个关键角度总结现状，并提出了自主进化式蜜罐的未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽探索了LLM用于解决蜜罐高仿真与低风险的固有矛盾，但进展零散且缺乏系统性总结。本文旨在提炼核心模式、挑战与评估方法，推动该领域发展。

Method: 通过对三类研究领域的系统化归纳：1) 建立LLM蜜罐检测向量的分类体系；2) 梳理现有LLM蜜罐的典型架构与评估趋势；3) 绘制蜜罐日志分析从数据简化到情报自动生成的演进路径。

Result: 提炼出关键研究范式及技术架构，揭示当前技术集中于交互仿真层面。强调LLM蜜罐的核心是构建‘以高智能应对高智能’的主动防御体系，而非简单替代人工脚本。

Conclusion: 未来研究应致力于开发能够自主演化的欺骗系统，以对抗自动化攻击。本综述为这一新兴领域提供统一认知框架，并指明对抗性自适应是核心突破方向。

Abstract: The advent of Large Language Models (LLMs) promised to resolve the
long-standing paradox in honeypot design: achieving high-fidelity deception
with low operational risk. However, despite a flurry of research since late
2022, progress has been incremental, and the field lacks a cohesive
understanding of the emerging architectural patterns, core challenges, and
evaluation paradigms. To fill this gap, this Systematization of Knowledge (SoK)
paper provides the first comprehensive overview of this new domain. We survey
and systematize three critical, intersecting research areas: first, we provide
a taxonomy of honeypot detection vectors, structuring the core problems that
LLM-based realism must solve; second, we synthesize the emerging literature on
LLM-honeypots, identifying a canonical architecture and key evaluation trends;
and third, we chart the evolutionary path of honeypot log analysis, from simple
data reduction to automated intelligence generation. We synthesize these
findings into a forward-looking research roadmap, arguing that the true
potential of this technology lies in creating autonomous, self-improving
deception systems to counter the emerging threat of intelligent, automated
attackers.

</details>


### [5] [WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows](https://arxiv.org/abs/2510.25960)
*Zeynep Yasemin Erdogan,Shishir Nagaraja,Chuadhry Mujeeb Ahmed,Ryan Shah*

Main category: cs.CR

TL;DR: 本文提出了一种利用声学侧信道分析（ASCA）的框架，通过捕捉机器人运动产生的声音来监测和验证机器人是否正确执行指令。该系统使用机器学习方法（包括SVM、DNN、RNN、CNN四种分类器），在实时行为与预期指令一致性验证上效果显著。


<details>
  <summary>Details</summary>
Motivation: 在敏感机器人环境中，需要低成本、无硬件改动的实时验证方案来确保指令正确执行。传统方法存在成本高或侵入性强的问题，而声学信号作为一种被动监测手段具有独特优势。

Method: 1. 基于机器人运动声学发射开发机器学习验证系统；2. 评估运动速度、方向及麦克风距离的影响；3. 使用SVM/DNN/RNN/CNN四类分类器对单动作和复合工作流（如抓取放置、包装）进行分类验证。

Result: 1. 单一动作在基线条件下验证准确率>80%；2. 复合工作流验证同样具备高置信度（最高达95.4%）；3. 距离7米内CNN模型保持>78%准确率，方向变化对RNN影响<4%。

Conclusion: 声学信号可成为敏感环境中实时被动验证机器人的有效手段，验证了ASCA在机器人操作监控领域的可行性。该系统无需硬件改造，为安全关键场景提供了新解决方案。

Abstract: In this paper, we present a framework that uses acoustic side- channel
analysis (ASCA) to monitor and verify whether a robot correctly executes its
intended commands. We develop and evaluate a machine-learning-based workflow
verification system that uses acoustic emissions generated by robotic
movements. The system can determine whether real-time behavior is consistent
with expected commands. The evaluation takes into account movement speed,
direction, and microphone distance. The results show that individual robot
movements can be validated with over 80% accuracy under baseline conditions
using four different classifiers: Support Vector Machine (SVM), Deep Neural
Network (DNN), Recurrent Neural Network (RNN), and Convolutional Neural Network
(CNN). Additionally, workflows such as pick-and-place and packing could be
identified with similarly high confidence. Our findings demonstrate that
acoustic signals can support real-time, low-cost, passive verification in
sensitive robotic environments without requiring hardware modifications.

</details>


### [6] [Message Recovery Attack in NTRU via Knapsack](https://arxiv.org/abs/2510.26003)
*Eirini Poimenidou,K. A. Draziotis*

Main category: cs.CR

TL;DR: 提出了针对NTRU-HPS变体的基于模块化背包问题的消息恢复攻击方法，仅需预知随机位置的部分消息和非零分量，即可在ε≈0.45时实现快速解密。


<details>
  <summary>Details</summary>
Motivation: 针对NTRU-HPS密码系统的安全性，探究在不掌握完整密钥信息的场景下，需要获取多少消息或临时向量的信息才能实现可行性恢复。

Method: 将消息解密问题转化为在特定格中寻找短向量问题求解模块化背包系统实例，利用FLATTER算法处理约45%预知随机系数。

Result: 普通桌面电脑可在数分钟内恢复完整消息，成功阈值处于ε≈0.45（即需预知消息与非零分量45%的系数）。

Conclusion: 证实NTRU-HPS系统当攻击者掌握近45%系数时可被有效破解，暴露该系统在部分信息泄露场景下的安全缺陷。

Abstract: In the present paper, we introduce a message-recovery attack based on the
Modular Knapsack Problem, applicable to all variants of the NTRU-HPS
cryptosystem. Assuming that a fraction $\epsilon$ of the coefficients of the
message ${\bf{m}}\in\{-1,0,1\}^N$ and of the nonce vector ${\bf
r}\in\{-1,0,1\}^N$ are known in advance at random positions, we reduce message
decryption to finding a short vector in a lattice that encodes an instance of a
modular knapsack system. This allows us to address a key question: how much
information about ${\bf m}$, or about the pair $({\bf m},{\bf r})$, is required
before recovery becomes feasible? A FLATTER reduction successfully recovers the
message, in practice when $\epsilon\approx 0.45$. Our implementation finds
${\bf m}$ within a few minutes on a commodity desktop.

</details>


### [7] [PEEL: A Poisoning-Exposing Encoding Theoretical Framework for Local Differential Privacy](https://arxiv.org/abs/2510.26102)
*Lisha Shuai,Jiuling Dong,Nan Zhang,Shaofeng Tan,Haokun Zhang,Zilong Song,Gaoya Dong,Xiaolong Yang*

Main category: cs.CR

TL;DR: 提出了一种名为PEEL的新型防御框架，用于对抗本地差分隐私（LDP）中的投毒攻击。PEEL通过重新编码数据来放大攻击痕迹，无需大量资源或领域先验知识，并保持LDP的无偏性和统计准确性。


<details>
  <summary>Details</summary>
Motivation: 本地差分隐私（LDP）在物联网（IoT）中广泛应用，但其易受投毒攻击。现有防御方法存在资源开销大或依赖领域先验知识的问题，难以实际部署。因此需要一个轻量级且无需先验的防御方案。

Method: 提出PEEL框架，作为非侵入式后处理模块。通过稀疏化、归一化和低秩投影对LDP扰动数据进行重新编码，利用LDP数据固有的结构一致性来放大并暴露投毒攻击（包括输出投毒和规则投毒）。

Result: 理论分析表明PEEL集成LDP后仍保持无偏性和统计准确性。实验评估显示，PEEL在投毒暴露准确率上优于四种现有防御方法，同时显著降低客户端计算成本，适合大规模IoT部署。

Conclusion: PEEL是一个高效且轻量的LDP投毒攻击防御框架，通过重新编码暴露攻击，具有高鲁棒性和实用性，尤其适用于资源受限的IoT环境。

Abstract: Local Differential Privacy (LDP) is a widely adopted privacy-protection model
in the Internet of Things (IoT) due to its lightweight, decentralized, and
scalable nature. However, it is vulnerable to poisoning attacks, and existing
defenses either incur prohibitive resource overheads or rely on domain-specific
prior knowledge, limiting their practical deployment. To address these
limitations, we propose PEEL, a Poisoning-Exposing Encoding theoretical
framework for LDP, which departs from resource- or prior-dependent
countermeasures and instead leverages the inherent structural consistency of
LDP-perturbed data. As a non-intrusive post-processing module, PEEL amplifies
stealthy poisoning effects by re-encoding LDP-perturbed data via
sparsification, normalization, and low-rank projection, thereby revealing both
output and rule poisoning attacks through structural inconsistencies in the
reconstructed space. Theoretical analysis proves that PEEL, integrated with
LDP, retains unbiasedness and statistical accuracy, while being robust to
expose both output and rule poisoning attacks. Moreover, evaluation results
show that LDP-integrated PEEL not only outperforms four state-of-the-art
defenses in terms of poisoning exposure accuracy but also significantly reduces
client-side computational costs, making it highly suitable for large-scale IoT
deployments.

</details>


### [8] [Security Vulnerabilities in AI-Generated Code: A Large-Scale Analysis of Public GitHub Repositories](https://arxiv.org/abs/2510.26103)
*Maximilian Schreiber,Pascal Tippe*

Main category: cs.CR

TL;DR: 本研究报告通过分析7703份来自ChatGPT、GitHub Copilot等AI工具的公共代码文件，发现87.9%的AI生成代码无已知漏洞，但存在语言性差异（如Python漏洞率更高）及工具差异（Copilot的Python安全密度更优）。研究还指出39%的AI代码用于文档生成，需关注其对可维护性的影响。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成代码工具在软件开发中的广泛集成，系统性评估其生成代码的安全性至关重要。现有研究多集中于小规模人工模拟场景，缺乏对真实场景下大规模开源项目的安全漏洞分析。

Method: 从公开GitHub仓库收集7703份明确标注由四大AI工具（ChatGPT占91.52%）生成的代码文件，使用CodeQL静态分析工具识别出4241个CWE漏洞实例，覆盖77种漏洞类型。按编程语言（Python/JavaScript/TypeScript）和工具分类统计漏洞分布。

Result: 1. 总体87.9%的AI生成代码无漏洞
2. Python漏洞率（16.18%-18.50%）显著高于JavaScript（8.66%-8.99%）和TypeScript（2.50%-7.14%）
3. GitHub Copilot在Python（每1739行代码1个CWE）和TypeScript安全密度表现最优，ChatGPT则在JavaScript更优
4. 39%的AI生成文件用于文档，影响软件可维护性

Conclusion: AI生成代码漏洞存在显著的语言和工具差异性，需开发语言针对性防护机制。文档生成作为主要应用场景的安全影响被低估，应建立上下文感知的安全实践标准。研究为负责任地集成AI代码提供了大规模实证依据。

Abstract: This paper presents a comprehensive empirical analysis of security
vulnerabilities in AI-generated code across public GitHub repositories. We
collected and analyzed 7,703 files explicitly attributed to four major AI
tools: ChatGPT (91.52\%), GitHub Copilot (7.50\%), Amazon CodeWhisperer
(0.52\%), and Tabnine (0.46\%). Using CodeQL static analysis, we identified
4,241 Common Weakness Enumeration (CWE) instances across 77 distinct
vulnerability types. Our findings reveal that while 87.9\% of AI-generated code
does not contain identifiable CWE-mapped vulnerabilities, significant patterns
emerge regarding language-specific vulnerabilities and tool performance. Python
consistently exhibited higher vulnerability rates (16.18\%-18.50\%) compared to
JavaScript (8.66\%-8.99\%) and TypeScript (2.50\%-7.14\%) across all tools. We
observed notable differences in security performance, with GitHub Copilot
achieving better security density for Python (1,739 LOC per CWE) and
TypeScript, while ChatGPT performed better for JavaScript. Additionally, we
discovered widespread use of AI tools for documentation generation (39\% of
collected files), an understudied application with implications for software
maintainability. These findings extend previous work with a significantly
larger dataset and provide valuable insights for developing language-specific
and context-aware security practices for the responsible integration of
AI-generated code into software development workflows.

</details>


### [9] [Who Moved My Transaction? Uncovering Post-Transaction Auditability Vulnerabilities in Modern Super Apps](https://arxiv.org/abs/2510.26210)
*Junlin Liu,Zhaomeng Deng,Ziming Wang,Mengyu Yao,Yifeng Cai,Yutao Hu,Ziqi Zhang,Yao Guo,Ding Li*

Main category: cs.CR

TL;DR: 论文研究了超级应用在交易后审计追踪的脆弱性，发现用户可轻易永久删除交易记录，隐藏未经授权或敏感活动。实证研究显示，6款超级应用中，5款删除交易记录时未使用强认证，仅1款要求生物特征验证。


<details>
  <summary>Details</summary>
Motivation: 当前超级应用的安全范式过度聚焦于交易前认证，忽略了交易后审计追踪的脆弱性。用户可删除交易记录以掩盖可疑活动，导致账户所有者无法察觉未授权交易。

Method: 使用6名志愿者对6款超级应用进行交叉评估，实证量化用户删除交易记录的难易程度及认证强度。

Result: 所有6款应用均允许删除交易记录，但其中5款（83%以上）未部署强认证机制；仅1款应用在删除时要求生物特征验证。

Conclusion: 主流超级应用普遍存在审计追踪安全缺陷，凸显移动安全领域的关键漏洞，亟需转向确保交易后审计完整性的新范式。

Abstract: Super apps are the cornerstones of modern digital life, embedding financial
transactions into nearly every aspect of daily routine. The prevailing security
paradigm for these platforms is overwhelmingly focused on pre-transaction
authentication, preventing unauthorized payments before they occur. We argue
that a critical vulnerability vector has been largely overlooked: the fragility
of post-transaction audit trails. We investigate the ease with which a user can
permanently erase their transaction history from an app's interface, thereby
concealing unauthorized or sensitive activities from the account owner. To
quantify this threat, we conducted an empirical study with 6 volunteers who
performed a cross-evaluation on six super apps. Our findings are alarming: all
six applications studied allow users to delete transaction records, yet a
staggering five out of six (83+\%) fail to protect these records with strong
authentication. Only one app in our study required biometric verification for
deletion. This study provides the first concrete evidence of this
near-ubiquitous vulnerability, demonstrating a critical gap in the current
mobile security landscape and underscoring the urgent need for a paradigm shift
towards ensuring post-transaction audit integrity.

</details>


### [10] [PVMark: Enabling Public Verifiability for LLM Watermarking Schemes](https://arxiv.org/abs/2510.26274)
*Haohua Duan,Liyao Xiang,Xin Zhang*

Main category: cs.CR

TL;DR: PVMark利用零知识证明（ZKP）技术，为大型语言模型（LLM）水印检测提供公开可验证性，解决了现有水印方案因依赖私钥导致的信任问题，同时不泄露任何密钥信息。


<details>
  <summary>Details</summary>
Motivation: 当前LLM水印方案依赖非公开的水印检测密钥，导致检测过程缺乏透明度。若公开密钥易遭移除攻击，而完全私密则无法公开验证，形成信任困境。

Method: 提出基于ZKP的插件PVMark，构建水印检测过程的零知识证明约束（包括映射、随机数生成、比较和求和），确保检测结果可被第三方验证且不泄露密钥。通过Python、Rust和Circom实现了三种水印方案、三种哈希函数和四种ZKP协议的组合验证。

Result: 实验证明PVMark能高效实现现有LLM水印方案的公开可验证性，且不影响水印性能（如准确性、检测速度），具备实际部署潜力。

Conclusion: PVMark通过ZKP技术首次解决了水印检测的公开验证问题，为LLM水印的实际应用扫除了信任障碍，未来可扩展至更多水印方案与协议。

Abstract: Watermarking schemes for large language models (LLMs) have been proposed to
identify the source of the generated text, mitigating the potential threats
emerged from model theft. However, current watermarking solutions hardly
resolve the trust issue: the non-public watermark detection cannot prove itself
faithfully conducting the detection. We observe that it is attributed to the
secret key mostly used in the watermark detection -- it cannot be public, or
the adversary may launch removal attacks provided the key; nor can it be
private, or the watermarking detection is opaque to the public. To resolve the
dilemma, we propose PVMark, a plugin based on zero-knowledge proof (ZKP),
enabling the watermark detection process to be publicly verifiable by third
parties without disclosing any secret key. PVMark hinges upon the proof of
`correct execution' of watermark detection on which a set of ZKP constraints
are built, including mapping, random number generation, comparison, and
summation. We implement multiple variants of PVMark in Python, Rust and Circom,
covering combinations of three watermarking schemes, three hash functions, and
four ZKP protocols, to show our approach effectively works under a variety of
circumstances. By experimental results, PVMark efficiently enables public
verifiability on the state-of-the-art LLM watermarking schemes yet without
compromising the watermarking performance, promising to be deployed in
practice.

</details>


### [11] [SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification](https://arxiv.org/abs/2510.26420)
*Yingjia Wang,Ting Qiao,Xing Liu,Chongzuo Li,Sixing Wu,Jianbin Li*

Main category: cs.CR

TL;DR: 本文提出了一种样本特定的干净标签后门水印方法（SSCL-BW），通过生成样本特定的水印以解决现有数据集所有权验证方法中的静态水印易被检测和移除的问题。该方法设计了一个复合损失函数确保水印的有效性、可靠性和视觉不可察觉性，并通过实验证明了其有效性和抗移除攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有后门水印方法存在局限性：毒标签水印因标签不一致易于检测，干净标签水印技术要求高且在高分辨率图像上易失效。两者均使用静态水印模式，易被检测和移除。因此，需要一种新型水印技术解决这些问题。

Method: 提出样本特定的干净标签后门水印（SSCL-BW）策略。训练基于U-Net的水印样本生成器，为每个样本生成独特水印。关键创新是设计包含三个部分的复合损失函数：目标样本损失确保水印有效性，非目标样本损失保证触发可靠性，感知相似性损失维持视觉不可察觉性。所有权验证采用黑盒测试检测预定义后门行为。

Result: 在基准数据集上的大量实验表明，该方法有效且对潜在的水印移除攻击具有鲁棒性。

Conclusion: SSCL-BW方法通过生成样本特定水印，克服了静态水印的漏洞，并以复合损失函数实现水印的可靠性和隐蔽性，为数据集版权保护提供有效解决方案。

Abstract: The rapid advancement of deep neural networks (DNNs) heavily relies on
large-scale, high-quality datasets. However, unauthorized commercial use of
these datasets severely violates the intellectual property rights of dataset
owners. Existing backdoor-based dataset ownership verification methods suffer
from inherent limitations: poison-label watermarks are easily detectable due to
label inconsistencies, while clean-label watermarks face high technical
complexity and failure on high-resolution images. Moreover, both approaches
employ static watermark patterns that are vulnerable to detection and removal.
To address these issues, this paper proposes a sample-specific clean-label
backdoor watermarking (i.e., SSCL-BW). By training a U-Net-based watermarked
sample generator, this method generates unique watermarks for each sample,
fundamentally overcoming the vulnerability of static watermark patterns. The
core innovation lies in designing a composite loss function with three
components: target sample loss ensures watermark effectiveness, non-target
sample loss guarantees trigger reliability, and perceptual similarity loss
maintains visual imperceptibility. During ownership verification, black-box
testing is employed to check whether suspicious models exhibit predefined
backdoor behaviors. Extensive experiments on benchmark datasets demonstrate the
effectiveness of the proposed method and its robustness against potential
watermark removal attacks.

</details>


### [12] [Interdependent Privacy in Smart Homes: Hunting for Bystanders in Privacy Policies](https://arxiv.org/abs/2510.26523)
*Shuaishuai Liu,Gergely Acs,Gergely Biczók*

Main category: cs.CR

TL;DR: 摘要分析了20种视频门铃和智能摄像头的隐私政策，重点关注这些设备对旁观者隐私的影响。研究发现，尽管部分厂商在隐私政策中提到旁观者，但主要依赖免责声明来转移责任，缺少对非用户隐私的有力保护。文章还通过实际案例说明问题严重性，并提出了政策与技术设计的改进建议。


<details>
  <summary>Details</summary>
Motivation: 智能家居设备（如视频门铃、安防摄像头）在普及过程中引发了对他人（邻居、访客、路人等）隐私的关注，即互依隐私问题。因相关数据保护法规缺失，且设备持有者常承担非专业数据控制角色，研究动机是验证厂商隐私政策是否因此存在监管空白。

Method: 本文采用聚焦分析：1）对20款视频门铃和智能摄像头产品进行隐私政策文本分析，重点提取涉及'旁观者隐私'的内容；2）结合现实案例说明设备如何实际影响第三方隐私；3）对照法律框架与技术可行性，评估政策与实际操作的差距。

Result: 研究发现：1）部分厂商虽承认旁观者存在，但仅以免责声明推卸责任（将收集非用户数据的道德责任转嫁到设备拥有者）；2）实际案例证明当前部署已对非用户造成隐私损害；3）厂商政策远滞后于法律要求与技术可实现的数据保护能力。

Conclusion: 建议厂商在隐私政策与系统设计中采取具体措施：改进政策语言以提升透明度，强化设备所有者与旁观者的知情控制权；通过技术手段（如匿名化）减少第三方隐私风险。强调解决该问题需政策、技术和责任分担的共同改进。

Abstract: Smart home devices such as video doorbells and security cameras are becoming
increasingly common in everyday life. While these devices offer convenience and
safety, they also raise new privacy concerns: how these devices affect others,
like neighbors, visitors, or people passing by. This issue is generally known
as interdependent privacy, where one person's actions (or inaction) may impact
the privacy of others, and, specifically, bystander privacy in the context of
smart homes. Given lax data protection regulations in terms of shared physical
spaces and amateur joint data controllers, we expect that the privacy policies
of smart home products reflect the missing regulatory incentives. This paper
presents a focused privacy policy analysis of 20 video doorbell and smart
camera products, concentrating explicitly on the bystander aspect. We show that
although some of the vendors acknowledge bystanders, they address it only to
the extent of including disclaimers, shifting the ethical responsibility for
collecting the data of non-users to the device owner. In addition, we identify
and examine real-world cases related to bystander privacy, demonstrating how
current deployments can impact non-users. Based on our findings, we analyze
vendor privacy policies in light of existing legal frameworks and technical
capabilities, and we provide practical recommendations for both policy language
and system design to enhance transparency and empower both bystanders and
device owners.

</details>


### [13] [A DRL-Empowered Multi-Level Jamming Approach for Secure Semantic Communication](https://arxiv.org/abs/2510.26610)
*Weixuan Chen,Qianqian Yang*

Main category: cs.CR

TL;DR: 提出了一种基于深度强化学习（DRL）的多级干扰方法，以增强MIMO衰落窃听信道上的语义通信（SemCom）系统的安全性。该方法结合了语义层干扰（通过编码任务无关文本实现）和物理层干扰（通过编码随机高斯噪声实现），并将这两种干扰信号与任务相关的语义信息叠加，以保护传输的语义不被窃听。此外，引入了深度确定性策略梯度（DDPG）算法来动态设计和优化任务相关语义信息和多级干扰信号的预编码矩阵，旨在提升合法用户的图像重建质量，同时降低窃听者的性能。


<details>
  <summary>Details</summary>
Motivation: 由于语义通信仅传输任务相关信息以提高通信效率，这同时使得语义信息容易受到窃听攻击。因此，需要一种有效的方法来增强语义通信系统的安全性，防止未经授权的用户获取敏感语义信息。

Method: 1. 在语义层和物理层实施多级干扰：语义层干扰编码任务无关的文本；物理层干扰编码随机高斯噪声。2. 使用DDPG算法动态设计和优化语义信息及多级干扰信号的预编码矩阵，以最大化合法用户的性能同时最小化窃听者的性能。3. 提出交替优化策略，联合训练语义通信模型和DDPG模型：迭代更新两个模块直到收敛。

Result: 与加密基准（ESCS）和基于编码干扰器的基准（EJ）相比，该方法在提供相当安全性的同时，将合法用户的峰值信噪比（PSNR）提高高达约0.6 dB。

Conclusion: 所提出的DRL驱动的多级干扰方法有效增强了语义通信系统的安全性，不仅防止窃听，还显著提升了合法用户的重建性能，验证了所提出的动态预编码矩阵设计的有效性及其在实际应用中的潜力。

Abstract: Semantic communication (SemCom) aims to transmit only task-relevant
information, thereby improving communication efficiency but also exposing
semantic information to potential eavesdropping. In this paper, we propose a
deep reinforcement learning (DRL)-empowered multi-level jamming approach to
enhance the security of SemCom systems over MIMO fading wiretap channels. This
approach combines semantic layer jamming, achieved by encoding task-irrelevant
text, and physical layer jamming, achieved by encoding random Gaussian noise.
These two-level jamming signals are superposed with task-relevant semantic
information to protect the transmitted semantics from eavesdropping. A deep
deterministic policy gradient (DDPG) algorithm is further introduced to
dynamically design and optimize the precoding matrices for both taskrelevant
semantic information and multi-level jamming signals, aiming to enhance the
legitimate user's image reconstruction while degrading the eavesdropper's
performance. To jointly train the SemCom model and the DDPG agent, we propose
an alternating optimization strategy where the two modules are updated
iteratively. Experimental results demonstrate that, compared with both the
encryption-based (ESCS) and encoded jammer-based (EJ) benchmarks, our method
achieves comparable security while improving the legitimate user's peak
signalto-noise ratio (PSNR) by up to approximately 0.6 dB.

</details>


### [14] [Toward Automated Security Risk Detection in Large Software Using Call Graph Analysis](https://arxiv.org/abs/2510.26620)
*Nicholas Pecka,Lotfi Ben Othmane,Renee Bryce*

Main category: cs.CR

TL;DR: 该论文提出了一种通过聚类调用图来自动化软件威胁建模的方法，使用密度基础和社区检测算法识别威胁集群。通过Splunk Forwarder Operator案例研究验证了方法的有效性，展示了其在发现代码密度安全弱点和系统性威胁评估方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 手工威胁建模方法通常费力且易出错。为了解决这个问题，本文研究自动化软件威胁建模，以提升效率并降低错误率。

Method: 首先使用密度基础聚类和社区检测算法对软件的调用图进行聚类，然后分析识别出的集群相关联的威胁。

Result: 在Splunk Forwarder Operator案例研究中，所提方法成功识别了相关代码密度的安全弱点，验证了方法的可行性，并展示了在支持系统性威胁评估方面的潜力。

Conclusion: 这项工作为现代云原生环境量身定制了可扩展的半自动化威胁建模框架，为自动化软件安全保障提供了新途径。

Abstract: Threat modeling plays a critical role in the identification and mitigation of
security risks; however, manual approaches are often labor intensive and prone
to error. This paper investigates the automation of software threat modeling
through the clustering of call graphs using density-based and community
detection algorithms, followed by an analysis of the threats associated with
the identified clusters. The proposed method was evaluated through a case study
of the Splunk Forwarder Operator (SFO), wherein selected clustering metrics
were applied to the software's call graph to assess pertinent code-density
security weaknesses. The results demonstrate the viability of the approach and
underscore its potential to facilitate systematic threat assessment. This work
contributes to the advancement of scalable, semi-automated threat modeling
frameworks tailored for modern cloud-native environments.

</details>
