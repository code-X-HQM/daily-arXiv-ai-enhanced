<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 2]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [A Decentralized Retrieval Augmented Generation System with Source Reliabilities Secured on Blockchain](https://arxiv.org/abs/2511.07577)
*Yining Lu,Wenyi Tang,Max Johnson,Taeho Jung,Meng Jiang*

Main category: cs.CR

TL;DR: 本文提出了一种去中心化的RAG（检索增强生成）系统，通过引入基于区块链的可靠性评分机制，解决了去中心化环境下数据源可靠性参差不齐的问题。系统动态评估数据源的响应质量，优先选择高质量来源，在不可靠数据环境中性能超过集中式系统10.7%，同时通过批量更新节省约56%边际成本。


<details>
  <summary>Details</summary>
Motivation: 集中式RAG系统存在数据收集、整合和管理成本高以及隐私问题。需要构建去中心化RAG系统，使基础模型能够直接从数据所有者处获取信息，同时保障数据控制权。但去中心化导致数据源可靠性差异大，影响检索精度和响应质量。

Method: 1. 设计动态可靠性评分机制，依据数据源对生成响应的贡献质量评估其可靠性；2. 在检索过程中优先选择高评分数据源；3. 通过区块链智能合约实现评分过程的安全透明管理，确保记录可验证且防篡改。

Result: 1. 在两种模拟环境（六种不同可靠性数据源）中测试：真实世界不可靠数据环境下，性能较集中式基准提升+10.7%；理想可靠数据环境下接近集中式系统的理论上限性能；2. 区块链批量更新操作节省约56%边际成本。

Conclusion: 去中心化RAG系统通过可靠性评分和区块链管理有效应对数据源可靠性差异问题，提升响应质量的同时降低运营成本。其在隐私保护和数据主权方面的优势为实际落地提供重要价值。

Abstract: Existing retrieval-augmented generation (RAG) systems typically use a centralized architecture, causing a high cost of data collection, integration, and management, as well as privacy concerns. There is a great need for a decentralized RAG system that enables foundation models to utilize information directly from data owners who maintain full control over their sources. However, decentralization brings a challenge: the numerous independent data sources vary significantly in reliability, which can diminish retrieval accuracy and response quality. To address this, our decentralized RAG system has a novel reliability scoring mechanism that dynamically evaluates each source based on the quality of responses it contributes to generate and prioritizes high-quality sources during retrieval. To ensure transparency and trust, the scoring process is securely managed through blockchain-based smart contracts, creating verifiable and tamper-proof reliability records without relying on a central authority. We evaluate our decentralized system with two Llama models (3B and 8B) in two simulated environments where six data sources have different levels of reliability. Our system achieves a +10.7\% performance improvement over its centralized counterpart in the real world-like unreliable data environments. Notably, it approaches the upper-bound performance of centralized systems under ideally reliable data environments. The decentralized infrastructure enables secure and trustworthy scoring management, achieving approximately 56\% marginal cost savings through batched update operations. Our code and system are open-sourced at github.com/yining610/Reliable-dRAG.

</details>


### [2] [LoopLLM: Transferable Energy-Latency Attacks in LLMs via Repetitive Generation](https://arxiv.org/abs/2511.07876)
*Xingyu Li,Xiaolei Liu,Cheng Liu,Yixiao Xu,Kangyi Ding,Bangzhou Xin,Jia-Li Yin*

Main category: cs.CR

TL;DR: 该论文提出了一个名为LoopLLM的框架，用于针对大型语言模型（LLMs）发起能量-延迟攻击，通过诱导模型陷入低熵解码循环来延长输出直至达到最大长度限制，显著超越了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有攻击方法通过控制输入延迟终止符来增加输出长度效率低下且难以为继，因为输出增长后控制终止符变得困难。因此，作者观察到重复生成会可靠地触发低熵解码循环，这启发了他们提出更有效的攻击框架LoopLLM。

Method: LoopLLM框架包含两个关键优化：(1) 重复诱导提示优化，利用自回归漏洞诱导模型生成高度重复内容；(2) 令牌对齐集成优化，通过聚合梯度转移攻击至不同LLMs以提升跨模型可迁移性。该方法通过在12个开源模型和2个商业模型上进行广泛实验验证。

Result: 实验表明LoopLLM在最大输出长度达成率上超过90%，远超基线方法的20%；同时跨模型可迁移性提升约40%，在DeepSeek-V3及Gemini 2.5 Flash等模型上表现突出。

Conclusion: LoopLLM证明了基于重复性低熵循环攻击的高效性，显著增强了大型语言模型在能量-延迟维度上的威胁表现，为未来防御机制设计提供了重要洞见。

Abstract: As large language models (LLMs) scale, their inference incurs substantial computational resources, exposing them to energy-latency attacks, where crafted prompts induce high energy and latency cost. Existing attack methods aim to prolong output by delaying the generation of termination symbols. However, as the output grows longer, controlling the termination symbols through input becomes difficult, making these methods less effective. Therefore, we propose LoopLLM, an energy-latency attack framework based on the observation that repetitive generation can trigger low-entropy decoding loops, reliably compelling LLMs to generate until their output limits. LoopLLM introduces (1) a repetition-inducing prompt optimization that exploits autoregressive vulnerabilities to induce repetitive generation, and (2) a token-aligned ensemble optimization that aggregates gradients to improve cross-model transferability. Extensive experiments on 12 open-source and 2 commercial LLMs show that LoopLLM significantly outperforms existing methods, achieving over 90% of the maximum output length, compared to 20% for baselines, and improving transferability by around 40% to DeepSeek-V3 and Gemini 2.5 Flash.

</details>
