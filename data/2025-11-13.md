<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 11]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Automated Hardware Trojan Insertion in Industrial-Scale Designs](https://arxiv.org/abs/2511.08703)
*Yaroslav Popryho,Debjit Pal,Inna Partin-Vaisband*

Main category: cs.CR

TL;DR: 本文提出了一个自动化且可扩展的方法，用于在工业规模网表中生成硬件木马（HT）类似模式，以在不改变用户可见功能的前提下对检测工具进行压力测试。该方法通过解析大型门级设计为连接图，利用SCOAP测试性指标探索稀有区域，并应用参数化、功能保持的图转换技术合成触发-负载对来模拟隐蔽HT的统计足迹。


<details>
  <summary>Details</summary>
Motivation: 工业系统级芯片（SoCs）通常包含数十万至数百万条网线以及数百万至数千万条连接边缘，这使得在现实设计上进行硬件木马检测器的经验评估显得必要且困难。当前公共基准测试集规模较小且多为手工制作，而发布真实的恶意RTL存在伦理和操作风险。因此，需要一种方法能够生成接近真实HT的模式来有效测试检测工具，而不涉及实际恶意内容的分发。

Method: 提出了一套自动化流水线：(i) 将大型门级设计解析为连接图；(ii) 使用SCOAP测试性指标探索稀有区域；(iii) 应用参数化且功能保持的图转换技术，合成模仿隐蔽硬件木马统计足迹的触发-负载对。

Result: 应用该方法生成的测试基准上，代表当前先进水平的图学习模型未能检测到木马，证明了该方法生成案例的挑战性。

Conclusion: 该框架通过提供可复现的挑战案例，弥合了学术电路与现代SoC之间的评估差距，有助于推进芯片安全研究，同时避免了分享分步攻击指令的风险。

Abstract: Industrial Systems-on-Chips (SoCs) often comprise hundreds of thousands to millions of nets and millions to tens of millions of connectivity edges, making empirical evaluation of hardware-Trojan (HT) detectors on realistic designs both necessary and difficult. Public benchmarks remain significantly smaller and hand-crafted, while releasing truly malicious RTL raises ethical and operational risks. This work presents an automated and scalable methodology for generating HT-like patterns in industry-scale netlists whose purpose is to stress-test detection tools without altering user-visible functionality. The pipeline (i) parses large gate-level designs into connectivity graphs, (ii) explores rare regions using SCOAP testability metrics, and (iii) applies parameterized, function-preserving graph transformations to synthesize trigger-payload pairs that mimic the statistical footprint of stealthy HTs. When evaluated on the benchmarks generated in this work, representative state-of-the-art graph-learning models fail to detect Trojans. The framework closes the evaluation gap between academic circuits and modern SoCs by providing reproducible challenge instances that advance security research without sharing step-by-step attack instructions.

</details>


### [2] [Channel-Robust RFF for Low-Latency 5G Device Identification in SIMO Scenarios](https://arxiv.org/abs/2511.08902)
*Yingjie Sun,Guyue Li,Hongfu Chou,Aiqun Hu*

Main category: cs.CR

TL;DR: 该论文提出了一种利用多天线信号提取射频指纹（RFF）的新技术——对数线性差值比（LLDR），以解决多径信道下RFF识别延迟和精度问题。该方法在单一时间点提取多个接收天线的信道频率响应（CFR），通过在子带内计算LLDR保持RFF鉴别性特征，无需多次采样或反馈，显著降低了延迟。仿真表明，在20dB SNR的20径信道中，对30个用户设备的识别准确率达96.13%，空口延迟低至0.491ms，满足URLLC要求。


<details>
  <summary>Details</summary>
Motivation: 5G超低时延需求下，现有加密方案增加计算开销导致识别延迟，而传统物理层射频指纹（RFF）在多径信道中精度下降。现有抗多径方法需多时间点采样或反馈机制，引入额外信令延迟。该研究旨在设计一种无需增加时延、能抵抗多径干扰的RFF提取技术。

Method: 提出对数线性差值比（LLDR）：①利用单个时间点上多个接收天线的共时信道频率响应（CFR），计算相邻天线CFR的对数差分比作为特征；②将频带划分为子带，在各子带内独立计算LLDR，解决依赖信道微小变化的问题；③避开多时间点采样和反馈机制，仅需单次测量降低获取时延。

Result: 在20dB SNR的20径多径信道环境下，对30个用户设备的识别准确率达到96.13%。通过Roofline模型评估理论延迟，空口延迟仅0.491ms，满足URLLC的严格时延要求（通常<1ms）。

Conclusion: LLDR技术突破性地实现单时间点多天线联合特征提取，克服多径干扰的同时避免额外延迟。该方法首次将空口延迟降至URLLC阈值以下，为物理层安全认证提供高精度、超低延迟解决方案，具有5G/6G实际部署价值。

Abstract: Ultra-low latency, the hallmark of fifth-generation mobile communications (5G), imposes exacting timing demands on identification as well. Current cryptographic solutions introduce additional computational overhead, which results in heightened identification delays. Radio frequency fingerprint (RFF) identifies devices at the physical layer, blocking impersonation attacks while significantly reducing latency. Unfortunately, multipath channels compromise RFF accuracy, and existing channel-resilient methods demand feedback or processing across multiple time points, incurring extra signaling latency. To address this problem, the paper introduces a new RFF extraction technique that employs signals from multiple receiving antennas to address multipath issues without adding latency. Unlike single-domain methods, the Log-Linear Delta Ratio (LLDR) of co-temporal channel frequency responses (CFRs) from multiple antennas is employed to preserve discriminative RFF features, eliminating multi-time sampling and reducing acquisition time. To overcome the challenge of the reliance on minimal channel variation, the frequency band is segmented into sub-bands, and the LLDR is computed within each sub-band individually. Simulation results indicate that the proposed scheme attains a 96.13% identification accuracy for 30 user equipments (UEs) within a 20-path channel under a signal-to-noise ratio (SNR) of 20 dB. Furthermore, we evaluate the theoretical latency using the Roofline model, resulting in the air interface latency of 0.491 ms, which satisfies ultra-reliable and low-latency communications (URLLC) latency requirements.

</details>


### [3] [iSeal: Encrypted Fingerprinting for Reliable LLM Ownership Verification](https://arxiv.org/abs/2511.08905)
*Zixun Xiong,Gaoyi Wu,Qingyang Yu,Mingyu Derek Ma,Lingfeng Yao,Miao Pan,Xiaojiang Du,Hao Wang*

Main category: cs.CR

TL;DR: 提出了iSeal方法，针对LLM知识产权保护，即使攻击者完全控制模型推理过程也能有效进行指纹验证。该方法在模型和外部模块中注入独特特征，结合纠错机制和基于相似性的验证策略，抵抗包括指纹消除和响应操纵在内的多种攻击，实现了100%的指纹成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM指纹方法在模型窃贼完全控制推理过程时无效，可能遭受指纹消除和输出篡改攻击。因此需要一种能在端到端控制场景下可靠验证所有权的方法。

Method: iSeal在目标模型和外部模块中注入独特特征；使用纠错码机制增强鲁棒性；采用基于相似性的验证策略（而非精确匹配）来抵御输出篡改。方法包含特征注入、纠错、相似性验证三个核心组件。

Result: 在12个LLM上测试，对10+种攻击（包括指纹消除和响应操纵）保持100%指纹成功率。现有基线方法在消除攻击和操纵攻击下完全失效。

Conclusion: iSeal是首个在攻击者端到端控制模型时仍能可靠工作的指纹方案，通过联合使用模型内/外特征、纠错机制和非精确匹配验证，填补了现有方法的安全缺陷。

Abstract: Given the high cost of large language model (LLM) training from scratch, safeguarding LLM intellectual property (IP) has become increasingly crucial. As the standard paradigm for IP ownership verification, LLM fingerprinting thus plays a vital role in addressing this challenge. Existing LLM fingerprinting methods verify ownership by extracting or injecting model-specific features. However, they overlook potential attacks during the verification process, leaving them ineffective when the model thief fully controls the LLM's inference process. In such settings, attackers may share prompt-response pairs to enable fingerprint unlearning or manipulate outputs to evade exact-match verification. We propose iSeal, the first fingerprinting method designed for reliable verification when the model thief controls the suspected LLM in an end-to-end manner. It injects unique features into both the model and an external module, reinforced by an error-correction mechanism and a similarity-based verification strategy. These components are resistant to verification-time attacks, including collusion-based fingerprint unlearning and response manipulation, backed by both theoretical analysis and empirical results. iSeal achieves 100 percent Fingerprint Success Rate (FSR) on 12 LLMs against more than 10 attacks, while baselines fail under unlearning and response manipulations.

</details>


### [4] [DeepTracer: Tracing Stolen Model via Deep Coupled Watermarks](https://arxiv.org/abs/2511.08985)
*Yunfei Yang,Xiaojun Chen,Yuexin Xuan,Zhendong Zhao,Xin Zhao,He Li*

Main category: cs.CR

TL;DR: 本文提出了一个名为DeepTracer的鲁棒模型水印框架，通过新颖的水印样本构建方法和同类耦合损失约束，使得水印任务与主要任务高度耦合，从而在模型窃取攻击中有效保护水印。此外，还引入了水印样本过滤机制以提高水印验证的可靠性。实验证明该方法在防御模型窃取攻击和水印攻击方面超越了现有方法，达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现今的模型水印技术在面对模型窃取攻击时容易被移除，导致模型拥有者难以有效验证被盗模型的版权。本文旨在分析在模型窃取场景下现有水印方法失效的根本原因，并探索解决方案。

Method: 作者引入了DeepTracer框架，该框架包含两个主要创新点：1) 利用新型水印样本构建方法和同类耦合损失约束，使水印任务与主要任务高度耦合，确保攻击者在窃取主要任务功能时不可避免学习到隐藏的水印任务；2) 提出水印样本过滤机制，精选用于模型版权验证的水印关键样本，增强水印可靠性。该方法在多个数据集和模型上进行了测试。

Result: 大量实验证明，DeepTracer在防御各种模型窃取攻击（如参数剪枝、模型蒸馏等）和水印攻击（如后门攻击）方面超越了现有方法，并且在不同数据集上都展示出高成功率和可靠性。同时，该方法在正常模型性能上的影响很小，表明其具有低开销性。

Conclusion: DeepTracer是一种鲁棒的模型水印工具，通过强制水印任务与主要任务耦合以及精选验证样本，解决了现有方法在模型窃取场景下被移除的问题，显著增强了模型的版权保护能力。其为模型所有者提供了有效的版权声明机制，尤其在开放服务提供环境中防止模型被盗方面具有实用价值。

Abstract: Model watermarking techniques can embed watermark information into the protected model for ownership declaration by constructing specific input-output pairs. However, existing watermarks are easily removed when facing model stealing attacks, and make it difficult for model owners to effectively verify the copyright of stolen models. In this paper, we analyze the root cause of the failure of current watermarking methods under model stealing scenarios and then explore potential solutions. Specifically, we introduce a robust watermarking framework, DeepTracer, which leverages a novel watermark samples construction method and a same-class coupling loss constraint. DeepTracer can incur a high-coupling model between watermark task and primary task that makes adversaries inevitably learn the hidden watermark task when stealing the primary task functionality. Furthermore, we propose an effective watermark samples filtering mechanism that elaborately select watermark key samples used in model ownership verification to enhance the reliability of watermarks. Extensive experiments across multiple datasets and models demonstrate that our method surpasses existing approaches in defending against various model stealing attacks, as well as watermark attacks, and achieves new state-of-the-art effectiveness and robustness.

</details>


### [5] [MedHE: Communication-Efficient Privacy-Preserving Federated Learning with Adaptive Gradient Sparsification for Healthcare](https://arxiv.org/abs/2511.09043)
*Farjana Yesmin*

Main category: cs.CR

TL;DR: 提出了MedHE框架，结合自适应梯度稀疏化和CKKS同态加密，在医疗联邦学习中实现高效隐私保护。


<details>
  <summary>Details</summary>
Motivation: 医疗联邦学习需在资源有限的医疗机构间保证强隐私性，同时保持计算效率。

Method: 采用带误差补偿的动态阈值机制进行梯度稀疏化（top-k选择），结合CKKS同态加密。

Result: 通信量减少97.5%（每轮1277MB→32MB），准确率89.5±0.8%，与标准联邦学习无显著差异（p=0.32），ε≤1.0的差分隐私保障，支持100+机构扩展。

Conclusion: MedHE满足HIPAA合规性，为医疗数据协作提供实用可行的隐私保护解决方案。

Abstract: Healthcare federated learning requires strong privacy guarantees while maintaining computational efficiency across resource-constrained medical institutions. This paper presents MedHE, a novel framework combining adaptive gradient sparsification with CKKS homomorphic encryption to enable privacy-preserving collaborative learning on sensitive medical data. Our approach introduces a dynamic threshold mechanism with error compensation for top-k gradient selection, achieving 97.5 percent communication reduction while preserving model utility. We provide formal security analysis under Ring Learning with Errors assumptions and demonstrate differential privacy guarantees with epsilon less than or equal to 1.0. Statistical testing across 5 independent trials shows MedHE achieves 89.5 percent plus or minus 0.8 percent accuracy, maintaining comparable performance to standard federated learning (p=0.32) while reducing communication from 1277 MB to 32 MB per training round. Comprehensive evaluation demonstrates practical feasibility for real-world medical deployments with HIPAA compliance and scalability to 100 plus institutions.

</details>


### [6] [Attack-Centric by Design: A Program-Structure Taxonomy of Smart Contract Vulnerabilities](https://arxiv.org/abs/2511.09051)
*Parsa Hedayatnia,Tina Tavakkoli,Hadi Amini,Mohammad Allahbakhsh,Haleh Amintoosi*

Main category: cs.CR

TL;DR: 本文提出了一个以攻击为中心、基于程序结构的分类法，将Solidity漏洞统一为八大根本原因族，覆盖控制流、外部调用、状态完整性等领域。


<details>
  <summary>Details</summary>
Motivation: 现有分类和工具局限于漏洞症状（如重入攻击），缺乏对结构性根源的统一归纳，导致漏洞检测碎片化且难以系统化防护。因此，需要建立统一分类体系以提升检测效力和安全教育的结构性。

Method: 1. 提出八类根因漏洞家族；2. 每类通过Solidity代码示例、攻击机制及修复方案说明；3. 将漏洞映射至静态/动态/学习型工具的检测信号；4. 对历史数据集（SmartBugs等）进行跨映射分析。

Result: 1. 构建了标准化分类体系；2. 验证发现传统数据集存在标签偏移（label drift）和覆盖缺口；3. 该分类法为漏洞检测、审计和教育提供结构化支持。

Conclusion: 八族分类法为智能合约安全领域提供了统一术语与实践框架，增强了漏洞检测的可解释性、审计的可复现性及安全教育的系统性。

Abstract: Smart contracts concentrate high value assets and complex logic in small, immutable programs, where even minor bugs can cause major losses. Existing taxonomies and tools remain fragmented, organized around symptoms such as reentrancy rather than structural causes. This paper introduces an attack-centric, program-structure taxonomy that unifies Solidity vulnerabilities into eight root-cause families covering control flow, external calls, state integrity, arithmetic safety, environmental dependencies, access control, input validation, and cross-domain protocol assumptions. Each family is illustrated through concise Solidity examples, exploit mechanics, and mitigations, and linked to the detection signals observable by static, dynamic, and learning-based tools. We further cross-map legacy datasets (SmartBugs, SolidiFI) to this taxonomy to reveal label drift and coverage gaps. The taxonomy provides a consistent vocabulary and practical checklist that enable more interpretable detection, reproducible audits, and structured security education for both researchers and practitioners.

</details>


### [7] [Improving Sustainability of Adversarial Examples in Class-Incremental Learning](https://arxiv.org/abs/2511.09088)
*Taifeng Liu,Xinjing Liu,Liangqiu Dong,Yang Liu,Yilong Yang,Zhuo Ma*

Main category: cs.CR

TL;DR: 本文提出SAE框架，旨在增强对抗样本在类增量学习（CIL）更新中的可持续性，解决现有对抗样本在模型更新后失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有对抗样本针对静态模型设计，但在CIL动态更新中，因领域漂移导致失效。需提升对抗样本在模型更新过程中的鲁棒性。

Method: 1. 核心思想：优化对抗样本语义，使其更接近目标类并远离其他类；2. 语义校正模块：利用视觉语言模型提取泛化语义，结合CIL模型修正优化方向；3. 过滤增强模块：在隐空间筛选具有目标类语义的非目标样本并增强，稳定语义。

Result: 在类别数增加9倍的CIL更新后，SAE平均比基线方法性能提升31.28%。

Conclusion: SAE通过语义校正和过滤增强显著提升对抗样本在CIL环境中的可持续性，为动态模型安全提供新思路。

Abstract: Current adversarial examples (AEs) are typically designed for static models. However, with the wide application of Class-Incremental Learning (CIL), models are no longer static and need to be updated with new data distributed and labeled differently from the old ones. As a result, existing AEs often fail after CIL updates due to significant domain drift. In this paper, we propose SAE to enhance the sustainability of AEs against CIL. The core idea of SAE is to enhance the robustness of AE semantics against domain drift by making them more similar to the target class while distinguishing them from all other classes. Achieving this is challenging, as relying solely on the initial CIL model to optimize AE semantics often leads to overfitting. To resolve the problem, we propose a Semantic Correction Module. This module encourages the AE semantics to be generalized, based on a visual-language model capable of producing universal semantics. Additionally, it incorporates the CIL model to correct the optimization direction of the AE semantics, guiding them closer to the target class. To further reduce fluctuations in AE semantics, we propose a Filtering-and-Augmentation Module, which first identifies non-target examples with target-class semantics in the latent space and then augments them to foster more stable semantics. Comprehensive experiments demonstrate that SAE outperforms baselines by an average of 31.28% when updated with a 9-fold increase in the number of classes.

</details>


### [8] [Differentially Private Rankings via Outranking Methods and Performance Data Aggregation](https://arxiv.org/abs/2511.09120)
*Luis Del Vasto-Terrientes*

Main category: cs.CR

TL;DR: 提出一种结合多准则决策(MCDM)排名方法和差分隐私(DP)的新方法，在保证隐私的前提下处理敏感数据驱动的决策问题。验证显示匿名化排名与真实结果保持强统计相关性。


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护机制与MCDM方法结合不足，而数据驱动决策领域日益依赖敏感数据，需解决隐私泄露风险

Method: 1.预处理聚合多用户评估为综合性能矩阵；2.在排名问题中引入差分隐私保护个体贡献

Result: 真实排名与匿名版本呈现强至极强统计相关性(>0.8)，同时提供鲁棒的隐私参数保障(ε≤1时仍保持0.9以上相关性)

Conclusion: 该方法首次实现排名导向型MCDM与DP的结合，为敏感决策场景提供可量化的隐私-效用平衡方案

Abstract: Multiple-Criteria Decision Making (MCDM) is a sub-discipline of Operations Research that helps decision-makers in choosing, ranking, or sorting alternatives based on conflicting criteria. Over time, its application has been expanded into dynamic and data-driven domains, such as recommender systems. In these contexts, the availability and handling of personal and sensitive data can play a critical role in the decision-making process. Despite this increased reliance on sensitive data, the integration of privacy mechanisms with MCDM methods is underdeveloped. This paper introduces an integrated approach that combines MCDM outranking methods with Differential Privacy (DP), safeguarding individual contributions' privacy in ranking problems. This approach relies on a pre-processing step to aggregate multiple user evaluations into a comprehensive performance matrix. The evaluation results show a strong to very strong statistical correlation between the true rankings and their anonymized counterparts, ensuring robust privacy parameter guarantees.

</details>


### [9] [One Signature, Multiple Payments: Demystifying and Detecting Signature Replay Vulnerabilities in Smart Contracts](https://arxiv.org/abs/2511.09134)
*Zexu Wang,Jiachi Chen,Zewei Lin,Wenqing Chen,Kaiwen Ning,Jianxing Yu,Yuming Feng,Yu Zhang,Weizhe Zhang,Zibin Zheng*

Main category: cs.CR

TL;DR: 本文对智能合约中存在的签名重放漏洞（SRV）进行了首次实证研究，揭示了其普遍性及危害，并提出了基于大语言模型（LLM）辅助的自动化检测工具LASiR，实验证明其高效性。


<details>
  <summary>Details</summary>
Motivation: 数字签名在智能合约权限验证中至关重要，但缺乏对签名使用条件的检查会导致重放漏洞（SRV），造成权限滥用和资产威胁。当前尚未有系统性研究，因此需通过实证分析探究SRV成因与特征，并构建自动化检测方案。

Method: 1) 从374份安全审计报告中提取108个详细SRV案例，归纳出5类漏洞模式；2) 提出工具LASiR：结合LLM的语义理解能力辅助静态污染分析以追踪签名状态，通过符号执行进行路径可达性验证；3) 在4条区块链（以太坊等）的15,383份含签名验证的合约上进行大规模实验。

Result: 1) SRV普遍存在：以太坊上19.63%的含签名合约存在漏洞，受影响合约持有476万美元活跃资产；2) LASiR检测F1值达87.90%，人工验证有效；3) 消融实验证明LLM提供的语义信息显著提升检测性能。

Conclusion: SRV是智能合约重大安全威胁，LASiR通过创新融合LLM语义分析与传统程序分析技术，实现了高精度检测，为区块链安全实践提供有效工具。

Abstract: Smart contracts have significantly advanced blockchain technology, and digital signatures are crucial for reliable verification of contract authority. Through signature verification, smart contracts can ensure that signers possess the required permissions, thus enhancing security and scalability. However, lacking checks on signature usage conditions can lead to repeated verifications, increasing the risk of permission abuse and threatening contract assets. We define this issue as the Signature Replay Vulnerability (SRV). In this paper, we conducted the first empirical study to investigate the causes and characteristics of the SRVs. From 1,419 audit reports across 37 blockchain security companies, we identified 108 with detailed SRV descriptions and classified five types of SRVs. To detect these vulnerabilities automatically, we designed LASiR, which utilizes the general semantic understanding ability of Large Language Models (LLMs) to assist in the static taint analysis of the signature state and identify the signature reuse behavior. It also employs path reachability verification via symbolic execution to ensure effective and reliable detection. To evaluate the performance of LASiR, we conducted large-scale experiments on 15,383 contracts involving signature verification, selected from the initial dataset of 918,964 contracts across four blockchains: Ethereum, Binance Smart Chain, Polygon, and Arbitrum. The results indicate that SRVs are widespread, with affected contracts holding $4.76 million in active assets. Among these, 19.63% of contracts that use signatures on Ethereum contain SRVs. Furthermore, manual verification demonstrates that LASiR achieves an F1-score of 87.90% for detection. Ablation studies and comparative experiments reveal that the semantic information provided by LLMs aids static taint analysis, significantly enhancing LASiR's detection performance.

</details>


### [10] [Unveiling Hidden Threats: Using Fractal Triggers to Boost Stealthiness of Distributed Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2511.09252)
*Jian Wang,Hong Shen,Chan-Tong Lam*

Main category: cs.CR

TL;DR: 提出了一种名为FTDBA的新方法，利用分形的自相似性增强子触发器的特征强度，在相同攻击强度下显著减少所需的中毒数据量，并通过动态角度扰动平衡效率和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 传统分布式后门攻击（DBA）通过将全局触发器分解为子触发器来提高隐蔽性，但需要更多的中毒数据来维持攻击强度，从而增加暴露风险。

Method: 利用分形的自相似性增强子触发器的特征强度，并引入动态角度扰动机制，自适应调整训练阶段的扰动强度以平衡效率和隐蔽性。

Result: 实验显示，FTDBA仅需传统DBA方法62.4%的中毒量即可达到92.3%的攻击成功率，同时将检测率降低22.8%，KL散度降低41.2%。

Conclusion: 该研究提出了一种低暴露、高效率的联邦后门攻击范式，并扩展了分形特征在对抗样本生成中的应用。

Abstract: Traditional distributed backdoor attacks (DBA) in federated learning improve stealthiness by decomposing global triggers into sub-triggers, which however requires more poisoned data to maintian the attck strength and hence increases the exposure risk. To overcome this defect, This paper proposes a novel method, namely Fractal-Triggerred Distributed Backdoor Attack (FTDBA), which leverages the self-similarity of fractals to enhance the feature strength of sub-triggers and hence significantly reduce the required poisoning volume for the same attack strength. To address the detectability of fractal structures in the frequency and gradient domains, we introduce a dynamic angular perturbation mechanism that adaptively adjusts perturbation intensity across the training phases to balance efficiency and stealthiness. Experiments show that FTDBA achieves a 92.3\% attack success rate with only 62.4\% of the poisoning volume required by traditional DBA methods, while reducing the detection rate by 22.8\% and KL divergence by 41.2\%. This study presents a low-exposure, high-efficiency paradigm for federated backdoor attacks and expands the application of fractal features in adversarial sample generation.

</details>


### [11] [Quantum Meet-in-the-Middle Attacks on Key-Length Extension Constructions](https://arxiv.org/abs/2511.09351)
*Min Liang,Ruihao Gao,Jiali Wu*

Main category: cs.CR

TL;DR: 提出针对双重密钥三重加密（2kTE）的两种量子中间相遇（MITM）攻击和针对三重异或级联加密（3XCE）的一种量子MITM攻击，并将MITM扩展为量子筛选中问（SITM）攻击框架，展示了在Q2和Q1模型下的量子优势。


<details>
  <summary>Details</summary>
Motivation: 研究密钥长度扩展（KLE）技术中双重密钥三重加密（2kTE）和三重异或级联加密（3XCE）在量子模型下的安全性，探索量子MITM和SITM攻击以评估其安全强度。

Method: 1. 针对2kTE：利用量子爪寻找（QCF）算法提出攻击（时间O(2^{2κ/3})），并基于Grover算法改进（时间O(2^{κ/2})）；2. 针对3XCE：设计Q1模型下的量子MITM攻击（时间O(2^{(κ+n)/2})）；3. 扩展量子SITM框架，适用于ELE=E^2◦L◦E^1结构及多种中间层L。

Result: 1. 2kTE在Q2模型下使用足够QRAM时，Grover攻击的复杂度与底层分组密码暴力破解相当，即无安全性提升；2. 3XCE在Q1模型下量子攻击实现二次加速；3. SITM框架可推广至更广的量子密码分析场景。

Conclusion: 2kTE在量子资源充足时无安全优势；3XCE在Q1模型下易受量子MITM攻击；新提出的量子SITM框架为评估KLE结构的量子安全性提供通用工具。

Abstract: Key-length extension (KLE) techniques provide a general approach to enhancing the security of block ciphers by using longer keys. There are mainly two classes of KLE techniques, cascade encryption and XOR-cascade encryption. This paper presents several quantum meet-in-the-middle (MITM) attacks against two specific KLE constructions.
  For the two-key triple encryption (2kTE), we propose two quantum MITM attacks under the Q2 model. The first attack, leveraging the quantum claw-finding (QCF) algorithm, achieves a time complexity of $O(2^{2κ/3})$ with $O(2^{2κ/3})$ quantum random access memory (QRAM). The second attack, based on Grover's algorithm, achieves a time complexity of $O(2^{κ/2})$ with $O(2^κ)$ QRAM. The latter complexity is nearly identical to Grover-based brute-force attack on the underlying block cipher, indicating that 2kTE does not enhance security under the Q2 model when sufficient QRAM resources are available.
  For the 3XOR-cascade encryption (3XCE), we propose a quantum MITM attack applicable to the Q1 model. This attack requires no QRAM and has a time complexity of $O(2^{(κ+n)/2})$ ($κ$ and $n$ are the key length and block length of the underlying block cipher, respectively.), achieving a quadratic speedup over classical MITM attack.
  Furthermore, we extend the quantum MITM attack to quantum sieve-in-the-middle (SITM) attack, which is applicable for more constructions. We present a general quantum SITM framework for the construction $ELE=E^2\circ L\circ E^1$ and provide specific attack schemes for three different forms of the middle layer $L$. The quantum SITM attack technique can be further applied to a broader range of quantum cryptanalysis scenarios.

</details>
