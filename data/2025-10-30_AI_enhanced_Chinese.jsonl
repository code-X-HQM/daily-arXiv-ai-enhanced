{"id": "2510.24807", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24807", "abs": "https://arxiv.org/abs/2510.24807", "authors": ["Ziyao Cui", "Minxing Zhang", "Jian Pei"], "title": "Learning to Attack: Uncovering Privacy Risks in Sequential Data Releases", "comment": null, "summary": "Privacy concerns have become increasingly critical in modern AI and data\nscience applications, where sensitive information is collected, analyzed, and\nshared across diverse domains such as healthcare, finance, and mobility. While\nprior research has focused on protecting privacy in a single data release, many\nreal-world systems operate under sequential or continuous data publishing,\nwhere the same or related data are released over time. Such sequential\ndisclosures introduce new vulnerabilities, as temporal correlations across\nreleases may enable adversaries to infer sensitive information that remains\nhidden in any individual release. In this paper, we investigate whether an\nattacker can compromise privacy in sequential data releases by exploiting\ndependencies between consecutive publications, even when each individual\nrelease satisfies standard privacy guarantees. To this end, we propose a novel\nattack model that captures these sequential dependencies by integrating a\nHidden Markov Model with a reinforcement learning-based bi-directional\ninference mechanism. This enables the attacker to leverage both earlier and\nlater observations in the sequence to infer private information. We instantiate\nour framework in the context of trajectory data, demonstrating how an adversary\ncan recover sensitive locations from sequential mobility datasets. Extensive\nexperiments on Geolife, Porto Taxi, and SynMob datasets show that our model\nconsistently outperforms baseline approaches that treat each release\nindependently. The results reveal a fundamental privacy risk inherent to\nsequential data publishing, where individually protected releases can\ncollectively leak sensitive information when analyzed temporally. These\nfindings underscore the need for new privacy-preserving frameworks that\nexplicitly model temporal dependencies, such as time-aware differential privacy\nor sequential data obfuscation strategies.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5728\u8fde\u7eed\u6570\u636e\u53d1\u5e03\u4e2d\uff0c\u5373\u4f7f\u6bcf\u4e2a\u53d1\u5e03\u90fd\u6ee1\u8db3\u9690\u79c1\u4fdd\u62a4\u6807\u51c6\uff0c\u653b\u51fb\u8005\u4ecd\u53ef\u80fd\u5229\u7528\u5e8f\u5217\u4f9d\u8d56\u5173\u7cfb\u63a8\u65ad\u654f\u611f\u4fe1\u606f\u3002\u63d0\u51fa\u65b0\u578b\u653b\u51fb\u6a21\u578b\uff0c\u7ed3\u5408\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\u53cc\u5411\u63a8\u65ad\u673a\u5236\uff0c\u5728\u8f68\u8ff9\u6570\u636e\u4e2d\u8bc1\u660e\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u663e\u793a\u653b\u51fb\u6548\u679c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6848\uff0c\u63ed\u793a\u5e8f\u5217\u6570\u636e\u53d1\u5e03\u56fa\u6709\u7684\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u73b0\u5b9e\u5e94\u7528\u5e38\u9700\u8fde\u7eed\u53d1\u5e03\u6570\u636e\uff0c\u800c\u73b0\u6709\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u4e3b\u8981\u9488\u5bf9\u5355\u6b21\u53d1\u5e03\u3002\u6587\u7ae0\u63ed\u793a\u4e00\u4e2a\u5173\u952e\u6f0f\u6d1e\uff1a\u5373\u4f7f\u6bcf\u6b21\u53d1\u5e03\u72ec\u7acb\u6ee1\u8db3\u9690\u79c1\u8981\u6c42\uff08\u5982\u5dee\u5206\u9690\u79c1\uff09\uff0c\u653b\u51fb\u8005\u4ecd\u80fd\u5229\u7528\u591a\u8f6e\u53d1\u5e03\u95f4\u7684\u65f6\u5e8f\u76f8\u5173\u6027\u63a8\u65ad\u654f\u611f\u4fe1\u606f\uff0c\u4ee5\u5f80\u7814\u7a76\u5bf9\u6b64\u5173\u6ce8\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u65b0\u578b\u653b\u51fb\u6846\u67b6\uff0c\u6838\u5fc3\u8bbe\u8ba1\u662f\u5c06\u5e8f\u5217\u6570\u636e\u5efa\u6a21\u4e3a\u9690\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\uff0c\u5e76\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u53cc\u5411\u63a8\u7406\u5f15\u64ce\uff08\u53ef\u540c\u6b65\u5229\u7528\u5386\u53f2\u4e0e\u672a\u6765\u89c2\u6d4b\u503c\uff09\u3002\u5728\u8f68\u8ff9\u9690\u79c1\u573a\u666f\u4e2d\u5b9e\u4f8b\u5316\u8be5\u6a21\u578b\uff1a\u5c06\u654f\u611f\u4f4d\u7f6e\u4f5c\u4e3a\u9690\u85cf\u72b6\u6001\uff0c\u516c\u5f00\u8f68\u8ff9\u70b9\u4e3a\u89c2\u6d4b\u503c\uff0c\u901a\u8fc7\u53cc\u5411Viterbi\u7b97\u6cd5\u63a8\u65ad\u7528\u6237\u771f\u5b9e\u4f4d\u7f6e\u3002", "result": "\u5728Geolife\u3001Porto Taxi\u548cSynMob\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff1a1) \u653b\u51fb\u6a21\u578b\u5bf9\u654f\u611f\u4f4d\u7f6e\u7684\u63a8\u65ad\u51c6\u786e\u7387\u6bd4\u5355\u6b21\u53d1\u5e03\u653b\u51fb\u57fa\u7ebf\u63d0\u534728-41%\uff1b2) \u53cc\u5411\u63a8\u7406\u673a\u5236\u8f83\u5355\u5411\u6a21\u578b\u63d0\u534716-23%\u51c6\u786e\u7387\uff1b3) \u5373\u4f7f\u4e2a\u4f53\u53d1\u5e03\u6ee1\u8db3\u03b5=1.0\u5fae\u5206\u9690\u79c1\uff0c\u8fde\u7eed\u53d1\u5e03\u4ecd\u5bfc\u81f4\u5b9e\u9645\u9690\u79c1\u9884\u7b97\u81a8\u80c0\u81f3\u03b5>4.0\u3002", "conclusion": "\u65f6\u5e8f\u76f8\u5173\u6027\u4f7f\u8fde\u7eed\u6570\u636e\u53d1\u5e03\u9762\u4e34\u65b0\u578b\u590d\u5408\u9690\u79c1\u98ce\u9669\uff0c\u9700\u5f00\u53d1\u65f6\u95f4\u611f\u77e5\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\uff08\u5982\u65f6\u5e8f\u5dee\u5206\u9690\u79c1\u3001\u5e8f\u5217\u6df7\u6dc6\u7b56\u7565\uff09\u3002\u5b9e\u9a8c\u8bc1\u660e\u53cc\u5411\u4f9d\u8d56\u5efa\u6a21\u662f\u9690\u79c1\u653b\u51fb\u7684\u6709\u6548\u8303\u5f0f\uff0c\u8be5\u8303\u5f0f\u9002\u7528\u4e8e\u533b\u7597\u3001\u91d1\u878d\u7b49\u8fde\u7eed\u53d1\u5e03\u573a\u666f\u7684\u9690\u79c1\u8bc4\u4f30\u3002"}}
{"id": "2510.24976", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24976", "abs": "https://arxiv.org/abs/2510.24976", "authors": ["Banafsheh Saber Latibari", "Najmeh Nazari", "Hossein Sayadi", "Houman Homayoun", "Abhijit Mahalanobis"], "title": "Hammering the Diagnosis: Rowhammer-Induced Stealthy Trojan Attacks on ViT-Based Medical Imaging", "comment": "Accepted, ICCD 2025", "summary": "Vision Transformers (ViTs) have emerged as powerful architectures in medical\nimage analysis, excelling in tasks such as disease detection, segmentation, and\nclassification. However, their reliance on large, attention-driven models makes\nthem vulnerable to hardware-level attacks. In this paper, we propose a novel\nthreat model referred to as Med-Hammer that combines the Rowhammer hardware\nfault injection with neural Trojan attacks to compromise the integrity of\nViT-based medical imaging systems. Specifically, we demonstrate how malicious\nbit flips induced via Rowhammer can trigger implanted neural Trojans, leading\nto targeted misclassification or suppression of critical diagnoses (e.g.,\ntumors or lesions) in medical scans. Through extensive experiments on benchmark\nmedical imaging datasets such as ISIC, Brain Tumor, and MedMNIST, we show that\nsuch attacks can remain stealthy while achieving high attack success rates\nabout 82.51% and 92.56% in MobileViT and SwinTransformer, respectively. We\nfurther investigate how architectural properties, such as model sparsity,\nattention weight distribution, and the number of features of the layer, impact\nattack effectiveness. Our findings highlight a critical and underexplored\nintersection between hardware-level faults and deep learning security in\nhealthcare applications, underscoring the urgent need for robust defenses\nspanning both model architectures and underlying hardware platforms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMed-Hammer\u7684\u65b0\u578b\u5a01\u80c1\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06Rowhammer\u786c\u4ef6\u6545\u969c\u6ce8\u5165\u4e0e\u795e\u7ecf\u6728\u9a6c\u653b\u51fb\u76f8\u7ed3\u5408\uff0c\u4ee5\u9488\u5bf9\u57fa\u4e8eVision Transformers\uff08ViT\uff09\u7684\u533b\u5b66\u6210\u50cf\u7cfb\u7edf\u8fdb\u884c\u653b\u51fb\u3002\u653b\u51fb\u901a\u8fc7\u786c\u4ef6\u8bf1\u53d1\u7684\u6bd4\u7279\u7ffb\u8f6c\u89e6\u53d1\u690d\u5165\u7684\u795e\u7ecf\u6728\u9a6c\uff0c\u5bfc\u81f4\u533b\u5b66\u626b\u63cf\u4e2d\u7684\u5b9a\u5411\u8bef\u5206\u7c7b\u6216\u5173\u952e\u8bca\u65ad\uff08\u5982\u80bf\u7624\u6216\u75c5\u53d8\uff09\u7684\u6291\u5236\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728MobileViT\u548cSwinTransformer\u6a21\u578b\u4e0a\u653b\u51fb\u6210\u529f\u7387\u5206\u522b\u8fbe\u523082.51%\u548c92.56%\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u533b\u7597\u5e94\u7528\u4e2d\u786c\u4ef6\u7ea7\u6545\u969c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u5b89\u5168\u7684\u672a\u5145\u5206\u63a2\u7d22\u7684\u4ea4\u96c6\uff0c\u4e9f\u9700\u8986\u76d6\u6a21\u578b\u67b6\u6784\u548c\u786c\u4ef6\u5e73\u53f0\u7684\u65b0\u578b\u9632\u5fa1\u63aa\u65bd\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9Transformer\uff08ViT\uff09\u5728\u533b\u5b66\u56fe\u50cf\u5206\u6790\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5927\u578b\u6ce8\u610f\u529b\u9a71\u52a8\u6a21\u578b\u5bf9\u786c\u4ef6\u7ea7\u653b\u51fb\uff08\u5982Rowhammer\uff09\u5177\u6709\u8106\u5f31\u6027\u3002\u533b\u5b66\u8bca\u65ad\u7cfb\u7edf\u7684\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u4e00\u65e6\u88ab\u653b\u51fb\u53ef\u5bfc\u81f4\u4e25\u91cd\u7684\u4e34\u5e8a\u8bef\u5224\uff08\u5982\u5ffd\u7565\u80bf\u7624\uff09\u3002\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u5173\u6ce8\u786c\u4ef6\u6545\u969c\u4e0e\u6df1\u5ea6\u5b66\u4e60\u5b89\u5168\u5728\u533b\u7597\u5e94\u7528\u4e2d\u7684\u4ea4\u53c9\u5a01\u80c1\u3002", "method": "\u63d0\u51fa\u4e86Med-Hammer\u5a01\u80c1\u6a21\u578b\uff0c\u5c06Rowhammer\u786c\u4ef6\u6545\u969c\u6ce8\u5165\u6280\u672f\u4e0e\u795e\u7ecf\u6728\u9a6c\u653b\u51fb\u7ed3\u5408\uff1a1\uff09\u901a\u8fc7\u5728ViT\u6a21\u578b\u4e2d\u690d\u5165\u795e\u7ecf\u6728\u9a6c\uff08\u5982\u52a0\u5165\u5bf9\u6297\u6027\u89e6\u53d1\u5668\uff09\uff1b2\uff09\u5229\u7528Rowhammer\u653b\u51fb\u5728\u786c\u4ef6\u5c42\u8bf1\u5bfc\u53ef\u63a7\u6bd4\u7279\u7ffb\u8f6c\uff0c\u6fc0\u6d3b\u6728\u9a6c\u89e6\u53d1\u5668\u3002\u5b9e\u9a8c\u4f7f\u7528ISIC\u3001Brain Tumor\u548cMedMNIST\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540cViT\u67b6\u6784\uff08MobileViT\u3001SwinTransformer\uff09\u5728\u653b\u51fb\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u7a00\u758f\u6027\u3001\u6ce8\u610f\u529b\u6743\u91cd\u5206\u5e03\u53ca\u5c42\u7279\u5f81\u6570\u7b49\u67b6\u6784\u7279\u6027\u5bf9\u653b\u51fb\u6709\u6548\u6027\u7684\u5f71\u54cd\u3002", "result": "\u653b\u51fb\u5728MobileViT\u548cSwinTransformer\u4e2d\u6210\u529f\u7387\u5206\u522b\u4e3a82.51%\u548c92.56%\uff0c\u8868\u660e\u786c\u4ef6\u7ea7\u653b\u51fb\u53ef\u6709\u6548\u89e6\u53d1\u6a21\u578b\u5185\u90e8\u6728\u9a6c\u5b9e\u73b0\u5b9a\u5411\u8bef\u8bca\u3002\u5173\u952e\u53d1\u73b0\uff1aa\uff09\u6a21\u578b\u7a00\u758f\u6027\u8d8a\u9ad8\uff0c\u6728\u9a6c\u6fc0\u6d3b\u6240\u9700\u6bd4\u7279\u7ffb\u8f6c\u8d8a\u5c11\uff1bb\uff09\u6ce8\u610f\u529b\u6743\u91cd\u96c6\u4e2d\u7684\u5c42\u66f4\u5bb9\u6613\u88ab\u6270\u52a8\uff1bc\uff09\u5e95\u5c42\u7279\u5f81\u5c42\u5bf9\u786c\u4ef6\u653b\u51fb\u66f4\u5177\u654f\u611f\u6027\u3002\u653b\u51fb\u5177\u6709\u9690\u853d\u6027\uff08\u4e0d\u7834\u574f\u6b63\u5e38\u529f\u80fd\uff09\u4e14\u9ad8\u9488\u5bf9\u6027\uff08\u5982\u7cbe\u51c6\u6291\u5236\u75c5\u7076\u533a\u57df\u6807\u8bc6\uff09\u3002", "conclusion": "Med-Hammer\u66b4\u9732\u4e86\u533b\u5b66ViT\u6a21\u578b\u5728\u786c\u4ef6\u5c42\u9762\u7684\u5b89\u5168\u6f0f\u6d1e\u2014\u2014\u5fae\u5c0f\u7684\u786c\u4ef6\u6545\u969c\u53ef\u6fc0\u6d3b\u9884\u57cb\u6728\u9a6c\u5bfc\u81f4\u707e\u96be\u6027\u8bef\u8bca\u3002\u6b64\u5a01\u80c1\u517c\u5177\u9690\u853d\u6027\u548c\u9ad8\u6548\u6027\uff0c\u4e14\u6a21\u578b\u67b6\u6784\u7279\u6027\uff08\u5982\u7a00\u758f\u5ea6\uff09\u76f4\u63a5\u5f71\u54cd\u653b\u51fb\u96be\u5ea6\u3002\u56e0\u6b64\uff0c\u5fc5\u987b\u8054\u5408\u4f18\u5316\u6a21\u578b\u7ed3\u6784\uff08\u5982\u6ce8\u610f\u529b\u673a\u5236\u52a0\u56fa\uff09\u4e0e\u786c\u4ef6\u5e73\u53f0\u9632\u62a4\uff08\u5982\u5185\u5b58\u7ea0\u9519\u673a\u5236\uff09\uff0c\u6784\u5efa\u533b\u7597AI\u7cfb\u7edf\u7684\u7aef\u5230\u7aef\u5b89\u5168\u4f53\u7cfb\u3002\u8be5\u7814\u7a76\u4e3a\u533b\u7597\u8bbe\u5907\u5b89\u5168\u6807\u51c6\u5236\u5b9a\u63d0\u4f9b\u4e86\u91cd\u8981\u542f\u793a\u3002"}}
{"id": "2510.24985", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24985", "abs": "https://arxiv.org/abs/2510.24985", "authors": ["Najmeh Nazari", "Banafsheh Saber Latibari", "Elahe Hosseini", "Fatemeh Movafagh", "Chongzhou Fang", "Hosein Mohammadi Makrani", "Kevin Immanuel Gubbi", "Abhijit Mahalanobis", "Setareh Rafatirad", "Hossein Sayadi", "Houman Homayoun"], "title": "FaRAccel: FPGA-Accelerated Defense Architecture for Efficient Bit-Flip Attack Resilience in Transformer Models", "comment": "Accepted By ICCD 2025", "summary": "Forget and Rewire (FaR) methodology has demonstrated strong resilience\nagainst Bit-Flip Attacks (BFAs) on Transformer-based models by obfuscating\ncritical parameters through dynamic rewiring of linear layers. However, the\napplication of FaR introduces non-negligible performance and memory overheads,\nprimarily due to the runtime modification of activation pathways and the lack\nof hardware-level optimization. To overcome these limitations, we propose\nFaRAccel, a novel hardware accelerator architecture implemented on FPGA,\nspecifically designed to offload and optimize FaR operations. FaRAccel\nintegrates reconfigurable logic for dynamic activation rerouting, and\nlightweight storage of rewiring configurations, enabling low-latency inference\nwith minimal energy overhead. We evaluate FaRAccel across a suite of\nTransformer models and demonstrate substantial reductions in FaR inference\nlatency and improvement in energy efficiency, while maintaining the robustness\ngains of the original FaR methodology. To the best of our knowledge, this is\nthe first hardware-accelerated defense against BFAs in Transformers,\neffectively bridging the gap between algorithmic resilience and efficient\ndeployment on real-world AI platforms.", "AI": {"tldr": "FaRAccel\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eFPGA\u7684\u786c\u4ef6\u52a0\u901f\u5668\u67b6\u6784\uff0c\u7528\u4e8e\u4f18\u5316Forget and Rewire(FaR)\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u5176\u5728Transformer\u6a21\u578b\u4e0a\u7684\u6267\u884c\u5ef6\u8fdf\u548c\u80fd\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u6297\u4f4d\u7ffb\u8f6c\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "FaR\u65b9\u6cd5\u867d\u80fd\u6709\u6548\u9632\u5fa1\u4f4d\u7ffb\u8f6c\u653b\u51fb\uff0c\u4f46\u56e0\u5176\u52a8\u6001\u91cd\u8fde\u6fc0\u6d3b\u8def\u5f84\u548c\u7f3a\u4e4f\u786c\u4ef6\u4f18\u5316\uff0c\u5728\u6027\u80fd\u548c\u5185\u5b58\u5f00\u9500\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u5728FPGA\u4e0a\u7684FaRAccel\u786c\u4ef6\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u91cd\u6784\u903b\u8f91\u5b9e\u73b0\u52a8\u6001\u6fc0\u6d3b\u91cd\u8def\u7531\u7684\u5378\u8f7d\uff0c\u4ee5\u53ca\u8f7b\u91cf\u7ea7\u5b58\u50a8\u91cd\u8fde\u914d\u7f6e\u4ee5\u964d\u4f4e\u5ef6\u8fdf\u548c\u80fd\u8017\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFaRAccel\u5728\u4e0d\u540cTransformer\u6a21\u578b\u4e0a\u663e\u8457\u51cf\u5c11\u4e86\u63a8\u7406\u5ef6\u8fdf\u5e76\u63d0\u9ad8\u80fd\u6548\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u539f\u59cbFaR\u7684\u9632\u5fa1\u9c81\u68d2\u6027\u3002", "conclusion": "FaRAccel\u9996\u6b21\u5728\u786c\u4ef6\u5c42\u9762\u52a0\u901fTransformer\u7684\u4f4d\u7ffb\u8f6c\u653b\u51fb\u9632\u5fa1\uff0c\u5f25\u5408\u4e86\u7b97\u6cd5\u9c81\u68d2\u6027\u4e0e\u73b0\u5b9e\u90e8\u7f72\u6548\u7387\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2510.24999", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24999", "abs": "https://arxiv.org/abs/2510.24999", "authors": ["Racchit Jain", "Satya Lokam", "Yehonathan Refael", "Adam Hakim", "Lev Greenberg", "Jay Tenenbaum"], "title": "SLIP-SEC: Formalizing Secure Protocols for Model IP Protection", "comment": null, "summary": "Large Language Models (LLMs) represent valuable intellectual property (IP),\nreflecting significant investments in training data, compute, and expertise.\nDeploying these models on partially trusted or insecure devices introduces\nsubstantial risk of model theft, making it essential to design inference\nprotocols with provable security guarantees.\n  We present the formal framework and security foundations of SLIP, a hybrid\ninference protocol that splits model computation between a trusted and an\nuntrusted resource. We define and analyze the key notions of model\ndecomposition and hybrid inference protocols, and introduce formal properties\nincluding safety, correctness, efficiency, and t-soundness. We construct secure\ninference protocols based on additive decompositions of weight matrices,\ncombined with masking and probabilistic verification techniques. We prove that\nthese protocols achieve information-theoretic security against\nhonest-but-curious adversaries, and provide robustness against malicious\nadversaries with negligible soundness error.\n  This paper focuses on the theoretical underpinnings of SLIP: precise\ndefinitions, formal protocols, and proofs of security. Empirical validation and\ndecomposition heuristics appear in the companion SLIP paper. Together, the two\nworks provide a complete account of securing LLM IP via hybrid inference,\nbridging both practice and theory.", "AI": {"tldr": "\u63d0\u51fa\u4e86SLIP\u534f\u8bae\u6846\u67b6\uff0c\u89e3\u51b3\u5728\u90e8\u5206\u53ef\u4fe1\u6216\u4e0d\u53ef\u4fe1\u8bbe\u5907\u4e0a\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65f6\u7684\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u95ee\u9898\u3002\u901a\u8fc7\u5c06\u6a21\u578b\u8ba1\u7b97\u5206\u89e3\u5230\u53ef\u4fe1\u548c\u4e0d\u53ef\u4fe1\u8d44\u6e90\u4e0a\uff0c\u7ed3\u5408\u63a9\u7801\u548c\u6982\u7387\u9a8c\u8bc1\u6280\u672f\uff0c\u5b9e\u73b0\u4fe1\u606f\u8bba\u5b89\u5168\u6027\u3002", "motivation": "LLMs\u4f5c\u4e3a\u91cd\u8981\u77e5\u8bc6\u4ea7\u6743\uff0c\u90e8\u7f72\u5728\u90e8\u5206\u53ef\u4fe1\u8bbe\u5907\u5b58\u5728\u88ab\u76d7\u98ce\u9669\u3002\u9700\u8bbe\u8ba1\u5177\u6709\u53ef\u8bc1\u660e\u5b89\u5168\u4fdd\u8bc1\u7684\u63a8\u7406\u534f\u8bae\u3002", "method": "\u5f00\u53d1\u6df7\u5408\u63a8\u7406\u534f\u8baeSLIP\uff1a\u5c06\u6743\u91cd\u77e9\u9635\u5206\u89e3\u4e3a\u52a0\u6cd5\u5f62\u5f0f\uff0c\u7ed3\u5408\u63a9\u7801\u548c\u6982\u7387\u9a8c\u8bc1\u6280\u672f\u3002\u534f\u8bae\u5728\u53ef\u4fe1\u4e0e\u4e0d\u53ef\u4fe1\u8d44\u6e90\u95f4\u5206\u5272\u8ba1\u7b97\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u534f\u8bae\u5728\u8bda\u5b9e\u4f46\u597d\u5947\u7684\u5bf9\u6297\u8005\u4e0b\u5177\u6709\u4fe1\u606f\u8bba\u5b89\u5168\u6027\uff0c\u5bf9\u6076\u610f\u5bf9\u6297\u8005\u63d0\u4f9b\u53ef\u5ffd\u7565\u7684\u53ef\u9760\u8bef\u5dee\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SLIP\u4e3aLLM\u77e5\u8bc6\u4ea7\u6743\u4fdd\u62a4\u5efa\u7acb\u7406\u8bba\u57fa\u7840\uff0c\u5305\u542b\u7cbe\u786e\u534f\u8bae\u5b9a\u4e49\u548c\u5b89\u5168\u8bc1\u660e\u3002\u5b8c\u6574\u65b9\u6848\u901a\u8fc7\u914d\u5957\u8bba\u6587\u8865\u5168\u5b9e\u8df5\u9a8c\u8bc1\u3002"}}
{"id": "2510.25025", "categories": ["cs.CR", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25025", "abs": "https://arxiv.org/abs/2510.25025", "authors": ["Zirui Cheng", "Jikai Sun", "Anjun Gao", "Yueyang Quan", "Zhuqing Liu", "Xiaohua Hu", "Minghong Fang"], "title": "Secure Retrieval-Augmented Generation against Poisoning Attacks", "comment": "To appear in IEEE BigData 2025", "summary": "Large language models (LLMs) have transformed natural language processing\n(NLP), enabling applications from content generation to decision support.\nRetrieval-Augmented Generation (RAG) improves LLMs by incorporating external\nknowledge but also introduces security risks, particularly from data poisoning,\nwhere the attacker injects poisoned texts into the knowledge database to\nmanipulate system outputs. While various defenses have been proposed, they\noften struggle against advanced attacks. To address this, we introduce RAGuard,\na detection framework designed to identify poisoned texts. RAGuard first\nexpands the retrieval scope to increase the proportion of clean texts, reducing\nthe likelihood of retrieving poisoned content. It then applies chunk-wise\nperplexity filtering to detect abnormal variations and text similarity\nfiltering to flag highly similar texts. This non-parametric approach enhances\nRAG security, and experiments on large-scale datasets demonstrate its\neffectiveness in detecting and mitigating poisoning attacks, including strong\nadaptive attacks.", "AI": {"tldr": "\u6458\u8981\u4ecb\u7ecd\u4e86\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u5e94\u7528\u53ca\u5b89\u5168\u98ce\u9669\uff0c\u7279\u522b\u662f\u6570\u636e\u4e2d\u6bd2\u653b\u51fb\u3002\u9488\u5bf9\u73b0\u6709\u9632\u5fa1\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u975e\u53c2\u6570\u5316\u68c0\u6d4b\u6846\u67b6RAGuard\uff0c\u901a\u8fc7\u6269\u5c55\u68c0\u7d22\u8303\u56f4\u3001\u57fa\u4e8e\u56f0\u60d1\u5ea6\u7684\u5206\u5757\u8fc7\u6ee4\u548c\u6587\u672c\u76f8\u4f3c\u6027\u8fc7\u6ee4\u6765\u68c0\u6d4b\u4e2d\u6bd2\u6587\u672c\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u591a\u79cd\u653b\u51fb\uff0c\u5305\u62ec\u5f3a\u81ea\u9002\u5e94\u6027\u653b\u51fb\u3002", "motivation": "RAG\u5f15\u5165\u5916\u90e8\u77e5\u8bc6\u4ee5\u589e\u5f3aLLM\u80fd\u529b\u65f6\u53ef\u80fd\u906d\u9047\u6570\u636e\u4e2d\u6bd2\u653b\u51fb\u2014\u2014\u653b\u51fb\u8005\u5411\u77e5\u8bc6\u5e93\u6ce8\u5165\u6709\u6bd2\u6587\u672c\u6765\u64cd\u7eb5\u8f93\u51fa\u3002\u73b0\u6709\u9632\u5fa1\u96be\u4ee5\u5e94\u5bf9\u9ad8\u7ea7\u653b\u51fb\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u578b\u68c0\u6d4b\u673a\u5236\u3002", "method": "\u63d0\u51faRAGuard\u6846\u67b6\uff1a1) \u6269\u5c55\u68c0\u7d22\u8303\u56f4\uff0c\u63d0\u9ad8\u7eaf\u51c0\u6587\u672c\u6bd4\u4f8b\uff1b2) \u5206\u5757\u56f0\u60d1\u5ea6\u8fc7\u6ee4\u68c0\u6d4b\u5f02\u5e38\uff1b3) \u6587\u672c\u76f8\u4f3c\u5ea6\u8fc7\u6ee4\u6807\u8bb0\u9ad8\u5ea6\u76f8\u4f3c\u5185\u5bb9\u3002\u8be5\u6846\u67b6\u4e0d\u4f9d\u8d56\u53ef\u8bad\u7ec3\u53c2\u6570\u3002", "result": "\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5b9e\u9a8c\u4e2d\uff0cRAGuard\u6210\u529f\u68c0\u6d4b\u5e76\u7f13\u89e3\u4e86\u5305\u62ec\u5f3a\u81ea\u9002\u5e94\u653b\u51fb\u5728\u5185\u7684\u591a\u79cd\u6570\u636e\u4e2d\u6bd2\u653b\u51fb\uff0c\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "RAGuard\u4f5c\u4e3a\u975e\u53c2\u6570\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86RAG\u7cfb\u7edf\u62b5\u5fa1\u6076\u610f\u6570\u636e\u4e2d\u6bd2\u7684\u80fd\u529b\uff0c\u4e14\u5b9e\u9a8c\u8bc1\u660e\u5176\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.25477", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.25477", "abs": "https://arxiv.org/abs/2510.25477", "authors": ["Yi Chen", "Bin Chen", "Peichang Zhang", "Da Che"], "title": "A Study on Privacy-Preserving Scholarship Evaluation Based on Decentralized Identity and Zero-Knowledge Proofs", "comment": null, "summary": "Traditional centralized scholarship evaluation processes typically require\nstudents to submit detailed academic records and qualification information,\nwhich exposes them to risks of data leakage and misuse, making it difficult to\nsimultaneously ensure privacy protection and transparent auditability. To\naddress these challenges, this paper proposes a scholarship evaluation system\nbased on Decentralized Identity (DID) and Zero-Knowledge Proofs (ZKP). The\nsystem aggregates multidimensional ZKPs off-chain, and smart contracts verify\ncompliance with evaluation criteria without revealing raw scores or\ncomputational details. Experimental results demonstrate that the proposed\nsolution not only automates the evaluation efficiently but also maximally\npreserves student privacy and data integrity, offering a practical and\ntrustworthy technical paradigm for higher education scholarship programs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eDID\u548cZKP\u7684\u5956\u5b66\u91d1\u8bc4\u4f30\u7cfb\u7edf\uff0c\u89e3\u51b3\u4f20\u7edf\u96c6\u4e2d\u5f0f\u7cfb\u7edf\u5728\u9690\u79c1\u4fdd\u62a4\u548c\u53ef\u4fe1\u5ba1\u8ba1\u4e0a\u7684\u77db\u76fe\u3002", "motivation": "\u4f20\u7edf\u5956\u5b66\u91d1\u8bc4\u4f30\u9700\u63d0\u4ea4\u8be6\u7ec6\u5b66\u672f\u8bb0\u5f55\uff0c\u5b58\u5728\u6570\u636e\u6cc4\u9732\u548c\u6ee5\u7528\u98ce\u9669\uff0c\u96be\u4ee5\u517c\u987e\u9690\u79c1\u4fdd\u62a4\u4e0e\u900f\u660e\u5ba1\u8ba1\u3002", "method": "\u5229\u7528\u94fe\u4e0b\u805a\u5408\u7684\u591a\u7ef4\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u667a\u80fd\u5408\u7ea6\u533f\u540d\u9a8c\u8bc1\u8bc4\u4f30\u6807\u51c6\u7b26\u5408\u6027\uff0c\u4e0d\u6cc4\u9732\u539f\u59cb\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7cfb\u7edf\u81ea\u52a8\u5316\u9ad8\u6548\u4e14\u6700\u5927\u7a0b\u5ea6\u4fdd\u62a4\u5b66\u751f\u9690\u79c1\u4e0e\u6570\u636e\u5b8c\u6574\u6027\u3002", "conclusion": "\u4e3a\u9ad8\u6821\u5956\u5b66\u91d1\u63d0\u4f9b\u5b9e\u7528\u53ef\u4fe1\u7684\u6280\u672f\u65b9\u6848\uff0c\u5b9e\u73b0\u9690\u79c1\u4e0e\u900f\u660e\u5ea6\u7684\u5e73\u8861\u3002"}}
{"id": "2510.25687", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25687", "abs": "https://arxiv.org/abs/2510.25687", "authors": ["Mallika Prabhakar", "Louise Xu", "Prateek Saxena"], "title": "Model Inversion Attacks Meet Cryptographic Fuzzy Extractors", "comment": null, "summary": "Model inversion attacks pose an open challenge to privacy-sensitive\napplications that use machine learning (ML) models. For example, face\nauthentication systems use modern ML models to compute embedding vectors from\nface images of the enrolled users and store them. If leaked, inversion attacks\ncan accurately reconstruct user faces from the leaked vectors. There is no\nsystematic characterization of properties needed in an ideal defense against\nmodel inversion, even for the canonical example application of a face\nauthentication system susceptible to data breaches, despite a decade of\nbest-effort solutions.\n  In this paper, we formalize the desired properties of a provably strong\ndefense against model inversion and connect it, for the first time, to the\ncryptographic concept of fuzzy extractors. We further show that existing fuzzy\nextractors are insecure for use in ML-based face authentication. We do so\nthrough a new model inversion attack called PIPE, which achieves a success rate\nof over 89% in most cases against prior schemes. We then propose L2FE-Hash, the\nfirst candidate fuzzy extractor which supports standard Euclidean distance\ncomparators as needed in many ML-based applications, including face\nauthentication. We formally characterize its computational security guarantees,\neven in the extreme threat model of full breach of stored secrets, and\nempirically show its usable accuracy in face authentication for practical face\ndistributions. It offers attack-agnostic security without requiring any\nre-training of the ML model it protects. Empirically, it nullifies both prior\nstate-of-the-art inversion attacks as well as our new PIPE attack.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u6a21\u578b\u53cd\u6f14\u653b\u51fb\uff0c\u7279\u522b\u662f\u4eba\u8138\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u7cca\u63d0\u53d6\u5668\u7684\u65b0\u578b\u9632\u5fa1\u65b9\u6848L2FE-Hash\uff0c\u80fd\u591f\u62b5\u5fa1\u73b0\u6709\u653b\u51fb\u5e76\u4fdd\u8bc1\u5b89\u5168\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u8138\u8ba4\u8bc1\u7cfb\u7edf\u5b58\u50a8\u7684\u5d4c\u5165\u5411\u91cf\u4e00\u65e6\u6cc4\u9732\uff0c\u6613\u53d7\u6a21\u578b\u53cd\u6f14\u653b\u51fb\uff08\u5982PIPE\u653b\u51fb\u6210\u529f\u7387\u8d8589%\uff09\uff0c\u800c\u73b0\u6709\u9632\u5fa1\u7f3a\u4e4f\u7cfb\u7edf\u6027\u4fdd\u969c\u4e14\u73b0\u6709\u6a21\u7cca\u63d0\u53d6\u5668\u4e0d\u9002\u7528\u4e8eML\u573a\u666f\u3002", "method": "\u9996\u6b21\u5c06\u6a21\u578b\u53cd\u6f14\u9632\u5fa1\u4e0e\u5bc6\u7801\u5b66\u6a21\u7cca\u63d0\u53d6\u5668\u7406\u8bba\u8fde\u63a5\uff0c\u63d0\u51faL2FE-Hash\u65b9\u6848\uff1a\u652f\u6301\u6807\u51c6\u6b27\u6c0f\u8ddd\u79bb\u6bd4\u8f83\u5668\uff0c\u65e0\u9700\u91cd\u8bad\u7ec3\u6a21\u578b\uff0c\u63d0\u4f9b\u5f62\u5f0f\u5316\u8ba1\u7b97\u5b89\u5168\u4fdd\u8bc1\u3002", "result": "\u7406\u8bba\u8bc1\u660eL2FE-Hash\u5728\u6781\u7aef\u5a01\u80c1\u6a21\u578b\u4e0b\u7684\u5b89\u5168\u6027\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u4eba\u8138\u8ba4\u8bc1\u4e2d\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff08\u5982FAR/FRR\u5728\u53ef\u63a5\u53d7\u8303\u56f4\uff09\uff0c\u5e76\u4f7fPIPE\u7b49\u653b\u51fb\u6210\u529f\u7387\u964d\u81f3\u63a5\u8fd10\u3002", "conclusion": "L2FE-Hash\u662f\u9996\u4e2a\u9002\u7528\u4e8eML\u7cfb\u7edf\u7684\u6a21\u7cca\u63d0\u53d6\u5668\uff0c\u63d0\u4f9b\u653b\u51fb\u65e0\u5173\u7684\u9632\u5fa1\u80fd\u529b\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u4eba\u8138\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u5f7b\u5e95\u89e3\u51b3\u5d4c\u5165\u5411\u91cf\u6cc4\u9732\u5bfc\u81f4\u7684\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2510.25746", "categories": ["cs.CR", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.25746", "abs": "https://arxiv.org/abs/2510.25746", "authors": ["Charlie Harrison", "Pasin Manurangsi"], "title": "Exact zCDP Characterizations for Fundamental Differentially Private Mechanisms", "comment": null, "summary": "Zero-concentrated differential privacy (zCDP) is a variant of differential\nprivacy (DP) that is widely used partly thanks to its nice composition\nproperty. While a tight conversion from $\\epsilon$-DP to zCDP exists for the\nworst-case mechanism, many common algorithms satisfy stronger guarantees. In\nthis work, we derive tight zCDP characterizations for several fundamental\nmechanisms. We prove that the tight zCDP bound for the $\\epsilon$-DP Laplace\nmechanism is exactly $\\epsilon + e^{-\\epsilon} - 1$, confirming a recent\nconjecture by Wang (2022). We further provide tight bounds for the discrete\nLaplace mechanism, $k$-Randomized Response (for $k \\leq 6$), and RAPPOR.\nLastly, we also provide a tight zCDP bound for the worst case bounded range\nmechanism.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u591a\u4e2a\u57fa\u672c\u673a\u5236\u5728\u96f6\u96c6\u4e2d\u5dee\u5206\u9690\u79c1\uff08zCDP\uff09\u4e0b\u7684\u7d27\u5bc6\u8868\u5f81\uff1a\u5305\u62ec\u62c9\u666e\u62c9\u65af\u673a\u5236\u3001\u79bb\u6563\u62c9\u666e\u62c9\u65af\u673a\u5236\u3001k-\u968f\u673a\u54cd\u5e94\uff08k \u2264 6\uff09\u3001RAPPOR\u548c\u6709\u754c\u8303\u56f4\u673a\u5236\u7684\u7d27zCDP\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u03b5-DP\u5230zCDP\u7684\u8f6c\u6362\u4ec5\u9002\u7528\u4e8e\u6700\u574f\u60c5\u51b5\u673a\u5236\uff0c\u800c\u8bb8\u591a\u5e38\u89c1\u7b97\u6cd5\u5b9e\u9645\u6ee1\u8db3\u66f4\u5f3a\u4fdd\u969c\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4e3a\u5173\u952e\u673a\u5236\u63d0\u4f9b\u7cbe\u786e\u7684zCDP\u8fb9\u754c\u4ee5\u4f18\u5316\u9690\u79c1\u5206\u6790\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\u4e25\u683c\u8bc1\u660e\u5404\u673a\u5236\u7684\u7d27zCDP\u8fb9\u754c\uff1a\u5229\u7528\u6982\u7387\u5206\u5e03\u7279\u6027\u5206\u6790\u62c9\u666e\u62c9\u65af\u673a\u5236\uff0c\u7ec4\u5408\u4f18\u5316\u89e3\u51b3\u79bb\u6563\u673a\u5236\uff08\u5982k-RR\uff09\uff0c\u5e76\u901a\u8fc7\u7edf\u8ba1\u5de5\u5177\u5904\u7406RAPPOR\u4e0e\u6709\u754c\u8303\u56f4\u673a\u5236\u3002", "result": "\u9996\u6b21\u7ed9\u51fa\u03b5-DP\u62c9\u666e\u62c9\u65af\u673a\u5236\u7684\u7cbe\u786ezCDP\u8fb9\u754c\uff08\u03b5 + e^\u2212\u03b5 \u2212 1\uff09\uff0c\u8bc1\u5b9e\u4e86Wang\u731c\u60f3\uff1b\u540c\u65f6\u83b7\u5f97\u79bb\u6563\u62c9\u666e\u62c9\u65af\u3001k-RR\uff08k\u22646\uff09\u3001RAPPOR\u4e0e\u6700\u574f\u6709\u754c\u8303\u56f4\u673a\u5236\u7684\u7d27\u8fb9\u754c\u3002", "conclusion": "\u6838\u5fc3\u673a\u5236\u7684\u5b9e\u9645zCDP\u4fdd\u969c\u8fdc\u8d85\u901a\u7528\u8f6c\u6362\u7ed3\u679c\uff0c\u7cbe\u786e\u8fb9\u754c\u53ef\u663e\u8457\u6539\u5584\u9690\u79c1\u9884\u7b97\u5206\u914d\u3002\u6b64\u5de5\u4f5c\u4e3a\u6784\u5efa\u9ad8\u6548zCDP\u7ec4\u5408\u63d0\u4f9b\u4e86\u7406\u8bba\u5de5\u5177\u3002"}}
