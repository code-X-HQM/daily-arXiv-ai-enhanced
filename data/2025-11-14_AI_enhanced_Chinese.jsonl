{"id": "2511.09582", "categories": ["cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.09582", "abs": "https://arxiv.org/abs/2511.09582", "authors": ["Banhirup Sengupta", "Peenal Gupta", "Souvik Sengupta"], "title": "Revisit to the Bai-Galbraith signature scheme", "comment": null, "summary": "Dilithium is one of the NIST approved lattice-based signature schemes. In this short note we describe the Bai-Galbraith signature scheme proposed in BG14, which differs to Dilithium, due to the fact that there is no public key compression. This lattice-based signature scheme is based on Learning with Errors (LWE).", "AI": {"tldr": "\u672c\u6587\u5bf9\u6bd4\u4e86Dilithium\u7b7e\u540d\u65b9\u6848\u4e0eBG14\u4e2d\u63d0\u51fa\u7684Bai-Galbraith\u7b7e\u540d\u65b9\u6848\uff0c\u5f3a\u8c03\u540e\u8005\u6ca1\u6709\u516c\u94a5\u538b\u7f29\u7684\u7279\u6027\u3002", "motivation": "\u8ba8\u8bbaDilithium\uff08NIST\u6807\u51c6\uff09\u4e0eBai-Galbraith\u7b7e\u540d\u65b9\u6848\u7684\u5dee\u5f02\uff0c\u7279\u522b\u662f\u516c\u94a5\u538b\u7f29\u7684\u7f3a\u5931\u3002", "method": "\u57fa\u4e8eLWE\uff08Learning with Errors\uff09\u7684\u683c\u57fa\u7b7e\u540d\u65b9\u6848\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u540c\u4e8eDilithium\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u5728\u8bbe\u8ba1\u4e2d\u7701\u7565\u4e86\u516c\u94a5\u538b\u7f29\u6b65\u9aa4\u3002", "conclusion": "BG14\u7684Bai-Galbraith\u65b9\u6848\u662f\u65e0\u9700\u516c\u94a5\u538b\u7f29\u7684\u57fa\u4e8eLWE\u7684\u7b7e\u540d\u65b9\u6848\uff0c\u4e3a\u683c\u57fa\u5bc6\u7801\u5b66\u63d0\u4f9b\u4e86\u4e0d\u540c\u8bbe\u8ba1\u601d\u8def\u3002"}}
{"id": "2511.09606", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.09606", "abs": "https://arxiv.org/abs/2511.09606", "authors": ["Fujiao Ji", "Doowon Kim"], "title": "How Can We Effectively Use LLMs for Phishing Detection?: Evaluating the Effectiveness of Large Language Model-based Phishing Detection Models", "comment": null, "summary": "Large language models (LLMs) have emerged as a promising phishing detection mechanism, addressing the limitations of traditional deep learning-based detectors, including poor generalization to previously unseen websites and a lack of interpretability. However, LLMs' effectiveness for phishing detection remains unexplored. This study investigates how to effectively leverage LLMs for phishing detection (including target brand identification) by examining the impact of input modalities (screenshots, logos, HTML, and URLs), temperature settings, and prompt engineering strategies. Using a dataset of 19,131 real-world phishing websites and 243 benign sites, we evaluate seven LLMs -- two commercial models (GPT 4.1 and Gemini 2.0 flash) and five open-source models (Qwen, Llama, Janus, DeepSeek-VL2, and R1) -- alongside two deep learning (DL)-based baselines (PhishIntention and Phishpedia).\n  Our findings reveal that commercial LLMs generally outperform open-source models in phishing detection, while DL models demonstrate better performance on benign samples. For brand identification, screenshot inputs achieve optimal results, with commercial LLMs reaching 93-95% accuracy and open-source models, particularly Qwen, achieving up to 92%. However, incorporating multiple input modalities simultaneously or applying one-shot prompts does not consistently enhance performance and may degrade results. Furthermore, higher temperature values reduce performance. Based on these results, we recommend using screenshot inputs with zero temperature to maximize accuracy for LLM-based detectors with HTML serving as auxiliary context when screenshot information is insufficient.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u5982\u4f55\u6709\u6548\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u9493\u9c7c\u7f51\u7ad9\u68c0\u6d4b\uff0c\u6bd4\u8f83\u4e86\u5546\u4e1a\u4e0e\u5f00\u6e90LLMs\u5728\u591a\u79cd\u8f93\u5165\u6a21\u6001\u4e0b\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u622a\u56fe\u8f93\u5165\u914d\u5408\u96f6\u6e29\u5ea6\u8bbe\u7f6e\u6548\u679c\u6700\u4f73\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u9493\u9c7c\u68c0\u6d4b\u5668\u6cdb\u5316\u80fd\u529b\u5dee\u3001\u7f3a\u4e4f\u89e3\u91ca\u6027\u7684\u95ee\u9898\uff0c\u5e76\u586b\u8865LLMs\u5728\u9493\u9c7c\u68c0\u6d4b\u9886\u57df\u6548\u679c\u8bc4\u4f30\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u8f93\u5165\u6a21\u6001\uff08\u622a\u56fe/Logo/HTML/URL\uff09\u3001\u6e29\u5ea6\u8bbe\u7f6e\u548c\u63d0\u793a\u7b56\u7565\uff0c\u572819,131\u4e2a\u9493\u9c7c\u7f51\u7ad9\u548c243\u4e2a\u826f\u6027\u7f51\u7ad9\u7684\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f307\u79cdLLM\uff08\u542b\u5546\u4e1a/\u5f00\u6e90\u6a21\u578b\uff09\u548c2\u4e2a\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "1) \u5546\u4e1aLLMs\u5728\u9493\u9c7c\u68c0\u6d4b\u4e2d\u6574\u4f53\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u4f46\u4f20\u7edfDL\u6a21\u578b\u5bf9\u826f\u6027\u6837\u672c\u8bc6\u522b\u66f4\u4f18\uff1b2) \u54c1\u724c\u8bc6\u522b\u4efb\u52a1\u4e2d\u622a\u56fe\u8f93\u5165\u6548\u679c\u6700\u4f73\uff0c\u5546\u4e1a\u6a21\u578b\u8fbe93-95%\uff0c\u5f00\u6e90Qwen\u6a21\u578b\u6700\u9ad892%\uff1b3) \u591a\u6a21\u6001\u8f93\u5165\u6216\u5c11\u6837\u672c\u63d0\u793a\u7b56\u7565\u65e0\u663e\u8457\u63d0\u5347\u751a\u81f3\u8d1f\u9762\u4f5c\u7528\uff1b4) \u8f83\u9ad8\u6e29\u5ea6\u503c\u4f7f\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u5efa\u8bae\u91c7\u7528\u622a\u56fe+\u96f6\u6e29\u5ea6\u8bbe\u7f6e\u6784\u5efaLLM\u9493\u9c7c\u68c0\u6d4b\u5668\uff0cHTML\u4f5c\u4e3a\u622a\u56fe\u4fe1\u606f\u4e0d\u8db3\u7684\u8865\u5145\uff1b\u8bc1\u5b9e\u4e86LLMs\u5728\u9493\u9c7c\u68c0\u6d4b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u4f46\u6027\u80fd\u548c\u8f93\u5165\u6a21\u6001\u9009\u62e9\u9ad8\u5ea6\u76f8\u5173\u3002"}}
{"id": "2511.09696", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.09696", "abs": "https://arxiv.org/abs/2511.09696", "authors": ["Bikash Chandra Singh", "Md Jakir Hossain", "Rafael Diaz", "Sandip Roy", "Ravi Mukkamala", "Sachin Shetty"], "title": "Cooperative Local Differential Privacy: Securing Time Series Data in Distributed Environments", "comment": null, "summary": "The rapid growth of smart devices such as phones, wearables, IoT sensors, and connected vehicles has led to an explosion of continuous time series data that offers valuable insights in healthcare, transportation, and more. However, this surge raises significant privacy concerns, as sensitive patterns can reveal personal details. While traditional differential privacy (DP) relies on trusted servers, local differential privacy (LDP) enables users to perturb their own data. However, traditional LDP methods perturb time series data by adding user-specific noise but exhibit vulnerabilities. For instance, noise applied within fixed time windows can be canceled during aggregation (e.g., averaging), enabling adversaries to infer individual statistics over time, thereby eroding privacy guarantees.\n  To address these issues, we introduce a Cooperative Local Differential Privacy (CLDP) mechanism that enhances privacy by distributing noise vectors across multiple users. In our approach, noise is collaboratively generated and assigned so that when all users' perturbed data is aggregated, the noise cancels out preserving overall statistical properties while protecting individual privacy. This cooperative strategy not only counters vulnerabilities inherent in time-window-based methods but also scales effectively for large, real-time datasets, striking a better balance between data utility and privacy in multiuser environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u534f\u4f5c\u5f0f\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08CLDP\uff09\u673a\u5236\uff0c\u901a\u8fc7\u5728\u591a\u7528\u6237\u95f4\u5206\u914d\u566a\u58f0\u5411\u91cf\u6765\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u786e\u4fdd\u805a\u5408\u540e\u566a\u58f0\u62b5\u6d88\u4ee5\u4fdd\u6301\u6570\u636e\u7edf\u8ba1\u7279\u6027\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u8bbe\u5907\u7684\u666e\u53ca\uff0c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u6fc0\u589e\u5f15\u53d1\u4e86\u9690\u79c1\u62c5\u5fe7\u3002\u4f20\u7edf\u672c\u5730\u5dee\u5206\u9690\u79c1\uff08LDP\uff09\u65b9\u6cd5\u5728\u56fa\u5b9a\u65f6\u95f4\u7a97\u53e3\u5185\u6dfb\u52a0\u7528\u6237\u7279\u5b9a\u566a\u58f0\uff0c\u4f46\u5b58\u5728\u6f0f\u6d1e\uff1a\u805a\u5408\u8fc7\u7a0b\u53ef\u80fd\u62b5\u6d88\u566a\u58f0\u5bfc\u81f4\u9690\u79c1\u6cc4\u9732\u3002", "method": "CLDP\u673a\u5236\u91c7\u7528\u534f\u4f5c\u5f0f\u566a\u58f0\u751f\u6210\u4e0e\u5206\u914d\u7b56\u7565\uff1a\u591a\u4e2a\u7528\u6237\u5171\u540c\u751f\u6210\u566a\u58f0\u5411\u91cf\u5e76\u5206\u914d\u5230\u5404\u81ea\u6570\u636e\u4e0a\uff0c\u4f7f\u5f97\u805a\u5408\u65f6\u7528\u6237\u95f4\u566a\u58f0\u76f8\u4e92\u62b5\u6d88\uff0c\u4ece\u800c\u5728\u4e0d\u5f71\u54cd\u6574\u4f53\u7edf\u8ba1\u7279\u6027\u7684\u524d\u63d0\u4e0b\u4fdd\u62a4\u4e2a\u4f53\u9690\u79c1\u3002", "result": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u4e8e\u65f6\u95f4\u7a97\u53e3\u7684\u4f20\u7edfLDP\u65b9\u6cd5\u7684\u6f0f\u6d1e\uff0c\u80fd\u591f\u9002\u5e94\u5927\u89c4\u6a21\u5b9e\u65f6\u6570\u636e\u96c6\uff0c\u5728\u591a\u7528\u6237\u73af\u5883\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u6570\u636e\u6548\u7528\u4e0e\u9690\u79c1\u5e73\u8861\u3002", "conclusion": "\u534f\u4f5c\u5f0f\u566a\u58f0\u5206\u914d\u673a\u5236\u4e3a\u65f6\u5e8f\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u9700\u8981\u5b9e\u65f6\u805a\u5408\u5206\u6790\u7684\u573a\u666f\u3002"}}
{"id": "2511.09775", "categories": ["cs.CR", "cs.AI", "cs.IT", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.09775", "abs": "https://arxiv.org/abs/2511.09775", "authors": ["Dilli Prasad Sharma", "Xiaowei Sun", "Liang Xue", "Xiaodong Lin", "Pulei Xiong"], "title": "Privacy-Preserving Explainable AIoT Application via SHAP Entropy Regularization", "comment": null, "summary": "The widespread integration of Artificial Intelligence of Things (AIoT) in smart home environments has amplified the demand for transparent and interpretable machine learning models. To foster user trust and comply with emerging regulatory frameworks, the Explainable AI (XAI) methods, particularly post-hoc techniques such as SHapley Additive exPlanations (SHAP), and Local Interpretable Model-Agnostic Explanations (LIME), are widely employed to elucidate model behavior. However, recent studies have shown that these explanation methods can inadvertently expose sensitive user attributes and behavioral patterns, thereby introducing new privacy risks. To address these concerns, we propose a novel privacy-preserving approach based on SHAP entropy regularization to mitigate privacy leakage in explainable AIoT applications. Our method incorporates an entropy-based regularization objective that penalizes low-entropy SHAP attribution distributions during training, promoting a more uniform spread of feature contributions. To evaluate the effectiveness of our approach, we developed a suite of SHAP-based privacy attacks that strategically leverage model explanation outputs to infer sensitive information. We validate our method through comparative evaluations using these attacks alongside utility metrics on benchmark smart home energy consumption datasets. Experimental results demonstrate that SHAP entropy regularization substantially reduces privacy leakage compared to baseline models, while maintaining high predictive accuracy and faithful explanation fidelity. This work contributes to the development of privacy-preserving explainable AI techniques for secure and trustworthy AIoT applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eSHAP\u71b5\u6b63\u5219\u5316\u7684\u9690\u79c1\u4fdd\u62a4\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u5c11\u53ef\u89e3\u91caAIoT\u5e94\u7528\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002\u901a\u8fc7\u5f15\u5165\u71b5\u6b63\u5219\u5316\u76ee\u6807\uff0c\u8be5\u65b9\u6cd5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u60e9\u7f5a\u4f4e\u71b5SHAP\u5206\u5e03\uff0c\u4f7f\u7279\u5f81\u8d21\u732e\u66f4\u5747\u5300\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\u548c\u89e3\u91ca\u5fe0\u5b9e\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u9690\u79c1\u6cc4\u9732\u3002", "motivation": "\u968f\u7740AIoT\u5728\u667a\u80fd\u5bb6\u5c45\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u53ef\u89e3\u91caAI\u65b9\u6cd5\uff08\u5982SHAP\u3001LIME\uff09\u88ab\u5927\u91cf\u91c7\u7528\u4ee5\u589e\u5f3a\u900f\u660e\u5ea6\u3002\u7136\u800c\u8fd9\u4e9b\u89e3\u91ca\u65b9\u6cd5\u5bb9\u6613\u66b4\u9732\u654f\u611f\u7528\u6237\u4fe1\u606f\uff0c\u5bfc\u81f4\u65b0\u7684\u9690\u79c1\u98ce\u9669\u3002\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u53c8\u80fd\u4fdd\u62a4\u9690\u79c1\u7684\u6280\u672f\u3002", "method": "1. \u63d0\u51faSHAP\u71b5\u6b63\u5219\u5316\u65b9\u6cd5\uff1a\u5728\u6a21\u578b\u8bad\u7ec3\u4e2d\u5f15\u5165\u71b5\u6b63\u5219\u5316\u76ee\u6807\u51fd\u6570\uff0c\u60e9\u7f5a\u4f4e\u71b5SHAP\u5206\u5e03\uff0c\u4f7f\u7279\u5f81\u8d21\u732e\u5206\u5e03\u66f4\u5747\u5300\uff1b2. \u8bbe\u8ba1\u57fa\u4e8eSHAP\u7684\u9690\u79c1\u653b\u51fb\u5957\u4ef6\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\uff1b3. \u5728\u667a\u80fd\u5bb6\u5c45\u80fd\u8017\u6570\u636e\u96c6\u4e0a\u6bd4\u8f83\u9690\u79c1\u6cc4\u9732\u7a0b\u5ea6\u548c\u6a21\u578b\u6548\u7528\u6307\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1. \u6240\u63d0\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u57fa\u7ebf\u6a21\u578b\u7684\u9690\u79c1\u6cc4\u9732\uff08\u5177\u4f53\u653b\u51fb\u6210\u529f\u7387\u4e0b\u964d\uff09\uff1b2. \u5728\u9884\u6d4b\u51c6\u786e\u5ea6\uff08\u5982MSE/RMSE\u7b49\u6307\u6807\uff09\u548c\u89e3\u91ca\u5fe0\u5b9e\u5ea6\uff08\u5982\u7279\u5f81\u6743\u91cd\u5206\u5e03\u5747\u5300\u6027\uff09\u65b9\u9762\u4e0e\u57fa\u7ebf\u4fdd\u6301\u76f8\u5f53\uff1b3. \u9a8c\u8bc1\u4e86\u71b5\u6b63\u5219\u5316\u5bf9\u4fdd\u62a4\u654f\u611f\u5c5e\u6027\u7684\u6709\u6548\u6027\u3002", "conclusion": "SHAP\u71b5\u6b63\u5219\u5316\u662f\u4e00\u79cd\u6709\u6548\u7684\u9690\u79c1\u4fdd\u62a4\u53ef\u89e3\u91caAI\u65b9\u6cd5\uff0c\u80fd\u5728\u7ef4\u6301\u6a21\u578b\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u89e3\u91ca\u8fc7\u7a0b\u7684\u4fe1\u606f\u6cc4\u9732\u3002\u8be5\u6280\u672f\u6709\u52a9\u4e8e\u6784\u5efa\u5b89\u5168\u53ef\u9760\u7684AIoT\u7cfb\u7edf\uff0c\u672a\u6765\u53ef\u62d3\u5c55\u81f3\u5176\u4ed6\u89e3\u91ca\u65b9\u6cd5\uff08\u5982LIME\uff09\u548c\u573a\u666f\uff08\u5982\u533b\u7597/\u91d1\u878d\uff09\u3002"}}
{"id": "2511.09876", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.09876", "abs": "https://arxiv.org/abs/2511.09876", "authors": ["Shuo Shi", "Jinghuai Zhang", "Shijie Jiang", "Chunyi Zhou", "Yuyuan Li", "Mengying Zhu", "Yangyang Wu", "Tianyu Du"], "title": "DP-GENG : Differentially Private Dataset Distillation Guided by DP-Generated Data", "comment": "14 pages, 9 figures, published in AAAI 2026", "summary": "Dataset distillation (DD) compresses large datasets into smaller ones while preserving the performance of models trained on them. Although DD is often assumed to enhance data privacy by aggregating over individual examples, recent studies reveal that standard DD can still leak sensitive information from the original dataset due to the lack of formal privacy guarantees. Existing differentially private (DP)-DD methods attempt to mitigate this risk by injecting noise into the distillation process. However, they often fail to fully leverage the original dataset, resulting in degraded realism and utility. This paper introduces \\libn, a novel framework that addresses the key limitations of current DP-DD by leveraging DP-generated data. Specifically, \\lib initializes the distilled dataset with DP-generated data to enhance realism. Then, generated data refines the DP-feature matching technique to distill the original dataset under a small privacy budget, and trains an expert model to align the distilled examples with their class distribution. Furthermore, we design a privacy budget allocation strategy to determine budget consumption across DP components and provide a theoretical analysis of the overall privacy guarantees. Extensive experiments show that \\lib significantly outperforms state-of-the-art DP-DD methods in terms of both dataset utility and robustness against membership inference attacks, establishing a new paradigm for privacy-preserving dataset distillation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u79c1\u6709\u4fdd\u62a4\u6570\u636e\u96c6\u84b8\u998f\u6846\u67b6LibN\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u751f\u6210\u7684\u6570\u636e\u89e3\u51b3\u4e86\u73b0\u6709DP-DD\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u901a\u8fc7DP\u751f\u6210\u7684\u6570\u636e\u521d\u59cb\u5316\u84b8\u998f\u6570\u636e\u96c6\u4ee5\u589e\u5f3a\u771f\u5b9e\u611f\uff0c\u7136\u540e\u57fa\u4e8eDP\u7279\u5f81\u5339\u914d\u6280\u672f\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u8fdb\u884c\u84b8\u998f\uff0c\u540c\u65f6\u8bad\u7ec3\u4e00\u4e2a\u4e13\u5bb6\u6a21\u578b\u4ee5\u5bf9\u9f50\u84b8\u998f\u6837\u672c\u7684\u7c7b\u522b\u5206\u5e03\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u5176\u663e\u8457\u8d85\u8d8a\u4e86\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "motivation": "\u57fa\u4e8e\u73b0\u6709\u5dee\u5206\u9690\u79c1\u6570\u636e\u96c6\u84b8\u998f\u65b9\u6cd5\u5728\u5904\u7406\u539f\u59cb\u6570\u636e\u65f6\u6548\u7387\u4f4e\u4e0b\u3001\u5b9e\u7528\u6027\u5dee\u4ee5\u53ca\u6613\u6cc4\u9732\u9690\u79c1\u7684\u95ee\u9898\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u63d0\u9ad8\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u548c\u6570\u636e\u5b9e\u7528\u6027\uff0c\u540c\u65f6\u62b5\u5fa1\u6210\u5458\u63a8\u7406\u653b\u51fb\u3002", "method": "1. \u4f7f\u7528DP\u751f\u6210\u7684\u6570\u636e\u521d\u59cb\u5316\u84b8\u998f\u6570\u636e\u96c6\u4ee5\u589e\u5f3a\u771f\u5b9e\u6027\u30022. \u8bbe\u8ba1\u4e00\u79cd\u6539\u8fdb\u7684DP\u7279\u5f81\u5339\u914d\u6280\u672f\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u5728\u5c0f\u7684\u9690\u79c1\u9884\u7b97\u4e0b\u8fdb\u884c\u84b8\u998f\u30023. \u8bad\u7ec3\u4e13\u5bb6\u6a21\u578b\u4ee5\u5bf9\u9f50\u84b8\u998f\u6837\u672c\u7684\u7c7b\u522b\u5206\u5e03\u30024. \u91c7\u7528\u9690\u79c1\u9884\u7b97\u5206\u914d\u7b56\u7565\u4f18\u5316DP\u7ec4\u4ef6\u4e4b\u95f4\u7684\u9884\u7b97\u6d88\u8017\u3002", "result": "\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\uff0cLibN\u5728\u6570\u636e\u96c6\u5b9e\u7528\u6027\u548c\u5bf9\u6297\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u9762\u7684\u9c81\u68d2\u6027\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684DP-DD\u65b9\u6cd5\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u6570\u636e\u96c6\u84b8\u998f\u5efa\u7acb\u4e86\u65b0\u7684\u8303\u5f0f\u3002", "conclusion": "LibN\u901a\u8fc7\u5de7\u5999\u6574\u5408DP\u751f\u6210\u7684\u6570\u636e\u548c\u4f18\u5316\u7684\u8bad\u7ec3\u3001\u9884\u7b97\u7b56\u7565\uff0c\u6210\u529f\u5730\u63d0\u5347\u4e86\u6570\u636e\u96c6\u84b8\u998f\u7684\u5b9e\u7528\u6027\u548c\u9690\u79c1\u4fdd\u62a4\u6548\u679c\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u4fe1\u606f\u6cc4\u9732\u98ce\u9669\uff0c\u4e3a\u89e3\u51b3DP-DD\u7684\u5b9e\u9645\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.09879", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09879", "abs": "https://arxiv.org/abs/2511.09879", "authors": ["Catherine Xia", "Manar H. Alalfi"], "title": "Taught by the Flawed: How Dataset Insecurity Breeds Vulnerable AI Code", "comment": null, "summary": "AI programming assistants have demonstrated a tendency to generate code containing basic security vulnerabilities. While developers are ultimately responsible for validating and reviewing such outputs, improving the inherent quality of these generated code snippets remains essential. A key contributing factor to insecure outputs is the presence of vulnerabilities in the training datasets used to build large language models (LLMs). To address this issue, we propose curating training data to include only code that is free from detectable vulnerabilities. In this study, we constructed a secure dataset by filtering an existing Python corpus using a static analysis tool to retain only vulnerability-free functions. We then trained two transformer-based models: one on the curated dataset and one on the original, unfiltered dataset. The models were evaluated on both the correctness and security of the code they generated in response to natural language function descriptions. Our results show that the model trained on the curated dataset produced outputs with fewer security issues, while maintaining comparable functional correctness. These findings highlight the importance of secure training data in improving the reliability of AI-based programming assistants, though further enhancements to model architecture and evaluation are needed to reinforce these outcomes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u7b5b\u9009\u65e0\u6f0f\u6d1e\u7684\u4ee3\u7801\u6765\u6784\u5efa\u5b89\u5168\u8bad\u7ec3\u96c6\uff0c\u4ee5\u63d0\u5347AI\u7f16\u7a0b\u52a9\u624b\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4fdd\u6301\u529f\u80fd\u6b63\u786e\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u5b89\u5168\u95ee\u9898\u3002", "motivation": "\u73b0\u6709AI\u7f16\u7a0b\u52a9\u624b\u751f\u6210\u7684\u4ee3\u7801\u5e38\u542b\u57fa\u7840\u5b89\u5168\u6f0f\u6d1e\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u4e3b\u8981\u6e90\u4e8e\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u7684\u6f0f\u6d1e\u4ee3\u7801\u3002\u56e0\u6b64\uff0c\u9700\u6784\u5efa\u65e0\u6f0f\u6d1e\u7684\u9ad8\u8d28\u91cf\u8bad\u7ec3\u96c6\u6765\u63d0\u5347\u751f\u6210\u4ee3\u7801\u7684\u5b89\u5168\u53ef\u9760\u6027\u3002", "method": "1. \u4f7f\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\u7b5b\u9009\u73b0\u6709Python\u4ee3\u7801\u5e93\uff0c\u6784\u5efa\u4ec5\u542b\u65e0\u6f0f\u6d1e\u51fd\u6570\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff1b2. \u5206\u522b\u7528\u539f\u59cb\u6570\u636e\u96c6\u548c\u7b5b\u9009\u6570\u636e\u96c6\u8bad\u7ec3\u4e24\u4e2aTransformer\u6a21\u578b\uff1b3. \u5bf9\u6bd4\u8bc4\u4f30\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u3002", "result": "\u4f7f\u7528\u5b89\u5168\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u751f\u6210\u4ee3\u7801\u65f6\u8868\u73b0\u51fa\uff1a1. \u5b89\u5168\u6027\u663e\u8457\u63d0\u5347\uff08\u6f0f\u6d1e\u6570\u91cf\u51cf\u5c11\uff09\uff1b2. \u529f\u80fd\u6b63\u786e\u6027\u4e0e\u539f\u59cb\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u5b89\u5168\u8bad\u7ec3\u6570\u636e\u5bf9\u63d0\u5347AI\u7f16\u7a0b\u52a9\u624b\u53ef\u9760\u6027\u7684\u5173\u952e\u4f5c\u7528\u3002\u672a\u6765\u9700\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u67b6\u6784\u4e0e\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u5f3a\u5316\u8be5\u6548\u679c\u3002"}}
{"id": "2511.10050", "categories": ["cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.10050", "abs": "https://arxiv.org/abs/2511.10050", "authors": ["Go Tsuruoka", "Takami Sato", "Qi Alfred Chen", "Kazuki Nomoto", "Ryunosuke Kobayashi", "Yuna Tanaka", "Tatsuya Mori"], "title": "Trapped by Their Own Light: Deployable and Stealth Retroreflective Patch Attacks on Traffic Sign Recognition Systems", "comment": null, "summary": "Traffic sign recognition plays a critical role in ensuring safe and efficient transportation of autonomous vehicles but remain vulnerable to adversarial attacks using stickers or laser projections. While existing attack vectors demonstrate security concerns, they suffer from visual detectability or implementation constraints, suggesting unexplored vulnerability surfaces in TSR systems. We introduce the Adversarial Retroreflective Patch (ARP), a novel attack vector that combines the high deployability of patch attacks with the stealthiness of laser projections by utilizing retroreflective materials activated only under victim headlight illumination. We develop a retroreflection simulation method and employ black-box optimization to maximize attack effectiveness. ARP achieves $\\geq$93.4\\% success rate in dynamic scenarios at 35 meters and $\\geq$60\\% success rate against commercial TSR systems in real-world conditions. Our user study demonstrates that ARP attacks maintain near-identical stealthiness to benign signs while achieving $\\geq$1.9\\% higher stealthiness scores than previous patch attacks. We propose the DPR Shield defense, employing strategically placed polarized filters, which achieves $\\geq$75\\% defense success rates for stop signs and speed limit signs against micro-prism patches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u5bf9\u6297\u6027\u653b\u51fb\u65b9\u6cd5\u2014\u2014\u5bf9\u6297\u6027\u9006\u5411\u53cd\u5c04\u8d34\u7247(ARP)\uff0c\u5229\u7528\u9006\u5411\u53cd\u5c04\u6750\u6599\u4ec5\u5728\u53d7\u5bb3\u8005\u8f66\u706f\u7167\u660e\u4e0b\u6fc0\u6d3b\u7684\u7279\u6027\uff0c\u7ed3\u5408\u8d34\u7247\u653b\u51fb\u7684\u9ad8\u90e8\u7f72\u6027\u548c\u6fc0\u5149\u6295\u5f71\u7684\u9690\u853d\u6027\u3002\u901a\u8fc7\u5f00\u53d1\u9006\u5411\u53cd\u5c04\u6a21\u62df\u65b9\u6cd5\u548c\u9ed1\u76d2\u4f18\u5316\uff0cARP\u5728\u52a8\u6001\u573a\u666f\u4e0b\u6210\u529f\u7387\u8fbe\u523093.4%\u4ee5\u4e0a\uff0c\u5e76\u5728\u73b0\u5b9e\u6761\u4ef6\u4e0b\u5bf9\u5546\u4e1a\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u7cfb\u7edf\u7684\u653b\u51fb\u6210\u529f\u7387\u8d8560%\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u91c7\u7528\u504f\u632f\u6ee4\u6ce2\u5668\u7684DPR Shield\u9632\u5fa1\u65b9\u6848\uff0c\u5bf9\u505c\u6b62\u6807\u5fd7\u548c\u9650\u901f\u6807\u5fd7\u7684\u9632\u5fa1\u6210\u529f\u7387\u8d85\u8fc775%\u3002", "motivation": "\u73b0\u6709\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u5728\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u7cfb\u7edf\u4e2d\u5b58\u5728\u89c6\u89c9\u53ef\u68c0\u6d4b\u6027\u6216\u5b9e\u65bd\u9650\u5236\u95ee\u9898\u3002\u4e3a\u63a2\u7d22\u5c1a\u672a\u88ab\u53d1\u73b0\u7684\u7cfb\u7edf\u6f0f\u6d1e\uff0c\u7ed3\u5408\u8d34\u7247\u653b\u51fb\u7684\u6613\u90e8\u7f72\u6027\u548c\u6fc0\u5149\u6295\u5f71\u7684\u9690\u853d\u6027\u4f18\u52bf\uff0c\u63d0\u51fa\u57fa\u4e8e\u9006\u5411\u53cd\u5c04\u6750\u6599\u7684\u653b\u51fb\u5411\u91cf\u3002", "method": "1) \u5229\u7528\u4ec5\u5728\u8f66\u8f86\u5934\u706f\u7167\u5c04\u4e0b\u6fc0\u6d3b\u7684\u9006\u5411\u53cd\u5c04\u6750\u6599\u5236\u4f5c\u653b\u51fb\u8d34\u7247\uff1b2) \u5f00\u53d1\u9006\u5411\u53cd\u5c04\u6a21\u62df\u65b9\u6cd5\uff1b3) \u91c7\u7528\u9ed1\u76d2\u4f18\u5316\u63d0\u5347\u653b\u51fb\u6548\u679c\uff1b4) \u9488\u5bf9\u653b\u51fb\u63d0\u51fa\u57fa\u4e8e\u504f\u632f\u6ee4\u6ce2\u5668\u7684DPR Shield\u9632\u5fa1\u65b9\u6848\u3002", "result": "1) \u52a8\u6001\u573a\u666f35\u7c73\u8ddd\u79bb\u653b\u51fb\u6210\u529f\u7387\u226593.4%\uff1b2) \u73b0\u5b9e\u5546\u4e1a\u7cfb\u7edf\u653b\u51fb\u6210\u529f\u7387\u226560%\uff1b3) \u9690\u853d\u6027\u8bc4\u5206\u6bd4\u4f20\u7edf\u8d34\u7247\u653b\u51fb\u9ad8\u22651.9%\uff1b4) DPR\u9632\u5fa1\u65b9\u6848\u5bf9\u7279\u5b9a\u6807\u5fd7\u7684\u9632\u5fa1\u6210\u529f\u7387\u226575%\u3002", "conclusion": "ARP\u653b\u51fb\u65b9\u6cd5\u6709\u6548\u7ed3\u5408\u9690\u853d\u6027\u548c\u53ef\u90e8\u7f72\u6027\uff0c\u663e\u8457\u63d0\u5347\u653b\u51fb\u6548\u679c\uff1b\u540c\u65f6\u63d0\u51fa\u7684\u504f\u632f\u6ee4\u6ce2\u5668\u9632\u5fa1\u65b9\u6848\u80fd\u6709\u6548\u51cf\u8f7b\u6b64\u7c7b\u653b\u51fb\u98ce\u9669\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u5b89\u5168\u63d0\u4f9b\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.10265", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.10265", "abs": "https://arxiv.org/abs/2511.10265", "authors": ["Tomasz Truderung"], "title": "Enhanced Anonymous Credentials for E-Voting Systems", "comment": null, "summary": "A simple and practical method for achieving everlasting privacy in e-voting systems, without relying on advanced cryptographic techniques, is to use anonymous voter credentials. The simplicity of this approach may, however, create some challenges, when combined with other security features, such as cast-as-intended verifiability with second device and second-factor authentication.\n  This paper considers a simple augmentation to the anonymous credential mechanism, using perfectly hiding commitments to link such credentials to the voter identities. This solution strengthens the binding between voters and their credentials while preserving everlasting privacy. It ensures that published ballots remain unlinkable to voter identities, yet enables necessary consistency checks during ballot casting and ballot auditing", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b8c\u7f8e\u9690\u85cf\u627f\u8bfa\u7684\u533f\u540d\u51ed\u8bc1\u673a\u5236\uff0c\u5728\u7535\u5b50\u6295\u7968\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u6301\u4e45\u9690\u79c1\uff0c\u540c\u65f6\u652f\u6301\u5f3a\u5236\u9a8c\u8bc1\u548c\u4e00\u81f4\u6027\u68c0\u67e5\u3002", "motivation": "\u73b0\u6709\u533f\u540d\u51ed\u8bc1\u65b9\u6cd5\u5728\u7ed3\u5408\u5176\u4ed6\u5b89\u5168\u7279\u6027\uff08\u5982\u7b2c\u4e8c\u8bbe\u5907\u9a8c\u8bc1\uff09\u65f6\u53ef\u80fd\u9762\u4e34\u6311\u6218\uff0c\u9700\u5f3a\u5316\u9009\u6c11\u4e0e\u51ed\u8bc1\u7684\u7ed1\u5b9a\u4e14\u4e0d\u727a\u7272\u9690\u79c1\u3002", "method": "\u5728\u533f\u540d\u51ed\u8bc1\u673a\u5236\u4e2d\u6dfb\u52a0\u5b8c\u7f8e\u9690\u85cf\u627f\u8bfa\uff0c\u5c06\u51ed\u8bc1\u4e0e\u9009\u6c11\u8eab\u4efd\u5b89\u5168\u5173\u8054\uff0c\u65e2\u4fdd\u6301\u4e0d\u53ef\u94fe\u63a5\u6027\u53c8\u652f\u6301\u5ba1\u8ba1\u6240\u9700\u7684\u4e00\u81f4\u6027\u9a8c\u8bc1\u3002", "result": "\u65b9\u6848\u5728\u4fdd\u7559\u9009\u7968\u4e0e\u8eab\u4efd\u6c38\u4e45\u4e0d\u53ef\u94fe\u63a5\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u4f7f\u7cfb\u7edf\u80fd\u6267\u884c\u5f3a\u5236\u6295\u7968\u9a8c\u8bc1\u548c\u5ba1\u8ba1\u9636\u6bb5\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u3002", "conclusion": "\u5b8c\u7f8e\u9690\u85cf\u627f\u8bfa\u4e3a\u533f\u540d\u51ed\u8bc1\u63d0\u4f9b\u4e86\u9690\u79c1\u4e0e\u529f\u80fd\u6027\u7684\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u9700\u540c\u65f6\u6ee1\u8db3\u591a\u91cd\u8981\u6c42\u7684\u6295\u7968\u7cfb\u7edf\u3002"}}
{"id": "2511.10423", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.10423", "abs": "https://arxiv.org/abs/2511.10423", "authors": ["Jiayang Meng", "Tao Huang", "Hong Chen", "Chen Hou", "Guolong Zheng"], "title": "Enhanced Privacy Leakage from Noise-Perturbed Gradients via Gradient-Guided Conditional Diffusion Models", "comment": null, "summary": "Federated learning synchronizes models through gradient transmission and aggregation. However, these gradients pose significant privacy risks, as sensitive training data is embedded within them. Existing gradient inversion attacks suffer from significantly degraded reconstruction performance when gradients are perturbed by noise-a common defense mechanism. In this paper, we introduce Gradient-Guided Conditional Diffusion Models (GG-CDMs) for reconstructing private images from leaked gradients without prior knowledge of the target data distribution. Our approach leverages the inherent denoising capability of diffusion models to circumvent the partial protection offered by noise perturbation, thereby improving attack performance under such defenses. We further provide a theoretical analysis of the reconstruction error bounds and the convergence properties of attack loss, characterizing the impact of key factors-such as noise magnitude and attacked model architecture-on reconstruction quality. Extensive experiments demonstrate our attack's superior reconstruction performance with Gaussian noise-perturbed gradients, and confirm our theoretical findings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff08GG-CDM\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u88ab\u566a\u58f0\u6270\u52a8\u7684\u68af\u5ea6\u4e2d\u91cd\u5efa\u79c1\u6709\u56fe\u50cf\uff0c\u63d0\u5347\u73b0\u6709\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u5728\u566a\u58f0\u9632\u5fa1\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u68af\u5ea6\u4f20\u8f93\u9690\u85cf\u9690\u79c1\u98ce\u9669\uff0c\u4f46\u73b0\u6709\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\u5728\u68af\u5ea6\u88ab\u566a\u58f0\u6270\u52a8\u65f6\u6027\u80fd\u4e0b\u964d\u3002\u4e3a\u514b\u670d\u566a\u58f0\u9632\u5fa1\u7684\u9650\u5236\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u6709\u6761\u4ef6\u6269\u6563\u6a21\u578b\u56fa\u6709\u7684\u53bb\u566a\u80fd\u529b\uff0c\u63d0\u51fa\u68af\u5ea6\u5f15\u5bfc\u7684\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff08GG-CDM\uff09\uff0c\u76f4\u63a5\u4ece\u6cc4\u6f0f\u7684\u68af\u5ea6\u91cd\u6784\u56fe\u50cf\uff0c\u65e0\u9700\u76ee\u6807\u6570\u636e\u5206\u5e03\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u5728\u591a\u79cd\u60c5\u51b5\u4e0b\uff08\u5305\u62ec\u9ad8\u65af\u566a\u58f0\u6270\u52a8\uff09\u91cd\u5efa\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u566a\u58f0\u5f3a\u5ea6\u548c\u6a21\u578b\u7ed3\u6784\u5bf9\u91cd\u5efa\u8d28\u91cf\u7684\u5f71\u54cd\u8fb9\u754c\u3002", "conclusion": "GG-CDM\u80fd\u6709\u6548\u7a81\u7834\u566a\u58f0\u9632\u5fa1\uff0c\u5bf9\u8054\u90a6\u5b66\u4e60\u9690\u79c1\u5b89\u5168\u63d0\u51fa\u65b0\u6311\u6218\uff1b\u7406\u8bba\u5206\u6790\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u653b\u51fb\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002"}}
{"id": "2511.10502", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10502", "abs": "https://arxiv.org/abs/2511.10502", "authors": ["Vincenzo Carletti", "Pasquale Foggia", "Carlo Mazzocca", "Giuseppe Parrella", "Mario Vento"], "title": "On the Detectability of Active Gradient Inversion Attacks in Federated Learning", "comment": null, "summary": "One of the key advantages of Federated Learning (FL) is its ability to collaboratively train a Machine Learning (ML) model while keeping clients' data on-site. However, this can create a false sense of security. Despite not sharing private data increases the overall privacy, prior studies have shown that gradients exchanged during the FL training remain vulnerable to Gradient Inversion Attacks (GIAs). These attacks allow reconstructing the clients' local data, breaking the privacy promise of FL. GIAs can be launched by either a passive or an active server. In the latter case, a malicious server manipulates the global model to facilitate data reconstruction. While effective, earlier attacks falling under this category have been demonstrated to be detectable by clients, limiting their real-world applicability. Recently, novel active GIAs have emerged, claiming to be far stealthier than previous approaches. This work provides the first comprehensive analysis of these claims, investigating four state-of-the-art GIAs. We propose novel lightweight client-side detection techniques, based on statistically improbable weight structures and anomalous loss and gradient dynamics. Extensive evaluation across several configurations demonstrates that our methods enable clients to effectively detect active GIAs without any modifications to the FL training protocol.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u5b58\u5728\u7684\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\uff08GIA\uff09\u98ce\u9669\uff0c\u5c24\u5176\u662f\u65b0\u578b\u4e3b\u52a8\u653b\u51fb\u7684\u9690\u853d\u6027\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6743\u91cd\u7ed3\u6784\u5f02\u5e38\u53ca\u635f\u5931/\u68af\u5ea6\u52a8\u6001\u7684\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6709\u6548\u8bc6\u522b\u653b\u51fb\u800c\u65e0\u9700\u4fee\u6539\u8054\u90a6\u5b66\u4e60\u534f\u8bae\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u867d\u80fd\u4fdd\u62a4\u5ba2\u6237\u7aef\u6570\u636e\u9690\u79c1\uff0c\u4f46\u4ea4\u6362\u7684\u68af\u5ea6\u4ecd\u9762\u4e34\u68af\u5ea6\u53cd\u6f14\u653b\u51fb\uff08GIA\uff09\u5a01\u80c1\u3002\u8fd1\u671f\u65b0\u578b\u4e3b\u52a8\u653b\u51fb\u58f0\u79f0\u6bd4\u4ee5\u5f80\u66f4\u9690\u853d\uff0c\u4f46\u5176\u53ef\u68c0\u6d4b\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef\u68c0\u6d4b\u6280\u672f\uff1a1\uff09\u7edf\u8ba1\u5f02\u5e38\u7684\u6743\u91cd\u7ed3\u6784\u68c0\u6d4b\uff1b2\uff09\u57fa\u4e8e\u635f\u5931\u548c\u68af\u5ea6\u52a8\u6001\u5f02\u5e38\u7684\u68c0\u6d4b\u3002\u5728\u591a\u79cd\u914d\u7f6e\u4e0b\u8bc4\u4f30\u4e86\u56db\u79cd\u524d\u6cbf\u4e3b\u52a8GIA\u3002", "result": "\u8de8\u591a\u573a\u666f\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u9ad8\u6548\u8bc6\u522b\u4e3b\u52a8GIA\uff08\u5305\u62ec\u6700\u65b0\u9690\u853d\u653b\u51fb\uff09\uff0c\u4e14\u65e0\u9700\u6539\u52a8\u8054\u90a6\u5b66\u4e60\u534f\u8bae\u3002", "conclusion": "\u5373\u4f7f\u65b0\u578b\u4e3b\u52a8\u653b\u51fb\u9690\u853d\u6027\u5f3a\uff0c\u5ba2\u6237\u7aef\u4ecd\u53ef\u901a\u8fc7\u8f7b\u91cf\u7edf\u8ba1\u65b9\u6cd5\u5b9e\u73b0\u6709\u6548\u68c0\u6d4b\uff0c\u4ece\u800c\u7ef4\u62a4\u8054\u90a6\u5b66\u4e60\u7684\u9690\u79c1\u627f\u8bfa\u3002"}}
{"id": "2511.10516", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.10516", "abs": "https://arxiv.org/abs/2511.10516", "authors": ["Josep Domingo-Ferrer"], "title": "How Worrying Are Privacy Attacks Against Machine Learning?", "comment": null, "summary": "In several jurisdictions, the regulatory framework on the release and sharing of personal data is being extended to machine learning (ML). The implicit assumption is that disclosing a trained ML model entails a privacy risk for any personal data used in training comparable to directly releasing those data. However, given a trained model, it is necessary to mount a privacy attack to make inferences on the training data. In this concept paper, we examine the main families of privacy attacks against predictive and generative ML, including membership inference attacks (MIAs), property inference attacks, and reconstruction attacks. Our discussion shows that most of these attacks seem less effective in the real world than what a prima face interpretation of the related literature could suggest.", "AI": {"tldr": "\u672c\u6587\u8d28\u7591\u4e86\u673a\u5668\u5b66\u4e60(ML)\u9690\u79c1\u98ce\u9669\u7684\u4f20\u7edf\u8ba4\u77e5\uff0c\u5206\u6790\u4e86\u591a\u79cd\u9690\u79c1\u653b\u51fb\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u771f\u5b9e\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8\u62ab\u9732\u8bad\u7ec3\u8fc7\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6240\u5e26\u6765\u7684\u5b9e\u9645\u9690\u79c1\u98ce\u9669\u7a0b\u5ea6\u3002\u5f53\u524d\u76d1\u7ba1\u6846\u67b6\u5047\u8bbe\u516c\u5f00ML\u6a21\u578b\u5e26\u6765\u7684\u9690\u79c1\u98ce\u9669\u7b49\u540c\u4e8e\u62ab\u9732\u539f\u59cb\u6570\u636e\uff0c\u4f46\u4f5c\u8005\u8ba4\u4e3a\u8fd9\u4e2a\u5047\u8bbe\u9700\u8981\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002", "method": "\u4f5c\u8005\u7cfb\u7edf\u5730\u68b3\u7406\u4e86\u5bf9\u6297\u9884\u6d4b\u6027\u548c\u751f\u6210\u5f0f\u6a21\u578b\u7684\u9690\u79c1\u653b\u51fb\u7c7b\u578b\uff0c\u91cd\u70b9\u8bc4\u4f30\u4e86\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIA\uff09\u3001\u5c5e\u6027\u63a8\u7406\u653b\u51fb\u3001\u91cd\u6784\u653b\u51fb\u7b49\u4e3b\u8981\u653b\u51fb\u6a21\u5f0f\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a\u73b0\u5b9e\u73af\u5883\u4e2d\u9690\u79c1\u653b\u51fb\u7684\u5b9e\u9645\u6709\u6548\u6027\u8fdc\u4f4e\u4e8e\u6587\u732e\u4e2d\u8868\u9762\u663e\u793a\u7684\u5a01\u80c1\u7a0b\u5ea6\u3002\u5927\u591a\u6570\u653b\u51fb\u5728\u7406\u8bba\u573a\u666f\u4e2d\u6709\u6548\uff0c\u4f46\u5728\u9762\u5bf9\u5b9e\u9645\u90e8\u7f72\u73af\u5883\u7684\u590d\u6742\u6027\u65f6\u4f1a\u663e\u8457\u5931\u6548\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\u76d1\u7ba1\u673a\u6784\u548c\u884c\u4e1a\u5e94\u91cd\u65b0\u8bc4\u4f30\u73b0\u6709\u9690\u79c1\u98ce\u9669\u5047\u8bbe\u3002\u672c\u6587\u547c\u5401\u533a\u5206\u6570\u636e\u62ab\u9732\u98ce\u9669\u4e0e\u5b9e\u9645\u653b\u51fb\u6548\u679c\uff0c\u4e3b\u5f20\u5efa\u7acb\u66f4\u5747\u8861\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5171\u4eab\u76d1\u7ba1\u6846\u67b6\u3002"}}
