<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 12]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [AFLGopher: Accelerating Directed Fuzzing via Feasibility-Aware Guidance](https://arxiv.org/abs/2511.10828)
*Weiheng Bai,Kefu Wu,Qiushi Wu,Kangjie Lu*

Main category: cs.CR

TL;DR: 本文提出了AFLGopher，一种可行性感知的定向模糊测试方法。通过预测分支可行性并动态更新可行性信息，它比现有工具更高效地达到目标代码和触发已知漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有定向模糊测试工具的反馈机制（基于控制流距离）未考虑可行性，导致效率低下。

Method: 设计了可行性预测技术：1) 基于有限踪迹预测所有分支可行性的分类方法；2) 运行时逐步更新可行性信息的机制。

Result: 实验证明AFLGopher性能显著优于现有工具：到达目标速度快2.52-3.76倍，触发漏洞速度快4.52-5.60倍。

Conclusion: 可行性感知机制大幅提升了定向模糊测试效率，AFLGopher是目前最先进的定向模糊测试工具。

Abstract: Directed fuzzing is a useful testing technique that aims to efficiently reach target code sites in a program. The core of directed fuzzing is the guiding mechanism that directs the fuzzing to the specified target. A general guiding mechanism adopted in existing directed fuzzers is to calculate the control-flow distance between the current progress and the target, and use that as feedback to guide the directed fuzzing. A fundamental problem with the existing guiding mechanism is that the distance calculation is \emph{feasibility-unaware}.
  In this work, we propose feasibility-aware directed fuzzing named AFLGopher. Our new feasibility-aware distance calculation provides pragmatic feedback to guide directed fuzzing to reach targets efficiently. We propose new techniques to address the challenges of feasibility prediction. Our new classification method allows us to predict the feasibility of all branches based on limited traces, and our runtime feasibility-updating mechanism gradually and efficiently improves the prediction precision. We implemented AFLGopher and compared AFLGopher with state-of-the-art directed fuzzers including AFLGo, enhanced AFLGo, WindRanger, BEACON and SelectFuzz. AFLGopher is 3.76x, 2.57x, 3.30x, 2.52x and 2.86x faster than AFLGo, BEACON, WindRanger, SelectFuzz and enhanced AFLGo, respectively, in reaching targets. AFLGopher is 5.60x, 5.20x, 4.98x, 4.52x, and 5.07x faster than AFLGo, BEACON, WindRanger, SelectFuzz and enhanced AFLGo, respectively, in triggering known vulnerabilities.

</details>


### [2] [Armadillo: Robust Single-Server Secure Aggregation for Federated Learning with Input Validation](https://arxiv.org/abs/2511.10863)
*Yiping Ma,Yue Guo,Harish Karthikeyan,Antigoni Polychroniadou*

Main category: cs.CR

TL;DR: 本文介绍了Armadillo安全聚合系统，针对联邦学习中的对抗性客户端提供破坏性抵抗。系统可在恶意客户端联盟试图操纵聚合时，将其影响限制在预定义范围内的合法输入误报上。相比先前工作，Armadillo在降低每客户端计算成本和减少通信轮次方面取得突破。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习安全聚合方案面临两难：Chowdhury等人方案中客户端计算开销高，Bell等人方案中通信轮次多。需开发同时具备低计算开销和低轮次复杂度的抗破坏安全聚合系统。

Method: 1) 设计双层安全聚合协议，仅需基础算术运算；2) 开发高效协议剔除恶意客户端影响。核心创新在于结合两层协议和低轮次剔除机制，并整合零知识证明技术确保安全性。

Result: Armadillo每轮安全聚合仅需3轮通信，且服务端与客户端保持轻量级计算。实验证实其在抵御阈值内恶意客户端联盟攻击的同时，显著优于现有方案的计算效率。

Conclusion: Armadillo通过创新架构平衡了安全性与效率，为联邦学习提供了首个同时满足低轮次、低计算开销的抗破坏聚合方案。双层协议与恶意影响剔除机制可推广至其他隐私计算场景。

Abstract: This paper presents a secure aggregation system Armadillo that has disruptive resistance against adversarial clients, such that any coalition of malicious clients (within the tolerated threshold) can affect the aggregation result only by misreporting their private inputs in a pre-defined legitimate range. Armadillo is designed for federated learning setting, where a single powerful server interacts with many weak clients iteratively to train models on client's private data. While a few prior works consider disruption resistance under such setting, they either incur high per-client cost (Chowdhury et al. CCS '22) or require many rounds (Bell et al. USENIX Security '23). Although disruption resistance can be achieved generically with zero-knowledge proof techniques (which we also use in this paper), we realize an efficient system with two new designs: 1) a simple two-layer secure aggregation protocol that requires only simple arithmetic computation; 2) an agreement protocol that removes the effect of malicious clients from the aggregation with low round complexity. With these techniques, Armadillo completes each secure aggregation in 3 rounds while keeping the server and clients computationally lightweight.

</details>


### [3] [On the Information-Theoretic Fragility of Robust Watermarking under Diffusion Editing](https://arxiv.org/abs/2511.10933)
*Yunyi Ni,Ziyu Yang,Ze Niu,Emily Davis,Finn Carter*

Main category: cs.CR

TL;DR: 本文研究了基于扩散模型的图像编辑技术对鲁棒图像水印的影响，发现扩散过程可导致已有水印信息丢失，并提出一种引导梯度攻击算法实现高效水印去除，同时讨论了对水印技术的伦理反思与改进策略。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型驱动的图像生成/编辑技术发展，现有水印方案面临被新型攻击技术破坏的风险。本文旨在探究扩散编辑操作对水印系统的影响机制及破坏程度。

Method: 1) 理论证明扩散变换会降低水印载体与载荷间的互信息；2) 设计引导扩散攻击算法主动擦除水印信号；3) 在主流深度学习水印方案上进行实验验证。

Result: 1) 扩散迭代导致水印恢复率趋近于零；2) 提出攻击算法在保持图像视觉质量的同时使水印恢复率降至近零；3) 现有水印方案全部失效。

Conclusion: 扩散模型具有破坏现有水印系统的能力，未来水印技术应考虑对抗生成式AI的方法，同时需谨慎对待水印去除技术带来的道德风险。

Abstract: Robust invisible watermarking embeds hidden information in images such that the watermark can survive various manipulations. However, the emergence of powerful diffusion-based image generation and editing techniques poses a new threat to these watermarking schemes. In this paper, we investigate the intersection of diffusion-based image editing and robust image watermarking. We analyze how diffusion-driven image edits can significantly degrade or even fully remove embedded watermarks from state-of-the-art robust watermarking systems. Both theoretical formulations and empirical experiments are provided. We prove that as a image undergoes iterative diffusion transformations, the mutual information between the watermarked image and the embedded payload approaches zero, causing watermark decoding to fail. We further propose a guided diffusion attack algorithm that explicitly targets and erases watermark signals during generation. We evaluate our approach on recent deep learning-based watermarking schemes and demonstrate near-zero watermark recovery rates after attack, while maintaining high visual fidelity of the regenerated images. Finally, we discuss ethical implications of such watermark removal capablities and provide design guidelines for future watermarking strategies to be more resilient in the era of generative AI.

</details>


### [4] [Gynopticon: Consensus-Based Cheating Detection System for Competitive Games](https://arxiv.org/abs/2511.10992)
*Jeuk Kang,Jungheum Park*

Main category: cs.CR

TL;DR: GYNOPTICON是一个创新的作弊检测框架，通过用户共识来识别游戏中的异常行为，解决现有内核级反作弊方案在隐私和安全方面的担忧。


<details>
  <summary>Details</summary>
Motivation: 当前针对竞技类游戏（如MOBA、FPS）的作弊检测研究较少，而现有的内核级反作弊方案虽有效但侵犯用户隐私和系统安全。因此需要一种兼顾效率与隐私的新方法。

Method: 框架整合轻量级客户端检测机制与服务器投票系统：客户端发现可疑行为后向服务器投票，服务器聚合投票以共识机制区分作弊者与正常玩家。

Result: 在模拟环境和真实FPS游戏中的实验显示：模拟验证了框架可行性，真实环境证实其能可靠检测作弊；公开数据集实验还证明了系统在长期游戏管理中的适用性。

Conclusion: GYNOPTICON作为用户驱动的共识方案，为竞技游戏提供了一种透明、隐私友好的实用反作弊替代方案，减少了对侵入式监控的依赖。

Abstract: Cheating in online games poses significant threats to the gaming industry, yet most prior research has concentrated on Massively Multiplayer Online Role-Playing Games (MMORPGs). Competitive genres-such as Multiplayer Online Battle Arena (MOBA), First Person Shooter (FPS), Real Time Strategy (RTS), and Action games-remain underexplored due to the difficulty of detecting cheating users and the demand for complex data and techniques. To address this gap, many game companies rely on kernel-level anti-cheat solutions, which, while effective, raise serious concerns regarding user privacy and system security. In this paper, we propose GYNOPTICON, a novel cheating detection framework that leverages user consensus to identify abnormal behavior. GYNOPTICON integrates a lightweight client-side detection mechanism with a server-side voting system: when suspicious activity is identified, clients cast votes to the server, which aggregates them to establish consensus and distinguish cheaters from legitimate players. This architecture enables transparency, reduces reliance on intrusive monitoring, and mitigates privacy risks. We evaluate GYNOPTICON in both a controlled simulation and a real-world FPS environment. Simulation results verify its feasibility and requirements, while real-world experiments confirm its effectiveness in reliably detecting cheating users. Furthermore, we demonstrate the system's applicability and sustainability for long-term game management using public datasets. GYNOPTICON represents a user-driven, consensus-based alternative to conventional anti-cheat systems, offering a practical and privacy-preserving solution for competitive online games.

</details>


### [5] [Data Poisoning Vulnerabilities Across Healthcare AI Architectures: A Security Threat Analysis](https://arxiv.org/abs/2511.11020)
*Farhad Abtahi,Fernando Seoane,Iván Pau,Mario Vega-Barbas*

Main category: cs.CR

TL;DR: 医疗AI系统面临数据投毒攻击，现有防御和监管不足。攻击者仅需少量样本即可在多种场景下成功攻击，成功率超60%，且难以检测。隐私法规意外保护攻击者，供应链弱点导致广泛风险。建议多层防御措施，并质疑黑盒模型在高风险决策中的适用性。


<details>
  <summary>Details</summary>
Motivation: 调查医疗AI系统在数据投毒攻击下的脆弱性，揭示当前防御和法规的不足，强调安全风险对医疗决策的高危险性。

Method: 分析四大类攻击场景（架构攻击、基础设施攻击、资源分配攻击、供应链攻击）中的八种具体场景，评估攻击成功率、检测难度及系统漏洞。

Result: 攻击者仅用100-500个样本即可破坏系统（成功率>60%），检测需6-12个月或无法实现；分布式架构扩大攻击面，隐私法阻碍检测，供应链漏洞影响数十至数百机构。

Conclusion: 亟需强制对抗测试、集成检测和隐私保护安全机制；提倡可解释模型替代黑盒系统，呼吁国际协作制定AI安全标准。

Abstract: Healthcare AI systems face major vulnerabilities to data poisoning that current defenses and regulations cannot adequately address. We analyzed eight attack scenarios in four categories: architectural attacks on convolutional neural networks, large language models, and reinforcement learning agents; infrastructure attacks exploiting federated learning and medical documentation systems; critical resource allocation attacks affecting organ transplantation and crisis triage; and supply chain attacks targeting commercial foundation models. Our findings indicate that attackers with access to only 100-500 samples can compromise healthcare AI regardless of dataset size, often achieving over 60 percent success, with detection taking an estimated 6 to 12 months or sometimes not occurring at all. The distributed nature of healthcare infrastructure creates many entry points where insiders with routine access can launch attacks with limited technical skill. Privacy laws such as HIPAA and GDPR can unintentionally shield attackers by restricting the analyses needed for detection. Supply chain weaknesses allow a single compromised vendor to poison models across 50 to 200 institutions. The Medical Scribe Sybil scenario shows how coordinated fake patient visits can poison data through legitimate clinical workflows without requiring a system breach. Current regulations lack mandatory adversarial robustness testing, and federated learning can worsen risks by obscuring attribution. We recommend multilayer defenses including required adversarial testing, ensemble-based detection, privacy-preserving security mechanisms, and international coordination on AI security standards. We also question whether opaque black-box models are suitable for high-stakes clinical decisions, suggesting a shift toward interpretable systems with verifiable safety guarantees.

</details>


### [6] [SALT-V: Lightweight Authentication for 5G V2X Broadcasting](https://arxiv.org/abs/2511.11028)
*Liu Cao,Weizheng Wang,Qipeng Xie,Dongyu Wei,Lyutianyang Zhang*

Main category: cs.CR

TL;DR: SALT-V是一种新型混合认证框架，通过分层协议解决了V2X通信中安全与效率的权衡问题。它结合ECDSA签名和轻量级GMAC操作，利用临时会话标签（EST）白名单机制实现95%消息的即时验证。评估显示其性能优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有方案在V2X通信中存在两难困境：传统公钥方案验证延迟高（2ms），无法满足紧急避碰需求；对称密钥方案虽延迟低（微秒级），但存在20-100ms密钥披露延迟。两者均无法同时满足5G NR-V2X对即时认证和计算效率的严苛要求。

Method: 1. 分层协议：对10%流量（BOOT帧）使用ECDSA建立信任锚；90%流量（DATA帧）使用GMAC操作轻量认证。2. 临时会话标签（EST）白名单机制：将GMAC密钥封装在ECDSA认证的BOOT帧中广播，使接收方无需等待密钥披露即可验证DATA帧。3. 布隆过滤器：实现1us内的O(1)复杂度证书撤销检查。

Result: 1. 平均计算时间0.035ms（比纯ECDSA快57倍）2. 端到端延迟1ms 3. 通信开销41字节 4. 线性扩展至2000辆车 5. 95%消息实现即时验证

Conclusion: SALT-V首次同时满足实时V2X部署的所有关键要求，解决了认证延迟与安全强度的根本性权衡，为安全关键型应用提供实用方案。其创新点在于协议分层设计和EST白名单机制，结合布隆过滤器实现高效撤销检查。

Abstract: Vehicle-to-Everything (V2X) communication faces a critical authentication dilemma: traditional public-key schemes like ECDSA provide strong security but impose 2 ms verification delays unsuitable for collision avoidance, while symmetric approaches like TESLA achieve microsecond-level efficiency at the cost of 20-100 ms key disclosure latency. Neither meets 5G New Radio (NR)-V2X's stringent requirements for both immediate authentication and computational efficiency. This paper presents SALT-V, a novel hybrid authentication framework that reconciles this fundamental trade-off through intelligent protocol stratification. SALT-V employs ECDSA signatures for 10% of traffic (BOOT frames) to establish sender trust, then leverages this trust anchor to authenticate 90% of messages (DATA frames) using lightweight GMAC operations. The core innovation - an Ephemeral Session Tag (EST) whitelist mechanism - enables 95% of messages to achieve immediate verification without waiting for key disclosure, while Bloom filter integration provides O(1) revocation checking in 1 us. Comprehensive evaluation demonstrates that SALT-V achieves 0.035 ms average computation time (57x faster than pure ECDSA), 1 ms end-to-end latency, 41-byte overhead, and linear scalability to 2000 vehicles, making it the first practical solution to satisfy all safety-critical requirements for real-time V2X deployment.

</details>


### [7] [Bridging Local and Federated Data Normalization in Federated Learning: A Privacy-Preserving Approach](https://arxiv.org/abs/2511.11249)
*Melih Coşğun,Mert Gençtürk,Sinem Sav*

Main category: cs.CR

TL;DR: 论文探讨了联邦学习（FL）中数据标准化的挑战，提出了一种在保持数据本地性的同时模拟全局归一化的联邦归一化方法，并设计了一种基于全同态加密的隐私保护方案来实现安全计算。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，由于数据的分散性和异质性，传统局部归一化在非独立同分布数据时效果不佳，而全局归一化又无法实现。如何在保证隐私的前提下实现有效归一化成为关键问题。

Method: 提出联邦归一化：1）通过安全共享归一化参数模拟全局归一化 2）设计基于多参与方全同态加密的安全计算方案，用于计算排序统计量（如中位数）3）实现多种标准化技术的隐私保护版本（如批归一化）。

Result: 联邦归一化实现了与全局归一化可比的模型性能，同时保护了数据隐私；提出的安全计算框架兼顾了效率和安全性。

Conclusion: 该方法在保持联邦学习去中心化的优势下，解决了异质数据导致的归一化难题，其安全计算框架可扩展至其他需要跨参与方统计信息的场景。

Abstract: Data normalization is a crucial preprocessing step for enhancing model performance and training stability. In federated learning (FL), where data remains distributed across multiple parties during collaborative model training, normalization presents unique challenges due to the decentralized and often heterogeneous nature of the data. Traditional methods rely on either independent client-side processing, i.e., local normalization, or normalizing the entire dataset before distributing it to parties, i.e., pooled normalization. Local normalization can be problematic when data distributions across parties are non-IID, while the pooled normalization approach conflicts with the decentralized nature of FL. In this paper, we explore the adaptation of widely used normalization techniques to FL and define the term federated normalization. Federated normalization simulates pooled normalization by enabling the collaborative exchange of normalization parameters among parties. Thus, it achieves performance on par with pooled normalization without compromising data locality. However, sharing normalization parameters such as the mean introduces potential privacy risks, which we further mitigate through a robust privacy-preserving solution. Our contributions include: (i) We systematically evaluate the impact of various federated and local normalization techniques in heterogeneous FL scenarios, (ii) We propose a novel homomorphically encrypted $k$-th ranked element (and median) calculation tailored for the federated setting, enabling secure and efficient federated normalization, (iii) We propose privacy-preserving implementations of widely used normalization techniques for FL, leveraging multiparty fully homomorphic encryption (MHE).

</details>


### [8] [Prompt Engineering vs. Fine-Tuning for LLM-Based Vulnerability Detection in Solana and Algorand Smart Contracts](https://arxiv.org/abs/2511.11250)
*Biagio Boi,Christian Esposito*

Main category: cs.CR

TL;DR: 本文研究大型语言模型（LLMs）在检测非EVM区块链（Solana和Algorand）智能合约中OWASP漏洞的能力。通过构建合成数据集，评估了提示工程、微调及混合方法在漏洞检测上的表现。结果表明，提示工程具有普适稳健性，微调能提升在TEAL等语言上的精确率与召回率；同时分析了平台架构差异对漏洞表现的影响，提出了基于LLM的静态漏洞检测方案的可行性。


<details>
  <summary>Details</summary>
Motivation: 智能合约在去中心化环境中具有重要作用，但若代码设计不当可能引发风险。当前缺乏针对非EVM平台（如Solana和Algorand）的漏洞标注数据集，且现有安全工具存在局限性。因此，本研究旨在探索LLMs在该领域的漏洞检测能力，并分析平台差异对漏洞特征的影响。

Method: 1. 构建合成数据集：围绕OWASP漏洞分类法，创建包含Rust（Solana）和PyTeal（Algorand）的智能合约片段数据集；
2. 评估三种LLM配置：提示工程（仅通过指令引导模型）、微调（在数据集上训练模型）及混合方法；
3. 比较不同配置在各类漏洞上的性能；
4. 分析Solana与Algorand架构差异如何影响漏洞表现，并提供平台特定的漏洞映射。

Result: 1. 提示工程整体稳健性最佳；
2. 微调显著提升在语义较简单语言（如TEAL）上的精确率与召回率；
3. 平台架构差异导致漏洞表现形式不同（如Solana账户模型使重入攻击更复杂）；
4. 现有安全工具因缺乏平台适配存在检测盲区。

Conclusion: LLM可用于智能合约静态漏洞检测，但需满足两个条件：①训练流程整合领域特定数据；②采用基于漏洞分类的分层方法。此外，平台架构设计直接影响漏洞特征，需开发针对性检测工具。

Abstract: Smart contracts have emerged as key components within decentralized environments, enabling the automation of transactions through self-executing programs. While these innovations offer significant advantages, they also present potential drawbacks if the smart contract code is not carefully designed and implemented. This paper investigates the capability of large language models (LLMs) to detect OWASP-inspired vulnerabilities in smart contracts beyond the Ethereum Virtual Machine (EVM) ecosystem, focusing specifically on Solana and Algorand. Given the lack of labeled datasets for non-EVM platforms, we design a synthetic dataset of annotated smart contract snippets in Rust (for Solana) and PyTeal (for Algorand), structured around a vulnerability taxonomy derived from OWASP. We evaluate LLMs under three configurations: prompt engineering, fine-tuning, and a hybrid of both, comparing their performance on different vulnerability categories. Experimental results show that prompt engineering achieves general robustness, while fine-tuning improves precision and recall on less semantically rich languages such as TEAL. Additionally, we analyze how the architectural differences of Solana and Algorand influence the manifestation and detectability of vulnerabilities, offering platform-specific mappings that highlight limitations in existing security tooling. Our findings suggest that LLM-based approaches are viable for static vulnerability detection in smart contracts, provided domain-specific data and categorization are integrated into training pipelines.

</details>


### [9] [Privacy Challenges and Solutions in Retrieval-Augmented Generation-Enhanced LLMs for Healthcare Chatbots: A Review of Applications, Risks, and Future Directions](https://arxiv.org/abs/2511.11347)
*Shaowei Guan,Hin Chi Kwok,Ngai Fong Law,Gregor Stiglic,Vivian Hui*

Main category: cs.CR

TL;DR: 本文综述了检索增强生成（RAG）在医疗保健领域的应用，重点关注隐私风险和保护机制。通过分析23篇关于医疗RAG应用的文献和17篇隐私保护策略，文章提出了一套结构化框架来分析隐私漏洞，并指出了当前临床验证不足、评估框架缺失等问题，为开发兼具临床效用和隐私保护的RAG系统提供了路线图。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG技术正快速融入临床和生物医学工作流，但隐私风险（如受保护健康信息泄露）仍缺乏系统化解决方案，需要全面梳理医疗RAG应用的隐私脆弱点及对策。

Method: 系统综述23篇医疗RAG应用文献和17篇隐私保护策略文献，通过涵盖数据存储/传输/检索/生成环节的管道式框架分析隐私漏洞，归纳威胁模型中的潜在故障模式及根本原因。

Result: 研究发现当前存在三个关键缺陷：临床验证不充分、标准化评估框架缺失、自动化评估工具不足。

Conclusion: 作者提出基于研究缺陷的行动方向，号召建立同时满足临床效用与隐私保护的医疗RAG系统，为研究人员提供了结构化漏洞分析框架及发展路线图。

Abstract: Retrieval-augmented generation (RAG) has rapidly emerged as a transformative approach for integrating large language models into clinical and biomedical workflows. However, privacy risks, such as protected health information (PHI) exposure, remain inconsistently mitigated. This review provides a thorough analysis of the current landscape of RAG applications in healthcare, including (i) sensitive data type across clinical scenarios, (ii) the associated privacy risks, (iii) current and emerging data-privacy protection mechanisms and (iv) future direction for patient data privacy protection. We synthesize 23 articles on RAG applications in healthcare and systematically analyze privacy challenges through a pipeline-structured framework encompassing data storage, transmission, retrieval and generation stages, delineating potential failure modes, their underlying causes in threat models and system mechanisms, and their practical implications. Building on this analysis, we critically review 17 articles on privacy-preserving strategies for RAG systems. Our evaluation reveals critical gaps, including insufficient clinical validation, absence of standardized evaluation frameworks, and lack of automated assessment tools. We propose actionable directions based on these limitations and conclude with a call to action. This review provides researchers and practitioners with a structured framework for understanding privacy vulnerabilities in healthcare RAG and offers a roadmap toward developing systems that achieve both clinical effectiveness and robust privacy preservation.

</details>


### [10] [SEAL: Subspace-Anchored Watermarks for LLM Ownership](https://arxiv.org/abs/2511.11356)
*Yanbo Dai,Zongjie Li,Zhenlan Ji,Shuai Wang*

Main category: cs.CR

TL;DR: 该论文针对大型语言模型知识产权保护存在的局限性，提出了SEAL框架，通过在潜在表示空间嵌入多比特水印，支持白盒和黑盒验证，并在实验中表现出更高的有效性、保真度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型是宝贵知识产权资产，但目前指纹识别方法无法识别具体模型实例，而传统水印方法易被后处理操作移除。因此需要一种更鲁棒的水印保护机制。

Method: SEAL框架利用模型编辑技术将被选定的锚点样本隐藏表示与预定义正交比特向量对齐，在潜在表示空间嵌入水印。该方法不影响原始预测结果，支持白盒/黑盒验证。

Result: 多数据集和六种主流LLM的测试表明，SEAL在有效性、保真度、效率和鲁棒性上均优于11种基准方法。即使在攻击者知晓水印机制的情况下仍能保持强大的验证性能。

Conclusion: SEAL通过潜在表示空间嵌入水印实现了高效可靠的知识产权保护，克服了现有技术的局限性，并能抵御恶意攻击。

Abstract: Large language models (LLMs) have achieved remarkable success across a wide range of natural language processing tasks, demonstrating human-level performance in text generation, reasoning, and question answering. However, training such models requires substantial computational resources, large curated datasets, and sophisticated alignment procedures. As a result, they constitute highly valuable intellectual property (IP) assets that warrant robust protection mechanisms. Existing IP protection approaches suffer from critical limitations. Model fingerprinting techniques can identify model architectures but fail to establish ownership of specific model instances. In contrast, traditional backdoor-based watermarking methods embed behavioral anomalies that can be easily removed through common post-processing operations such as fine-tuning or knowledge distillation.
  We propose SEAL, a subspace-anchored watermarking framework that embeds multi-bit signatures directly into the model's latent representational space, supporting both white-box and black-box verification scenarios. Our approach leverages model editing techniques to align the hidden representations of selected anchor samples with predefined orthogonal bit vectors. This alignment embeds the watermark while preserving the model's original factual predictions, rendering the watermark functionally harmless and stealthy. We conduct comprehensive experiments on multiple benchmark datasets and six prominent LLMs, comparing SEAL with 11 existing fingerprinting and watermarking methods to demonstrate its superior effectiveness, fidelity, efficiency, and robustness. Furthermore, we evaluate SEAL under potential knowledgeable attacks and show that it maintains strong verification performance even when adversaries possess knowledge of the watermarking mechanism and the embedded signatures.

</details>


### [11] [SoK: Security Evaluation of Wi-Fi CSI Biometrics: Attacks, Metrics, and Systemic Weaknesses](https://arxiv.org/abs/2511.11381)
*Gioliano de Oliveira Braga,Pedro Henrique dos Santos Rocha,Rafael Pimenta de Mattos Paixão,Giovani Hoff da Costa,Gustavo Cavalcanti Morais,Lourenço Alves Pereira Júnior*

Main category: cs.CR

TL;DR: 该论文对基于Wi-Fi信道状态信息（CSI）的生物识别认证进行了系统性分析，从安全角度评估了现有研究在基础设施、信号表示、特征管道、学习模型和评估方法上的差异，揭示了系统性不一致问题，并提出了统一评估框架与安全边界指南。


<details>
  <summary>Details</summary>
Motivation: 现有CSI生物识别研究缺乏对安全属性、对抗弹性和方法一致性的统一理解，导致评估标准不一致且潜在风险被忽视。

Method: 通过系统化知识（SoK）方法分析现有研究差异，构建统一评估框架，引入安全相关指标（如每类EER、FCS、基尼系数）评估风险集中度，并模拟攻击场景（重放、几何模拟、环境扰动）。

Result: 发现现有方法存在系统性缺陷：依赖聚合准确率、FAR/FRR/EER报告不全、缺少单用户风险分析、忽视威胁模型；新指标揭示传统方法掩盖的风险集中问题，并识别出具体攻击面与漏洞。

Conclusion: 论文界定了当前CSI生物识别的安全边界，提出严格评估与可重复实验指南，为安全社区提供结构化证据以重新评估Wi-Fi CSI作为认证原语的适用性。

Abstract: Wi-Fi Channel State Information (CSI) has been repeatedly proposed as a biometric modality, often with reports of high accuracy and operational feasibility. However, the field lacks a consolidated understanding of its security properties, adversarial resilience, and methodological consistency. This Systematization of Knowledge (SoK) examines CSI-based biometric authentication through a security perspective, analyzing how existing work differs across sensing infrastructure, signal representations, feature pipelines, learning models, and evaluation methodologies. Our synthesis reveals systemic inconsistencies: reliance on aggregate accuracy metrics, limited reporting of FAR/FRR/EER, absence of per-user risk analysis, and scarce consideration of threat models or adversarial feasibility. We construct a unified evaluation framework to empirically expose these issues and demonstrate how security-relevant metrics, such as per-class EER, FCS, and the Gini Coefficient, uncover risk concentration that remains hidden under traditional reporting practices. Our analysis highlights concrete attack surfaces and shows how methodological choices materially influence vulnerability profiles, which include replay, geometric mimicry, and environmental perturbation. Based on these findings, we articulate the security boundaries of current CSI biometrics and provide guidelines for rigorous evaluation, reproducible experimentation, and future research directions. This SoK offers the security community a structured, evidence-driven reassessment of Wi-Fi CSI biometrics and their suitability as an authentication primitive.

</details>


### [12] [Automated Side-Channel Analysis of Cryptographic Protocol Implementations](https://arxiv.org/abs/2511.11385)
*Faezeh Nasrabadi,Robert Künnemann,Hamed Nemati*

Main category: cs.CR

TL;DR: 本文提出了一种从WhatsApp二进制实现中提取正式模型的方法，并结合侧信道泄露分析，发现了新的隐私攻击和已知漏洞。


<details>
  <summary>Details</summary>
Motivation: 针对大型闭源应用（如WhatsApp）缺乏正式模型的问题，作者旨在从二进制层面提取模型并分析安全漏洞，包括功能缺陷和侧信道攻击风险。

Method: 结合CryptoBap框架进行二进制分析，通过Ghidra逆向工程提取协议模型；扩展CryptoBap以整合硬件泄露合约，利用DeepSec工具对功能和侧信道漏洞进行形式化验证。

Result: 成功提取了WhatsApp的首个形式化模型，发现了功能与规范的差异、一个允许窃取联系人信息的隐私攻击漏洞，并确认了电子护照协议中的已知攻击。

Conclusion: 该方法可系统检测闭源系统的功能和侧信道漏洞，发现了WhatsApp的实质性风险，证明了二进制级形式化建模与侧信道分析结合的有效性。

Abstract: We extract the first formal model of WhatsApp from its implementation by combining binary-level analysis (via CryptoBap) with reverse engineering (via Ghidra) to handle this large closed-source application. Using this model, we prove forward secrecy, identify a known clone-attack against post-compromise security and discover functional gaps between WhatsApp's implementation and its specification. We further introduce a methodology to analyze cryptographic protocol implementations for their resilience to side-channel attacks. This is achieved by extending the CryptoBap framework to integrate hardware leakage contracts into the protocol model, which we then pass to the state-of-the-art protocol prover, DeepSec. This enables a detailed security analysis against both functional bugs and microarchitectural side-channel attacks. Using this methodology, we identify a privacy attack in WhatsApp that allows a side-channel attacker to learn the victim's contacts and confirm a known unlinkability attack on the BAC protocol used in electronic passports.
  Key contributions include (1) the first formal model of WhatsApp, extracted from its binary, (2) a framework to integrate side-channel leakage contracts into protocol models for the first time, and (3) revealing critical vulnerabilities invisible to specification-based methods.

</details>
