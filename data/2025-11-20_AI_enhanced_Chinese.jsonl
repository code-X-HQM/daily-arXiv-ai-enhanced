{"id": "2511.14908", "categories": ["cs.CR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.14908", "abs": "https://arxiv.org/abs/2511.14908", "authors": ["Geft\u00e9 Almeida", "Marcio Pohlmann", "Alex Severo", "Diego Kreutz", "Tiago Heinrich", "Louren\u00e7o Pereira"], "title": "On-Premise SLMs vs. Commercial LLMs: Prompt Engineering and Incident Classification in SOCs and CSIRTs", "comment": "5 pages, 3 figures, 3 tables, submitted to ERRC/WRSeg 2025", "summary": "In this study, we evaluate open-source models for security incident classification, comparing them with proprietary models. We utilize a dataset of anonymized real incidents, categorized according to the NIST SP 800-61r3 taxonomy and processed using five prompt-engineering techniques (PHP, SHP, HTP, PRP, and ZSL). The results indicate that, although proprietary models still exhibit higher accuracy, locally deployed open-source models provide advantages in privacy, cost-effectiveness, and data sovereignty.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5f00\u6e90\u6a21\u578b\u5728\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u4e13\u6709\u6a21\u578b\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u4e13\u6709\u6a21\u578b\u51c6\u786e\u6027\u66f4\u9ad8\uff0c\u4f46\u672c\u5730\u90e8\u7f72\u7684\u5f00\u6e90\u6a21\u578b\u5728\u9690\u79c1\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u4e3b\u6743\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u8bc4\u4f30\u548c\u6bd4\u8f83\u5f00\u6e90\u4e0e\u4e13\u6709\u6a21\u578b\u5728\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u53ca\u4f18\u7f3a\u70b9\uff0c\u7279\u522b\u662f\u5728\u9690\u79c1\u3001\u6210\u672c\u3001\u6570\u636e\u4e3b\u6743\u7b49\u65b9\u9762\u7684\u6743\u8861\u3002", "method": "\u4f7f\u7528\u7ecfNIST SP 800-61r3\u5206\u7c7b\u6cd5\u6807\u6ce8\u7684\u533f\u540d\u771f\u5b9e\u4e8b\u4ef6\u6570\u636e\u96c6\uff0c\u5e76\u5e94\u7528\u4e94\u79cd\u63d0\u793a\u8bcd\u4f18\u5316\u6280\u672f\uff08PHP, SHP, HTP, PRP, ZSL\uff09\u8fdb\u884c\u6a21\u578b\u6bd4\u8f83\u3002", "result": "\u4e13\u6709\u6a21\u578b\u5728\u51c6\u786e\u6027\u4e0a\u4fdd\u6301\u4f18\u52bf\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u5728\u672c\u5730\u90e8\u7f72\u65f6\u5c55\u73b0\u51fa\u9690\u79c1\u4fdd\u62a4\u3001\u6210\u672c\u6548\u76ca\u548c\u6570\u636e\u4e3b\u6743\u65b9\u9762\u7684\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u5f00\u6e90\u6a21\u578b\u4e3a\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5bf9\u6570\u636e\u9690\u79c1\u548c\u4e3b\u6743\u8981\u6c42\u8f83\u9ad8\u7684\u573a\u666f\uff0c\u5c3d\u7ba1\u5176\u51c6\u786e\u6027\u4ecd\u7565\u900a\u4e8e\u4e13\u6709\u6a21\u578b\u3002"}}
{"id": "2511.14937", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14937", "abs": "https://arxiv.org/abs/2511.14937", "authors": ["Niloofar Mireshghallah", "Neal Mangaokar", "Narine Kokhlikyan", "Arman Zharmagambetov", "Manzil Zaheer", "Saeed Mahloujifar", "Kamalika Chaudhuri"], "title": "CIMemories: A Compositional Benchmark for Contextual Integrity of Persistent Memory in LLMs", "comment": null, "summary": "Large Language Models (LLMs) increasingly use persistent memory from past interactions to enhance personalization and task performance. However, this memory introduces critical risks when sensitive information is revealed in inappropriate contexts. We present CIMemories, a benchmark for evaluating whether LLMs appropriately control information flow from memory based on task context. CIMemories uses synthetic user profiles with over 100 attributes per user, paired with diverse task contexts in which each attribute may be essential for some tasks but inappropriate for others. Our evaluation reveals that frontier models exhibit up to 69% attribute-level violations (leaking information inappropriately), with lower violation rates often coming at the cost of task utility. Violations accumulate across both tasks and runs: as usage increases from 1 to 40 tasks, GPT-5's violations rise from 0.1% to 9.6%, reaching 25.1% when the same prompt is executed 5 times, revealing arbitrary and unstable behavior in which models leak different attributes for identical prompts. Privacy-conscious prompting does not solve this - models overgeneralize, sharing everything or nothing rather than making nuanced, context-dependent decisions. These findings reveal fundamental limitations that require contextually aware reasoning capabilities, not just better prompting or scaling.", "AI": {"tldr": "CIMemories\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u8bb0\u5fc6\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u65f6\u5b58\u5728\u4e25\u91cd\u6cc4\u6f0f\u98ce\u9669\uff0c\u5728\u4e0a\u4e0b\u6587\u4e0d\u9002\u5f53\u65f6\u6cc4\u9732\u4fe1\u606f\u7684\u6bd4\u4f8b\u9ad8\u8fbe69%\uff0c\u4e14\u63d0\u793a\u5de5\u7a0b\u65e0\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u9700\u8981\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u80fd\u529b\u3002", "motivation": "LLMs\u4f7f\u7528\u6301\u4e45\u8bb0\u5fc6\u63d0\u5347\u4e2a\u6027\u5316\u548c\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u6b64\u529f\u80fd\u5b58\u5728\u654f\u611f\u4fe1\u606f\u5728\u4e0d\u9002\u5f53\u65f6\u523b\u6cc4\u9732\u7684\u98ce\u9669\uff0c\u9700\u8bc4\u4f30\u6a21\u578b\u5bf9\u8bb0\u5fc6\u4fe1\u606f\u6d41\u7684\u63a7\u5236\u80fd\u529b\u3002", "method": "\u521b\u5efa\u5408\u6210\u7528\u6237\u6863\u6848\uff08\u542b100+\u5c5e\u6027\uff09\uff0c\u8bbe\u8ba1\u591a\u6837\u5316\u4efb\u52a1\u4e0a\u4e0b\u6587\uff08\u6bcf\u4e2a\u5c5e\u6027\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u5fc5\u8981\uff0c\u5728\u53e6\u4e00\u4e9b\u4e2d\u53ef\u80fd\u4e0d\u9002\u5f53\uff09\uff0c\u8bc4\u4f30LLMs\u5728\u662f\u5426\u4ec5\u5f53\u4e0a\u4e0b\u6587\u9002\u5f53\u65f6\u624d\u4f7f\u7528\u76f8\u5173\u8bb0\u5fc6\u5c5e\u6027\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5c5e\u6027\u7ea7\u8fdd\u89c4\u7387\uff08\u4e0d\u5f53\u6cc4\u9732\uff09\u6700\u9ad8\u8fbe69%\uff1b\u4efb\u52a1\u6570\u91cf\u589e\u52a0\uff081\u219240\u4e2a\u4efb\u52a1\uff09\u65f6GPT-5\u8fdd\u89c4\u7387\u4ece0.1%\u5347\u81f39.6%\uff1b\u540c\u4e00\u63d0\u793a\u8fd0\u884c5\u6b21\u8fdd\u89c4\u7387\u8fbe25.1%\uff0c\u4e14\u6cc4\u9732\u5c5e\u6027\u4e0d\u7a33\u5b9a\uff1b\u9690\u79c1\u63d0\u793a\u65e0\u6548\uff0c\u6a21\u578b\u8d8b\u4e8e\u5168\u5206\u4eab\u6216\u5168\u5c4f\u853d\u3002", "conclusion": "LLMs\u5bf9\u8bb0\u5fc6\u4e2d\u7684\u654f\u611f\u4fe1\u606f\u7f3a\u4e4f\u7a33\u5b9a\u7684\u4e0a\u4e0b\u6587\u63a7\u5236\u80fd\u529b\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u9700\u5f00\u53d1\u5177\u5907\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u7684\u65b0\u65b9\u6848\u800c\u975e\u4f9d\u8d56\u63d0\u793a\u6539\u8fdb\u6216\u6a21\u578b\u7f29\u653e\u3002"}}
{"id": "2511.14963", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.14963", "abs": "https://arxiv.org/abs/2511.14963", "authors": ["Adrian Shuai Li", "Elisa Bertino"], "title": "LFreeDA: Label-Free Drift Adaptation for Windows Malware Detection", "comment": null, "summary": "Machine learning (ML)-based malware detectors degrade over time as concept drift introduces new and evolving families unseen during training. Retraining is limited by the cost and time of manual labeling or sandbox analysis. Existing approaches mitigate this via drift detection and selective labeling, but fully label-free adaptation remains largely unexplored. Recent self-training methods use a previously trained model to generate pseudo-labels for unlabeled data and then train a new model on these labels. The unlabeled data are used only for inference and do not participate in training the earlier model. We argue that these unlabeled samples still carry valuable information that can be leveraged when incorporated appropriately into training. This paper introduces LFreeDA, an end-to-end framework that adapts malware classifiers to drift without manual labeling or drift detection. LFreeDA first performs unsupervised domain adaptation on malware images, jointly training on labeled and unlabeled samples to infer pseudo-labels and prune noisy ones. It then adapts a classifier on CFG representations using the labeled and selected pseudo-labeled data, leveraging the scalability of images for pseudo-labeling and the richer semantics of CFGs for final adaptation. Evaluations on the real-world MB-24+ dataset show that LFreeDA improves accuracy by up to 12.6% and F1 by 11.1% over no-adaptation lower bounds, and is only 4% and 3.4% below fully supervised upper bounds in accuracy and F1, respectively. It also matches the performance of state-of-the-art methods provided with ground truth labels for 300 target samples. Additional results on two controlled-drift benchmarks further confirm that LFreeDA maintains malware detection performance as malware evolves without human labeling.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u7b7e\u6216\u504f\u79fb\u68c0\u6d4b\u7684\u81ea\u9002\u5e94\u65b9\u6cd5LFreeDA\uff0c\u901a\u8fc7\u8054\u5408\u8bad\u7ec3\u6709\u6807\u7b7e\u548c\u65e0\u6807\u7b7e\u6837\u672c\u751f\u6210\u4f2a\u6807\u7b7e\u5e76\u8fc7\u6ee4\u566a\u58f0\uff0c\u5229\u7528\u6076\u610f\u8f6f\u4ef6\u56fe\u50cf\u548cCFG\u8868\u793a\u6765\u9002\u5e94\u6982\u5ff5\u6f02\u79fb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "motivation": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u4f1a\u968f\u6982\u5ff5\u6f02\u79fb\u800c\u6027\u80fd\u4e0b\u964d\uff0c\u91cd\u65b0\u8bad\u7ec3\u9700\u8981\u9ad8\u6602\u7684\u624b\u52a8\u6807\u8bb0\u6210\u672c\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6f02\u79fb\u68c0\u6d4b\u548c\u9009\u62e9\u6027\u6807\u8bb0\uff0c\u800c\u5b8c\u5168\u65e0\u9700\u6807\u8bb0\u7684\u81ea\u9002\u5e94\u65b9\u6cd5\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u4f5c\u8005\u8ba4\u4e3a\u65e0\u6807\u7b7e\u6837\u672c\u5728\u9002\u5f53\u6574\u5408\u540e\u53ef\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u4fe1\u606f\u3002", "method": "LFreeDA\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a1) \u5728\u6076\u610f\u8f6f\u4ef6\u56fe\u50cf\u4e0a\u6267\u884c\u65e0\u76d1\u7763\u57df\u9002\u5e94\uff0c\u8054\u5408\u8bad\u7ec3\u6709\u6807\u7b7e\u548c\u65e0\u6807\u7b7e\u6837\u672c\u4ee5\u63a8\u65ad\u4f2a\u6807\u7b7e\u5e76\u526a\u9664\u566a\u58f0\u6807\u7b7e\uff1b2) \u5229\u7528\u63a7\u5236\u6d41\u56fe(CFG)\u8868\u793a\uff0c\u4f7f\u7528\u6709\u6807\u7b7e\u6570\u636e\u53ca\u9009\u5b9a\u7684\u4f2a\u6807\u7b7e\u6570\u636e\u8c03\u6574\u5206\u7c7b\u5668\uff0c\u7ed3\u5408\u56fe\u50cf\u7684\u6613\u6269\u5c55\u6027\u548cCFG\u7684\u4e30\u5bcc\u8bed\u4e49\u3002", "result": "\u5728\u771f\u5b9e\u6570\u636e\u96c6MB-24+\u4e0a\uff0cLFreeDA\u4f7f\u51c6\u786e\u7387\u63d0\u534712.6%\uff0cF1\u503c\u63d0\u534711.1%\uff0c\u4ec5\u6bd4\u5168\u76d1\u7763\u4e0a\u9650\u4f4e4%\uff08\u51c6\u786e\u7387\uff09\u548c3.4%\uff08F1\uff09\u3002\u5728\u4e09\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u6076\u610f\u8f6f\u4ef6\u6f14\u5316\u65f6\u4fdd\u6301\u68c0\u6d4b\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u3002", "conclusion": "LFreeDA\u5b9e\u73b0\u4e86\u7aef\u5230\u7aef\u7684\u65e0\u6807\u7b7e\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u5668\u81ea\u9002\u5e94\uff0c\u6709\u6548\u5e94\u5bf9\u6982\u5ff5\u6f02\u79fb\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u65e0\u6807\u7b7e\u6837\u672c\u7684\u6f5c\u5728\u4fe1\u606f\uff0c\u7ed3\u5408\u4e24\u79cd\u7279\u5f81\u8868\u793a\u7684\u4f18\u52bf\uff0c\u6027\u80fd\u63a5\u8fd1\u6709\u76d1\u7763\u65b9\u6cd5\uff0c\u4f18\u4e8e\u4f20\u7edf\u65e0\u81ea\u9002\u5e94\u65b9\u6848\u3002"}}
{"id": "2511.15033", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.15033", "abs": "https://arxiv.org/abs/2511.15033", "authors": ["Thanh-Cong Nguyen", "Ngoc-Thanh Nguyen", "Van-Giau Ung", "Duc-Ly Vu"], "title": "Towards Classifying Benign And Malicious Packages Using Machine Learning", "comment": "5 pages, 2 figures, 3 tables", "summary": "Recently, the number of malicious open-source packages in package repositories has been increasing dramatically. While major security scanners focus on identifying known Common Vulnerabilities and Exposures (CVEs) in open-source packages, there are very few studies on detecting malicious packages. Malicious open-source package detection typically requires static, dynamic analysis, or both. Dynamic analysis is more effective as it can expose a package's behaviors at runtime. However, current dynamic analysis tools (e.g., ossf's package-analysis) lack an automatic method to differentiate malicious packages from benign packages. In this paper, we propose an approach to extract the features from dynamic analysis (e.g., executed commands) and leverage machine learning techniques to automatically classify packages as benign or malicious. Our evaluation of nearly 2000 packages on npm shows that the machine learning classifier achieves an AUC of 0.91 with a false positive rate of nearly 0%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u673a\u5668\u5b66\u4e60\u5bf9\u5f00\u6e90\u5305\u8fdb\u884c\u6076\u610f\u884c\u4e3a\u81ea\u52a8\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u6790\u63d0\u53d6\u7279\u5f81\uff08\u5982\u6267\u884c\u547d\u4ee4\uff09\uff0c\u5728npm\u5305\u4e0a\u8bc4\u4f30\u663e\u793aAUC\u8fbe0.91\uff0c\u8bef\u62a5\u7387\u8fd10%\u3002", "motivation": "\u5f53\u524d\u6076\u610f\u5f00\u6e90\u5305\u6570\u91cf\u6fc0\u589e\uff0c\u800c\u73b0\u6709\u5b89\u5168\u626b\u63cf\u5668\u4e3b\u8981\u5173\u6ce8\u5df2\u77e5CVE\u6f0f\u6d1e\uff0c\u9488\u5bf9\u6076\u610f\u5305\u7684\u68c0\u6d4b\u7814\u7a76\u8f83\u5c11\u3002\u52a8\u6001\u5206\u6790\u867d\u80fd\u66b4\u9732\u8fd0\u884c\u65f6\u884c\u4e3a\uff0c\u4f46\u7f3a\u4e4f\u81ea\u52a8\u533a\u5206\u6076\u610f\u4e0e\u826f\u6027\u5305\u7684\u65b9\u6cd5\u3002", "method": "\u4ece\u52a8\u6001\u5206\u6790\u4e2d\u63d0\u53d6\u8fd0\u884c\u65f6\u7279\u5f81\uff08\u5982\u6267\u884c\u547d\u4ee4\uff09\uff0c\u91c7\u7528\u673a\u5668\u5b66\u4e60\u6280\u672f\u81ea\u52a8\u5206\u7c7b\u5305\u7684\u6076\u610f\u6027\u3002\u5bf9npm\u4ed3\u5e93\u8fd12000\u4e2a\u5305\u8fdb\u884c\u4e86\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "result": "\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u5728\u6d4b\u8bd5\u4e2d\u53d6\u5f970.91\u7684AUC\u503c\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd10%\u7684\u8bef\u62a5\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u81ea\u52a8\u8bc6\u522b\u6076\u610f\u5f00\u6e90\u5305\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5de5\u5177\uff0c\u4e3a\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.15071", "categories": ["cs.CR", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.15071", "abs": "https://arxiv.org/abs/2511.15071", "authors": ["Ashwin Karthikeyan", "Hengyu Liu", "Kuldeep S. Meel", "Ning Luo"], "title": "Towards Practical Zero-Knowledge Proof for PSPACE", "comment": null, "summary": "Efficient zero-knowledge proofs (ZKPs) have been restricted to NP statements so far, whereas they exist for all statements in PSPACE. This work presents the first practical zero-knowledge (ZK) protocols for PSPACE-complete statements by enabling ZK proofs of QBF (Quantified Boolean Formula) evaluation. The core idea is to validate quantified resolution proofs (Q-Res) in ZK. We develop an efficient polynomial encoding of Q-Res proofs, enabling proof validation through low-overhead arithmetic checks. We also design a ZK protocol to prove knowledge of a winning strategy related to the QBF, which is often equally important in practice. We implement our protocols and evaluate them on QBFEVAL. The results show that our protocols can verify 72% of QBF evaluations via Q-Res proof and 82% of instances' winning strategies within 100 seconds, for instances where such proofs or strategies can be obtained.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5b9e\u7528\u7684PSPACE\u5b8c\u5907\u8bed\u53e5\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u534f\u8bae\uff0c\u901a\u8fc7\u9a8c\u8bc1\u91cf\u5316\u5e03\u5c14\u516c\u5f0f\uff08QBF\uff09\u8bc4\u4f30\u5b9e\u73b0\u3002\u6838\u5fc3\u601d\u60f3\u662f\u96f6\u77e5\u8bc6\u9a8c\u8bc1\u91cf\u5316\u89e3\u6790\u8bc1\u660e\uff08Q-Res\uff09\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684\u591a\u9879\u5f0f\u7f16\u7801\u548c\u7528\u4e8e\u8bc1\u660e\u83b7\u80dc\u7b56\u7565\u77e5\u8bc6\u7684\u534f\u8bae\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u534f\u8bae\u53ef\u5728100\u79d2\u5185\u9a8c\u8bc172%\u7684QBF\u8bc4\u4f30\u548c82%\u5b9e\u4f8b\u7684\u83b7\u80dc\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u9ad8\u6548\u7684\u96f6\u77e5\u8bc6\u8bc1\u660e\u5927\u591a\u9650\u4e8eNP\u95ee\u9898\uff0c\u800c\u5728PSPACE\u95ee\u9898\u4e2d\u5b58\u5728\u5b9e\u9645\u9700\u6c42\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u5728PSPACE\u5b8c\u5907\u95ee\u9898\u4e0a\u7f3a\u4e4f\u5b9e\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u7684\u7a7a\u767d\uff0c\u5c24\u5176\u9488\u5bf9QBF\u8fd9\u7c7b\u91cd\u8981\u95ee\u9898\u7684\u9a8c\u8bc1\u9700\u6c42\u3002", "method": "1. \u63d0\u51fa\u5c06\u91cf\u5316\u89e3\u6790\u8bc1\u660e\uff08Q-Res\uff09\u5728\u96f6\u77e5\u8bc6\u6761\u4ef6\u4e0b\u9a8c\u8bc1\u7684\u65b9\u6cd5\uff1b2. \u8bbe\u8ba1\u9ad8\u6548\u7684\u591a\u9879\u5f0f\u7f16\u7801\u6280\u672f\uff0c\u4f7f\u8bc1\u660e\u9a8c\u8bc1\u8f6c\u5316\u4e3a\u4f4e\u5f00\u9500\u7684\u7b97\u672f\u68c0\u67e5\uff1b3. \u5f00\u53d1\u65b0\u534f\u8bae\u7528\u4e8e\u8bc1\u660eQBF\u76f8\u5173\u83b7\u80dc\u7b56\u7565\uff08\u5982\u535a\u5f08\u7b56\u7565\uff09\u7684\u77e5\u8bc6\u5b58\u5728\u6027\u3002\u57fa\u4e8eQBFEVAL\u6807\u51c6\u5e93\u5b9e\u73b0\u548c\u8bc4\u4f30\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u5728\u53ef\u83b7\u53d6Q-Res\u8bc1\u660e\u6216\u7b56\u7565\u7684\u5b9e\u4f8b\u4e0a\uff1a1. 72%\u7684QBF\u8bc4\u4f30\u53ef\u901a\u8fc7Q-Res\u8bc1\u660e\u5728100\u79d2\u5185\u5b8c\u6210\u96f6\u77e5\u8bc6\u9a8c\u8bc1\uff1b2. 82%\u7684\u5b9e\u4f8b\u83b7\u80dc\u7b56\u7565\u53ef\u5728\u540c\u7b49\u65f6\u9650\u5185\u5b8c\u6210\u9a8c\u8bc1\u3002\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u7b56\u7565\u8bc1\u660e\u6027\u80fd\u4f18\u4e8eQ-Res\u8bc1\u660e\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u5b9e\u73b0\u4e86PSPACE\u5b8c\u5907\u95ee\u9898\u7684\u5b9e\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\uff0c\u7a81\u7834\u4e86\u4f20\u7edfNP\u95ee\u9898\u9650\u5236\u3002\u9a8c\u8bc1\u534f\u8bae\u5728\u6807\u51c6\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u51fa\u53ef\u884c\u6027\uff0c\u4e3a\u590d\u6742\u903b\u8f91\u51b3\u7b56\u548c\u5b89\u5168\u534f\u8bae\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u9690\u79c1\u4fdd\u62a4\u5de5\u5177\u3002\u672a\u6765\u53ef\u4f18\u5316\u8bc1\u660e\u89c4\u6a21\u5e76\u6269\u5c55\u81f3\u66f4\u591aPSPACE\u95ee\u9898\u3002"}}
{"id": "2511.15165", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15165", "abs": "https://arxiv.org/abs/2511.15165", "authors": ["Jingzhuo Zhou"], "title": "Can MLLMs Detect Phishing? A Comprehensive Security Benchmark Suite Focusing on Dynamic Threats and Multimodal Evaluation in Academic Environments", "comment": null, "summary": "The rapid proliferation of Multimodal Large Language Models (MLLMs) has introduced unprecedented security challenges, particularly in phishing detection within academic environments. Academic institutions and researchers are high-value targets, facing dynamic, multilingual, and context-dependent threats that leverage research backgrounds, academic collaborations, and personal information to craft highly tailored attacks. Existing security benchmarks largely rely on datasets that do not incorporate specific academic background information, making them inadequate for capturing the evolving attack patterns and human-centric vulnerability factors specific to academia. To address this gap, we present AdapT-Bench, a unified methodological framework and benchmark suite for systematically evaluating MLLM defense capabilities against dynamic phishing attacks in academic settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86AdapT-Bench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u5b66\u672f\u73af\u5883\u4e2d\u62b5\u5fa1\u52a8\u6001\u9493\u9c7c\u653b\u51fb\u80fd\u529b\u7684\u7edf\u4e00\u6846\u67b6\u548c\u57fa\u51c6\u5957\u4ef6\u3002", "motivation": "\u5e94\u5bf9\u5b66\u672f\u673a\u6784\u9762\u4e34\u7684\u9ad8\u5ea6\u9488\u5bf9\u6027\u9493\u9c7c\u653b\u51fb\u5a01\u80c1\uff0c\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u7531\u4e8e\u7f3a\u4e4f\u5b66\u672f\u80cc\u666f\u4fe1\u606f\u800c\u65e0\u6cd5\u6709\u6548\u6355\u6349\u9488\u5bf9\u5b66\u672f\u754c\u7684\u653b\u51fb\u6a21\u5f0f\u3002", "method": "\u5f00\u53d1\u4e86\u7edf\u4e00\u65b9\u6cd5\u6846\u67b6AdapT-Bench\uff0c\u5305\u542b\u52a8\u6001\u3001\u591a\u8bed\u8a00\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5a01\u80c1\u60c5\u666f\uff0c\u4e13\u95e8\u6574\u5408\u5b66\u672f\u80cc\u666f\u6570\u636e\u6784\u5efa\u8bc4\u4f30\u4f53\u7cfb\u3002", "result": "\u5efa\u7acb\u8d77\u9488\u5bf9\u5b66\u672f\u754c\u9493\u9c7c\u653b\u51fb\u7684\u8bc4\u4f30\u4f53\u7cfb\uff08\u4f46\u6458\u8981\u672a\u5177\u4f53\u8bf4\u660e\u5b9e\u9a8c\u7ed3\u679c\uff09\u3002", "conclusion": "AdapT-Bench\u586b\u8865\u4e86\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u5728\u5b66\u672f\u73af\u5883\u9002\u5e94\u6027\u65b9\u9762\u7684\u7a7a\u767d\uff0c\u4e3a\u63d0\u5347MLLMs\u9632\u5fa1\u52a8\u6001\u9493\u9c7c\u653b\u51fb\u80fd\u529b\u63d0\u4f9b\u8bc4\u4f30\u57fa\u7840\u3002"}}
{"id": "2511.15463", "categories": ["cs.CR", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.15463", "abs": "https://arxiv.org/abs/2511.15463", "authors": ["Minh Trung Tran", "Nasrin Sohrabi", "Zahir Tari", "Qin Wang"], "title": "How To Cook The Fragmented Rug Pull?", "comment": null, "summary": "Existing rug pull detectors assume a simple workflow: the deployer keeps liquidity pool (LP) tokens and performs one or a few large sells (within a day) that collapse the pool and cash out. In practice, however, many real-world exits violate these assumptions by splitting the attack across both time and actor dimensions: attackers break total extraction into many low-impact trades and route proceeds through multiple non-owner addresses, producing low-visibility drains.\n  We formalize this family of attacks as the fragmented rug pull (FRP) and offer a compact recipe for a slow-stewed beef special: (i) keep the lid on (to preserve LP control so on-chain extraction remains feasible), (ii) chop thin slices (to split the total exit volume into many low-impact micro-trades that individually fall below impact thresholds), and (iii) pass the ladle (to delegate sells across multiple wallets so that each participant takes a small share of the extraction). Technically, we define three atomic predicate groups and show that their orthogonal combinations yield evasive strategies overlooked by prior heuristics (USENIX Sec 19, USENIX Sec 23).\n  We validate the model with large-scale measurements. Our corpus contains 303,614 LPs, among which 105,434 are labeled as FRP pools. The labeled subset includes 34,192,767 pool-related transactions and 401,838 inflated-seller wallets, involving 1,501,408 unique interacting addresses. Notably, owner-wallet participation in inflated selling among FRP-flagged LPs has declined substantially (33.1% of cases), indicating a shift in scam behavior: the liquidity drain is no longer held on the owner wallet. We also detected 127,252 wallets acting as serial scammers when repeatedly engaging in inflated selling across multiple FRP LPs. Our empirical findings demonstrate that the evasive strategies we define are widespread and operationally significant.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u52a0\u5bc6\u8d27\u5e01\u9886\u57df\u7684\u2018\u788e\u7247\u5316\u8dd1\u8def\u6b3a\u8bc8\u2019\uff08FRP\uff09\uff0c\u63cf\u8ff0\u4e86\u653b\u51fb\u8005\u5982\u4f55\u901a\u8fc7\u62c6\u5206\u5927\u989d\u4ea4\u6613\u5e76\u5728\u591a\u4e2a\u5730\u5740\u95f4\u6267\u884c\u4ee5\u964d\u4f4e\u53ef\u89c1\u6027\u6765\u8017\u5c3d\u7ba1\u6d41\u52a8\u6027\u3002\u4f5c\u8005\u63d0\u51fa\u653b\u51fb\u884c\u4e3a\u7684\u7406\u8bba\u6a21\u578b\uff0c\u6db5\u76d6\u52a8\u673a\u3001\u65b9\u6cd5\u548c\u5b9e\u8bc1\u9a8c\u8bc1\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u8dd1\u8def\u63a2\u6d4b\u5668\u4f9d\u8d56\u7b80\u5355\u5047\u8bbe\uff08\u5373\u653b\u51fb\u8005\u4fdd\u7559\u6d41\u52a8\u6027\u6c60\uff08LP\uff09\u4ee3\u5e01\u5e76\u5728\u77ed\u671f\u5185\u5927\u989d\u629b\u552e\uff09\uff0c\u4f46\u73b0\u5b9e\u4e2d\u5b58\u5728\u901a\u8fc7\u5206\u5e03\u5f0f\u4ea4\u6613\u548c\u591a\u65b9\u53c2\u4e0e\u7684\u4f4e\u53ef\u89c1\u6027\u8017\u7aed\u884c\u4e3a\u3002", "method": "\u5f62\u5f0f\u5316FRP\u653b\u51fb\u65b9\u5f0f\uff1a1) \u4fdd\u6301LP\u4ee3\u5e01\u63a7\u5236\u4ee5\u786e\u4fdd\u53ef\u63d0\u53d6\u6d41\u52a8\u6027\uff1b2) \u5206\u8584\u4ea4\u6613\u91cf\u81f3\u591a\u4e2a\u5c0f\u989d\u629b\u552e\uff1b3) \u591a\u5730\u5740\u5206\u62c5\u9500\u552e\u64cd\u4f5c\uff08\u6d17\u52fa\u4f20\u9012\u6a21\u578b\uff09\u3002\u5f00\u53d1\u539f\u5b50\u8c13\u8bcd\u7ec4\u68c0\u6d4b\u673a\u5236\u4ee5\u8bc6\u522b\u5206\u6563\u653b\u51fb\u6a21\u5f0f\u3002", "result": "\u5927\u89c4\u6a21\u5b9e\u8bc1\u68c0\u9a8c\uff1a\u5728303,614\u4e2aLP\u4e2d\u8bc6\u522b105,434\u4e2aFRP\u6c60\uff08\u5360\u6bd434.7%\uff09\uff0c\u6d89\u53ca3,420\u4e07\u6b21\u4ea4\u6613\u300140.2\u4e07\u4e2a\u6b3a\u8bc8\u94b1\u5305\u548c\u8d85150\u4e07\u72ec\u7acb\u5730\u5740\u3002\u5173\u952e\u53d1\u73b0\uff1a1) \u4ec533.1%\u6848\u4f8b\u6d89\u53ca\u5b98\u65b9\u5730\u5740\u629b\u552e\uff08\u8bc1\u660e\u788e\u7247\u5316\u8d8b\u52bf\uff09\uff1b2) \u540c\u65f6\u8bc6\u522b\u51fa127,252\u4e2a\u91cd\u590d\u6b3a\u8bc8\u5730\u5740\u3002", "conclusion": "\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u5ffd\u7565\u4e86\u788e\u7247\u5316\u653b\u51fb\u7b56\u7565\uff0cFRP\u6a21\u578b\u9996\u6b21\u7cfb\u7edf\u6027\u63cf\u8ff0\u4e86\u6b64\u7c7b\u653b\u51fb\u5e76\u5b9e\u8bc1\u5176\u5e7f\u6cdb\u5b58\u5728\u6027\uff08\u7279\u522b\u662f\u5b98\u65b9\u8131\u94a9\u73b0\u8c61\uff09\u3002\u5b9e\u8bc1\u5de5\u5177\u4e0e\u6570\u636e\u96c6\u4e3a\u76d1\u7ba1\u63d0\u4f9b\u65b0\u68c0\u6d4b\u7ef4\u5ea6\u3002"}}
{"id": "2511.15479", "categories": ["cs.CR", "cs.DC", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.15479", "abs": "https://arxiv.org/abs/2511.15479", "authors": ["Martin Slind Hagen", "Emil Lundqvist", "Alex Phu", "Yenan Wang", "Kim Strandberg", "Elad Michael Schiller"], "title": "Towards a Formal Verification of Secure Vehicle Software Updates", "comment": "This technical report is a preprint of the article accepted for publication in Computer & Security 2025", "summary": "With the rise of software-defined vehicles (SDVs), where software governs most vehicle functions alongside enhanced connectivity, the need for secure software updates has become increasingly critical. Software vulnerabilities can severely impact safety, the economy, and society. In response to this challenge, Strandberg et al. [escar Europe, 2021] introduced the Unified Software Update Framework (UniSUF), designed to provide a secure update framework that integrates seamlessly with existing vehicular infrastructures.\n  Although UniSUF has previously been evaluated regarding cybersecurity, these assessments have not employed formal verification methods. To bridge this gap, we perform a formal security analysis of UniSUF. We model UniSUF's architecture and assumptions to reflect real-world automotive systems and develop a ProVerif-based framework that formally verifies UniSUF's compliance with essential security requirements - confidentiality, integrity, authenticity, freshness, order, and liveness - demonstrating their satisfiability through symbolic execution. Our results demonstrate that UniSUF adheres to the specified security guarantees, ensuring the correctness and reliability of its security framework.", "AI": {"tldr": "\u6982\u8ff0\uff1a\u7814\u7a76\u9488\u5bf9\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\uff08SDVs\uff09\u80cc\u666f\u4e0b\u7edf\u4e00\u8f6f\u4ef6\u66f4\u65b0\u6846\u67b6\uff08UniSUF\uff09\u8fdb\u884c\u5f62\u5f0f\u5316\u5b89\u5168\u9a8c\u8bc1\u3002\u586b\u8865\u4e86\u5148\u524d\u672a\u4f7f\u7528\u5f62\u5f0f\u5316\u65b9\u6cd5\u9a8c\u8bc1\u7684\u7a7a\u767d\u3002", "motivation": "\u80cc\u666f\uff1a\u8f6f\u4ef6\u5b9a\u4e49\u6c7d\u8f66\uff08SDVs\uff09\u7684\u8f6f\u4ef6\u6f0f\u6d1e\u53ef\u80fd\u4e25\u91cd\u5f71\u54cd\u5b89\u5168\u3001\u7ecf\u6d4e\u548c\u793e\u4f1a\uff0c\u56e0\u6b64\u786e\u4fdd\u8f6f\u4ef6\u5347\u7ea7\u5b89\u5168\u81f3\u5173\u91cd\u8981\u3002\u524d\u671f\u63d0\u51fa\u7684UniSUF\u6846\u67b6\u9700\u8981\u7ecf\u8fc7\u7cfb\u7edf\u5316\u9a8c\u8bc1\u3002", "method": "\u65b9\u6cd5\uff1a\u5efa\u7acbUniSUF\u7684\u67b6\u6784\u548c\u5047\u8bbe\u6a21\u578b(\u8d34\u5408\u771f\u5b9e\u8f66\u8f7d\u7cfb\u7edf)\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8eProVerif\u7684\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7\u6267\u884c\u9a8c\u8bc1\u6846\u67b6\u6240\u9700\u7684\u5b89\u5168\u5c5e\u6027(\u4fdd\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u3001\u771f\u5b9e\u6027\u3001\u65b0\u9c9c\u6027\u3001\u987a\u5e8f\u6027\u548c\u6d3b\u6027)\u3002", "result": "\u7ed3\u679c\uff1a\u8bc1\u660eUniSUF\u6ee1\u8db3\u6240\u6709\u6307\u5b9a\u7684\u5b89\u5168\u5c5e\u6027\u8981\u6c42(\u4fdd\u5bc6\u6027\u7b49\u516d\u9879)\uff0c\u9a8c\u8bc1\u4e86\u5176\u5b89\u5168\u6846\u67b6\u7684\u53ef\u9760\u6027\u548c\u6b63\u786e\u6027\u3002", "conclusion": "\u7ed3\u8bba\uff1a\u5f62\u5f0f\u5316\u9a8c\u8bc1\u8868\u660eUniSUF\u534f\u8bae\u5728\u65e2\u5b9a\u6a21\u578b\u4e0b\u7b26\u5408\u9884\u8bbe\u5b89\u5168\u76ee\u6807\uff0c\u5176\u6846\u67b6\u5177\u5907\u5b89\u5168\u8fd0\u884c\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
