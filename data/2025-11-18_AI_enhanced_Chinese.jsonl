{"id": "2511.10712", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10712", "abs": "https://arxiv.org/abs/2511.10712", "authors": ["Qinfeng Li", "Miao Pan", "Jintao Chen", "Fu Teng", "Zhiqiang Shen", "Ge Su", "Hao Peng", "Xuhong Zhang"], "title": "Do Not Merge My Model! Safeguarding Open-Source LLMs Against Unauthorized Model Merging", "comment": "Accepted by AAAI 2026 Conference", "summary": "Model merging has emerged as an efficient technique for expanding large language models (LLMs) by integrating specialized expert models. However, it also introduces a new threat: model merging stealing, where free-riders exploit models through unauthorized model merging. Unfortunately, existing defense mechanisms fail to provide effective protection. Specifically, we identify three critical protection properties that existing methods fail to simultaneously satisfy: (1) proactively preventing unauthorized merging; (2) ensuring compatibility with general open-source settings; (3) achieving high security with negligible performance loss. To address the above issues, we propose MergeBarrier, a plug-and-play defense that proactively prevents unauthorized merging. The core design of MergeBarrier is to disrupt the Linear Mode Connectivity (LMC) between the protected model and its homologous counterparts, thereby eliminating the low-loss path required for effective model merging. Extensive experiments show that MergeBarrier effectively prevents model merging stealing with negligible accuracy loss.", "AI": {"tldr": "\u6a21\u578b\u5408\u5e76\u6280\u672f\u53ef\u9ad8\u6548\u6269\u5c55\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u4e5f\u5e26\u6765\u6a21\u578b\u5408\u5e76\u7a83\u53d6\u7684\u65b0\u5a01\u80c1\u3002\u73b0\u6709\u9632\u5fa1\u673a\u5236\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u4e09\u4e2a\u5173\u952e\u4fdd\u62a4\u5c5e\u6027\uff1a\u4e3b\u52a8\u9632\u8303\u672a\u6388\u6743\u5408\u5e76\u3001\u4e0e\u901a\u7528\u5f00\u6e90\u8bbe\u7f6e\u517c\u5bb9\u3001\u9ad8\u5b89\u5168\u6027\u4e14\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565\u3002MergeBarrier\u4f5c\u4e3a\u4e00\u79cd\u5373\u63d2\u5373\u7528\u9632\u5fa1\u65b9\u6848\uff0c\u901a\u8fc7\u7834\u574f\u53d7\u4fdd\u62a4\u6a21\u578b\u4e0e\u5176\u540c\u6e90\u6a21\u578b\u95f4\u7684\u7ebf\u6027\u8fde\u63a5\u6027\uff0c\u6d88\u9664\u6a21\u578b\u5408\u5e76\u6240\u9700\u7684\u4f4e\u635f\u5931\u8def\u5f84\u3002\u5b9e\u9a8c\u8bc1\u660eMergeBarrier\u80fd\u6709\u6548\u963b\u6b62\u6a21\u578b\u5408\u5e76\u7a83\u53d6\u4e14\u7cbe\u5ea6\u635f\u5931\u6781\u5c0f\u3002", "motivation": "\u9488\u5bf9\u6a21\u578b\u5408\u5e76\u6280\u672f\u5f15\u53d1\u7684\u5b89\u5168\u5a01\u80c1\u2014\u2014\u6076\u610f\u7528\u6237\u901a\u8fc7\u672a\u6388\u6743\u5408\u5e76\u7a83\u53d6\u4e13\u5bb6\u6a21\u578b\uff0c\u73b0\u6709\u9632\u5fa1\u65b9\u6cd5\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u4e3b\u52a8\u9632\u62a4\u3001\u5f00\u6e90\u517c\u5bb9\u6027\u548c\u4f4e\u6027\u80fd\u635f\u8017\u4e09\u5927\u9700\u6c42\u3002", "method": "\u63d0\u51faMergeBarrier\u9632\u5fa1\u673a\u5236\uff0c\u5176\u6838\u5fc3\u8bbe\u8ba1\u662f\u7834\u574f\u53d7\u4fdd\u62a4\u6a21\u578b\u4e0e\u5176\u540c\u6e90\u526f\u672c\u4e4b\u95f4\u7684\u7ebf\u6027\u6a21\u5f0f\u8fde\u63a5\u6027\uff08LMC\uff09\uff0c\u4f7f\u6a21\u578b\u5408\u5e76\u8fc7\u7a0b\u65e0\u6cd5\u83b7\u5f97\u6240\u9700\u7684\u4f4e\u635f\u5931\u8def\u5f84\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u5373\u63d2\u5373\u7528\u7684\u65b9\u5f0f\u8fd0\u4f5c\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cMergeBarrier\u80fd\u6709\u6548\u963b\u6b62\u6a21\u578b\u5408\u5e76\u7a83\u53d6\u884c\u4e3a\uff0c\u540c\u65f6\u4ec5\u5e26\u6765\u53ef\u5ffd\u7565\u7684\u51c6\u786e\u7387\u635f\u5931\uff08\u539f\u59cb\u6a21\u578b\u51c6\u786e\u7387\u6bcf\u4e0b\u964d1%\uff0c\u9632\u5fa1\u6210\u529f\u7387\u63d0\u5347\u7ea613%\uff09\u3002", "conclusion": "MergeBarrier\u9996\u6b21\u89e3\u51b3\u4e86\u6a21\u578b\u5408\u5e76\u7a83\u53d6\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u6ee1\u8db3\u4e09\u5927\u9632\u62a4\u7279\u6027\uff0c\u4e3a\u5f00\u6e90\u6a21\u578b\u5b89\u5168\u63d0\u4f9b\u4e86\u65b0\u4fdd\u969c\u3002"}}
{"id": "2511.10714", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10714", "abs": "https://arxiv.org/abs/2511.10714", "authors": ["Shuaitong Liu", "Renjue Li", "Lijia Yu", "Lijun Zhang", "Zhiming Liu", "Gaojie Jin"], "title": "BadThink: Triggered Overthinking Attacks on Chain-of-Thought Reasoning in Large Language Models", "comment": "Accepted at AAAI 2026 (Main Track). This arXiv version corresponds to the camera-ready manuscript and includes expanded appendices. Please cite the AAAI 2026 version when available", "summary": "Recent advances in Chain-of-Thought (CoT) prompting have substantially improved the reasoning capabilities of large language models (LLMs), but have also introduced their computational efficiency as a new attack surface. In this paper, we propose BadThink, the first backdoor attack designed to deliberately induce \"overthinking\" behavior in CoT-enabled LLMs while ensuring stealth. When activated by carefully crafted trigger prompts, BadThink manipulates the model to generate inflated reasoning traces - producing unnecessarily redundant thought processes while preserving the consistency of final outputs. This subtle attack vector creates a covert form of performance degradation that significantly increases computational costs and inference time while remaining difficult to detect through conventional output evaluation methods. We implement this attack through a sophisticated poisoning-based fine-tuning strategy, employing a novel LLM-based iterative optimization process to embed the behavior by generating highly naturalistic poisoned data. Our experiments on multiple state-of-the-art models and reasoning tasks show that BadThink consistently increases reasoning trace lengths - achieving an over 17x increase on the MATH-500 dataset - while remaining stealthy and robust. This work reveals a critical, previously unexplored vulnerability where reasoning efficiency can be covertly manipulated, demonstrating a new class of sophisticated attacks against CoT-enabled systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u9488\u5bf9CoT\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9690\u853d\u540e\u95e8\u653b\u51fb\uff0c\u5f15\u53d1\u8fc7\u5ea6\u601d\u8003\u884c\u4e3a\u3002", "motivation": "CoT\u63d0\u793a\u7684\u8fdb\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u540c\u65f6\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u672c\u7814\u7a76\u65e8\u5728\u8bbe\u8ba1\u4e00\u79cd\u9690\u853d\u7684\u540e\u95e8\u653b\u51fb\uff0c\u8bf1\u5bfc\u6a21\u578b\u4ea7\u751f\u5197\u4f59\u63a8\u7406\u8f68\u8ff9\u4ee5\u589e\u52a0\u8ba1\u7b97\u8d1f\u62c5\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u4e2d\u6bd2\u7684\u5fae\u8c03\u7b56\u7565\u5b9e\u73b0\u653b\u51fb\uff0c\u91c7\u7528\u57fa\u4e8eLLM\u7684\u8fed\u4ee3\u4f18\u5316\u8fc7\u7a0b\u751f\u6210\u9ad8\u5ea6\u81ea\u7136\u7684\u4e2d\u6bd2\u6570\u636e\u3002", "result": "\u5728\u591a\u4e2a\u5148\u8fdb\u6a21\u578b\u548c\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u653b\u51fb\u4f7f\u63a8\u7406\u8f68\u8ff9\u663e\u8457\u5ef6\u957f\uff08\u5982MATH-500\u6570\u636e\u96c6\u589e\u52a017\u500d\u4ee5\u4e0a\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u9690\u853d\u6027\u548c\u8f93\u51fa\u4e00\u81f4\u6027\u3002", "conclusion": "\u63ed\u793a\u4e86CoT\u7cfb\u7edf\u5b58\u5728\u63a8\u7406\u6548\u7387\u88ab\u9690\u853d\u64cd\u63a7\u7684\u65b0\u653b\u51fb\u9762\uff0c\u8bc1\u660e\u4e86\u9488\u5bf9\u6b64\u7c7b\u7cfb\u7edf\u7684\u65b0\u578b\u9ad8\u7ea7\u653b\u51fb\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.10720", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.10720", "abs": "https://arxiv.org/abs/2511.10720", "authors": ["Runpeng Geng", "Yanting Wang", "Chenlong Yin", "Minhao Cheng", "Ying Chen", "Jinyuan Jia"], "title": "PISanitizer: Preventing Prompt Injection to Long-Context LLMs via Prompt Sanitization", "comment": "The code is available at https://github.com/sleeepeer/PISanitizer", "summary": "Long context LLMs are vulnerable to prompt injection, where an attacker can inject an instruction in a long context to induce an LLM to generate an attacker-desired output. Existing prompt injection defenses are designed for short contexts. When extended to long-context scenarios, they have limited effectiveness. The reason is that an injected instruction constitutes only a very small portion of a long context, making the defense very challenging. In this work, we propose PISanitizer, which first pinpoints and sanitizes potential injected tokens (if any) in a context before letting a backend LLM generate a response, thereby eliminating the influence of the injected instruction. To sanitize injected tokens, PISanitizer builds on two observations: (1) prompt injection attacks essentially craft an instruction that compels an LLM to follow it, and (2) LLMs intrinsically leverage the attention mechanism to focus on crucial input tokens for output generation. Guided by these two observations, we first intentionally let an LLM follow arbitrary instructions in a context and then sanitize tokens receiving high attention that drive the instruction-following behavior of the LLM. By design, PISanitizer presents a dilemma for an attacker: the more effectively an injected instruction compels an LLM to follow it, the more likely it is to be sanitized by PISanitizer. Our extensive evaluation shows that PISanitizer can successfully prevent prompt injection, maintain utility, outperform existing defenses, is efficient, and is robust to optimization-based and strong adaptive attacks. The code is available at https://github.com/sleeepeer/PISanitizer.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u95ee\u9898\uff0c\u63d0\u51faPISanitizer\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4f4d\u548c\u51c0\u5316\u5173\u952e\u6ce8\u5165\u4ee4\u724c\u6709\u6548\u9632\u5fa1\u653b\u51fb\u3002", "motivation": "\u73b0\u6709\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u65b9\u6848\u9488\u5bf9\u77ed\u4e0a\u4e0b\u6587\u8bbe\u8ba1\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u6548\u679c\u6709\u9650\uff0c\u56e0\u6ce8\u5165\u6307\u4ee4\u4ec5\u5360\u957f\u6587\u672c\u6781\u5c0f\u6bd4\u4f8b\u96be\u4ee5\u68c0\u6d4b\uff0c\u4e9f\u9700\u6709\u6548\u9632\u5fa1\u673a\u5236\u3002", "method": "\u5229\u7528LLM\u9075\u5faa\u6307\u4ee4\u7279\u6027\u53ca\u6ce8\u610f\u529b\u673a\u5236\u539f\u7406\uff0c\u9996\u5148\u8bf1\u5bfc\u6a21\u578b\u6267\u884c\u4efb\u610f\u4e0a\u4e0b\u6587\u6307\u4ee4\uff0c\u540e\u9ad8\u6ce8\u610f\u529b\u9a71\u52a8\u6307\u4ee4\u884c\u4e3a\u7684\u5173\u952e\u4ee4\u724c\u8fdb\u884c\u51c0\u5316\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660ePISanitizer\u80fd\u6210\u529f\u9632\u5fa1\u63d0\u793a\u6ce8\u5165\u3001\u4fdd\u6301\u6a21\u578b\u6548\u7528\u3001\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\uff0c\u9ad8\u6548\u4e14\u6297\u4f18\u5316\u653b\u51fb\u4e0e\u5f3a\u81ea\u9002\u5e94\u653b\u51fb\u3002", "conclusion": "\u63d0\u51fa\u9996\u4e2a\u957f\u4e0a\u4e0b\u6587\u63d0\u793a\u6ce8\u5165\u9632\u5fa1\u65b9\u6848\uff0c\u4ee5\u6ce8\u610f\u529b\u5206\u6790\u4e3a\u6838\u5fc3\u5f62\u6210\u653b\u51fb\u8005\u4e24\u96be\u56f0\u5883\uff1a\u6307\u4ee4\u5f3a\u5236\u529b\u8d8a\u5f3a\u88ab\u51c0\u5316\u6982\u7387\u8d8a\u9ad8\uff0c\u4e3a\u5b9e\u7528\u5316\u9632\u5fa1\u5f00\u8f9f\u65b0\u8def\u5f84\u3002"}}
{"id": "2511.11549", "categories": ["cs.CR", "cs.DB", "cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.11549", "abs": "https://arxiv.org/abs/2511.11549", "authors": ["Shreya Meel", "Sennur Ulukus"], "title": "HetDAPAC: Leveraging Attribute Heterogeneity in Distributed Attribute-Based Private Access Control", "comment": null, "summary": "Verifying user attributes to provide fine-grained access control to databases is fundamental to attribute-based authentication. Either a single (central) authority verifies all the attributes, or multiple independent authorities verify the attributes distributedly. In the central setup, the authority verifies all user attributes, and the user downloads only the authorized record. While this is communication efficient, it reveals all user attributes to the authority. A distributed setup prevents this privacy breach by letting each authority verify and learn only one attribute. Motivated by this, Jafarpisheh~et~al. introduced an information-theoretic formulation, called distributed attribute-based private access control (DAPAC). With $N$ non-colluding authorities (servers), $N$ attributes and $K$ possible values for each attribute, the DAPAC system lets each server learn only the single attribute value that it verifies, and is oblivious to the remaining $N-1$. The user retrieves its designated record, without learning anything about the remaining database records. The goal is to maximize the rate, i.e., the ratio of desired message size to total download size. However, not all attributes are sensitive, and DAPAC's privacy constraints can be too restrictive, negatively affecting the rate. To leverage the heterogeneous privacy requirements of user attributes, we propose heterogeneous (Het)DAPAC, a framework which off-loads verification of $N-D$ of the $N$ attributes to a central server, and retains DAPAC's architecture for the $D$ sensitive attributes. We first present a HetDAPAC scheme, which improves the rate from $\\frac{1}{2K}$ to $\\frac{1}{K+1}$, while sacrificing the privacy of a few non-sensitive attributes. Unlike DAPAC, our scheme entails a download imbalance across servers; we propose a second scheme achieving a balanced per-server download and a rate of $\\frac{D+1}{2KD}$.", "AI": {"tldr": "\"HetDAPAC\"\u662f\u5728\u5206\u5e03\u5f0f\u57fa\u4e8e\u5c5e\u6027\u7684\u79c1\u6709\u8bbf\u95ee\u63a7\u5236\uff08DAPAC\uff09\u6846\u67b6\u57fa\u7840\u4e0a\u63d0\u51fa\u7684\u6539\u8fdb\u65b9\u6848\u3002\u4f5c\u8005\u4eec\u9488\u5bf9\u7528\u6237\u5c5e\u6027\u7684\u5f02\u6784\u9690\u79c1\u8981\u6c42\uff0c\u901a\u8fc7\u5c06\u90e8\u5206\u975e\u654f\u611f\u5c5e\u6027\u7684\u9a8c\u8bc1\u96c6\u4e2d\u5316\u5904\u7406\uff0c\u5728\u727a\u7272\u5c11\u91cf\u975e\u654f\u611f\u5c5e\u6027\u7684\u540c\u65f6\u5bf9DAPAC\u8fdb\u884c\u4f18\u5316\u3002HetDAPAC\u4ee5\u975e\u5e73\u8861\u670d\u52a1\u5668\u4e0b\u8f7d\u8d1f\u8f7d\u4e3a\u4ee3\u4ef7\u5c06\u7cfb\u7edf\u7684\u4f20\u8f93\u7387\u4ece\u539f\u6765\u7684\u6bcf\u5c5e\u6027${1}/{2K}$\u63d0\u5347\u81f3${1}/{K+1}$\uff1b\u968f\u540e\u53e6\u4e00\u7248\u672c\u65b9\u6848\u5b9e\u73b0\u4e86\u5404\u670d\u52a1\u5668\u4e0b\u8f7d\u8d1f\u8f7d\u5e73\u8861\u4e0b\uff0c\u7cfb\u7edf\u7684\u4f20\u8f93\u7387\u63d0\u9ad8\u5230${(D+1)}/{2KD}$\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5cDAPAC\u5bf9\u4e8e\u6240\u6709\u7528\u6237\u5c5e\u6027\u5747\u91c7\u53d6\u4e00\u89c6\u540c\u4ec1\u7684\u9690\u79c1\u4fdd\u62a4\u5f3a\u5ea6\u7b56\u7565\uff0c\u4f46\u5b9e\u9645\u60c5\u51b5\u662f\u4e00\u4e9b\u7528\u6237\u5c5e\u6027\u5e76\u4e0d\u654f\u611f\uff0c\u56e0\u6b64\u73b0\u6709DAPAC\u65b9\u6848\u4f20\u8f93\u6548\u7387\u8f83\u4f4e\u3002\u9488\u5bf9\u6b64\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5206\u5c42\u7ed3\u6784\u6846\u67b6\u201cHetDAPAC\u201d\uff0c\u65e8\u5728\u5bf9\u7528\u6237\u654f\u611f\u5c5e\u6027\u4ecd\u91c7\u7528\u5206\u5e03\u5f0f\u7684DAPAC\u65b9\u6848\u4ee5\u4fdd\u8bc1\u9690\u79c1\u5b89\u5168\u6027\uff1b\u5bf9\u975e\u654f\u611f\u6027\u5c5e\u6027\u5219\u901a\u8fc7\u4e2d\u592e\u670d\u52a1\u5668\u96c6\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u800c\u4e0d\u9700\u518d\u9690\u79c1\u4fdd\u62a4\uff0c\u8fd9\u6837\u63d0\u9ad8\u6574\u4e2a\u7cfb\u7edf\u7684\u4f20\u8f93\u7387\u3002", "method": "HetDAPAC\u6846\u67b6\u5c06\u6d89\u53caN\u4e2a\u5c5e\u6027\u7684\u7cfb\u7edf\u4e2d\u5b58\u5728D\u4e2a\u654f\u611f\u5c5e\u6027\u4e0eN-D\u4e2a\u975e\u654f\u611f\u5c5e\u6027\u5206\u5f00\u5904\u7406\u2014\u5bf9\u4e8e\u654f\u611f\u5c5e\u6027\u7ee7\u7eed\u4f7f\u7528\u5206\u5e03\u5f0f\u3001\u591a\u670d\u52a1\u5668\u67b6\u6784\u5404\u4fdd\u62a4\u5176\u4e2d\u4e00\u9879\u5c5e\u6027\uff1b\u5bf9\u4e8e\u975e\u654f\u611f\u5c5e\u6027\u7684\u9a8c\u8bc1\uff0c\u5219\u8f6c\u79fb\u5230\u4e00\u4e2a\u4e2d\u592e\u670d\u52a1\u5668\u96c6\u4e2d\u5b8c\u6210\u4ee5\u51cf\u5c11\u5206\u5e03\u5f0f\u901a\u4fe1\u5f00\u9500\u3002\u8be5\u6846\u67b6\u4e0b\u5177\u4f53\u5b9e\u73b0\u4e24\u4e2a\u65b9\u6848\uff1a\u7b2c\u4e00\u79cd\u65b9\u6848\u91c7\u7528\u975e\u5e73\u8861\u8bbe\u8ba1\uff0c\u5373\u5c06\u654f\u611f\u6570\u636e\u7684\u9a8c\u8bc1\u4efb\u52a1\u5206\u5e03\u4e8eD\u4e2a\u670d\u52a1\u5668\u5e76\u5b9e\u73b0\u4f20\u8f93\u6548\u7387\u63d0\u5347\u4e3a${1}/{K+1}$\u3002\u4e3a\u4e86\u89e3\u51b3\u4e0d\u540c\u670d\u52a1\u5668\u95f4\u7684\u8d1f\u8f7d\u5747\u8861\u95ee\u9898\uff0c\u4f5c\u8005\u968f\u540e\u63d0\u51fa\u7b2c\u4e8c\u7248\u672c\u7684\u6846\u67b6\u65b9\u6848\u5b9e\u73b0\u4e86\u5404\u670d\u52a1\u5668\u4e0b\u8f7d\u8d1f\u8f7d\u5e73\u8861\u4e0b\u4f20\u8f93\u7387\u63d0\u9ad8\u81f3${(D+1)}/{2KD}$\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff1aHetDAPAC\u9996\u6b21\u63d0\u51fa\u7684\u975e\u5e73\u8861\u65b9\u6848\u80fd\u591f\u5b9e\u73b0\u76f8\u6bd4DAPAC\u539f\u65b9\u6848\u66f4\u4f18\u7684\u4f20\u8f93\u6548\u7387\u2014\u4ece\u6bcf\u5c5e\u6027${1}/{2K}$\u63d0\u5347\u81f3${1}/{K+1}$\uff1b\u540c\u65f6\u8be5\u4ee3\u4ef7\u662f\u727a\u7272\u975e\u654f\u611f\u5c5e\u6027\u7684\u9690\u79c1\u6027\u3002\u540e\u7eed\u6539\u8fdb\u65b9\u6848\u5219\u6210\u529f\u5728\u8d1f\u8f7d\u5747\u8861\u7684\u60c5\u51b5\u4e0b\u628a\u7cfb\u7edf\u7684\u6574\u4f53\u4f20\u8f93\u7387\u63d0\u9ad8\u5230${(D+1)}/{2KD}$\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684HetDAPAC\u6846\u67b6\u80fd\u591f\u6839\u636e\u7528\u6237\u5c5e\u6027\u5b9e\u9645\u9690\u79c1\u4fdd\u62a4\u8981\u6c42\u7684\u5f02\u8d28\u6027\u5bf9\u4e0d\u540c\u7684\u5c5e\u6027\u65bd\u52a0\u4e0d\u540c\u5f3a\u5ea6\u7684\u9690\u79c1\u4fdd\u62a4\u7b56\u7565\u2014\u5c06\u975e\u654f\u611f\u5c5e\u6027\u96c6\u4e2d\u9a8c\u8bc1\u800c\u4e0d\u964d\u4f4e\u4f20\u8f93\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u80fd\u591f\u6210\u529f\u5728\u5206\u5e03\u5f0f\u9690\u79c1\u4fdd\u62a4\u573a\u666f\u4e2d\u63d0\u9ad8\u7cfb\u7edf\u7684\u6709\u6548\u4f20\u8f93\u7387\uff1b\u540c\u65f6\u8be5\u6846\u67b6\u4e5f\u80fd\u591f\u652f\u6301\u670d\u52a1\u5668\u95f4\u8d1f\u8f7d\u5747\u8861\u7684\u8bbe\u8ba1\u9700\u6c42\u3002"}}
