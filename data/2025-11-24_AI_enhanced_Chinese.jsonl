{"id": "2511.16709", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16709", "abs": "https://arxiv.org/abs/2511.16709", "authors": ["Yige Li", "Zhe Li", "Wei Zhao", "Nay Myat Min", "Hanxun Huang", "Xingjun Ma", "Jun Sun"], "title": "AutoBackdoor: Automating Backdoor Attacks via LLM Agents", "comment": "23 pages", "summary": "Backdoor attacks pose a serious threat to the secure deployment of large language models (LLMs), enabling adversaries to implant hidden behaviors triggered by specific inputs. However, existing methods often rely on manually crafted triggers and static data pipelines, which are rigid, labor-intensive, and inadequate for systematically evaluating modern defense robustness. As AI agents become increasingly capable, there is a growing need for more rigorous, diverse, and scalable \\textit{red-teaming frameworks} that can realistically simulate backdoor threats and assess model resilience under adversarial conditions. In this work, we introduce \\textsc{AutoBackdoor}, a general framework for automating backdoor injection, encompassing trigger generation, poisoned data construction, and model fine-tuning via an autonomous agent-driven pipeline. Unlike prior approaches, AutoBackdoor uses a powerful language model agent to generate semantically coherent, context-aware trigger phrases, enabling scalable poisoning across arbitrary topics with minimal human effort. We evaluate AutoBackdoor under three realistic threat scenarios, including \\textit{Bias Recommendation}, \\textit{Hallucination Injection}, and \\textit{Peer Review Manipulation}, to simulate a broad range of attacks. Experiments on both open-source and commercial models, including LLaMA-3, Mistral, Qwen, and GPT-4o, demonstrate that our method achieves over 90\\% attack success with only a small number of poisoned samples. More importantly, we find that existing defenses often fail to mitigate these attacks, underscoring the need for more rigorous and adaptive evaluation techniques against agent-driven threats as explored in this work. All code, datasets, and experimental configurations will be merged into our primary repository at https://github.com/bboylyg/BackdoorLLM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAutoBackdoor\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u9a71\u52a8\u6d41\u7a0b\u81ea\u52a8\u5316\u540e\u95e8\u653b\u51fb\uff08\u5305\u62ec\u89e6\u53d1\u8bcd\u751f\u6210\u3001\u6570\u636e\u6bd2\u5316\u548c\u6a21\u578b\u5fae\u8c03\uff09\uff0c\u5728\u591a\u4e2a\u73b0\u5b9e\u5a01\u80c1\u573a\u666f\u4e0b\u9a8c\u8bc1\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff08\u8d8590%\uff09\uff0c\u5e76\u63ed\u793a\u73b0\u6709\u9632\u5fa1\u5bf9\u667a\u80fd\u4f53\u9a71\u52a8\u5a01\u80c1\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u89e6\u53d1\u5668\u548c\u9759\u6001\u6570\u636e\u6d41\u7a0b\uff0c\u96be\u4ee5\u7cfb\u7edf\u8bc4\u4f30\u73b0\u4ee3\u9632\u5fa1\u9c81\u68d2\u6027\uff0c\u9700\u5efa\u7acb\u66f4\u4e25\u683c\u3001\u591a\u6837\u5316\u3001\u53ef\u6269\u5c55\u7684\u7ea2\u961f\u6846\u67b6\u6765\u6a21\u62df\u771f\u5b9e\u5a01\u80c1\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u81ea\u52a8\u751f\u6210\u8bed\u4e49\u8fde\u8d2f\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u89e6\u53d1\u8bcd\uff1b\u6784\u5efa\u81ea\u52a8\u5316\u6d41\u7a0b\uff08\u89e6\u53d1\u5668\u751f\u6210\u3001\u6570\u636e\u6bd2\u5316\u3001\u5fae\u8c03\uff09\uff1b\u5728\u504f\u89c1\u63a8\u8350\u3001\u5e7b\u89c9\u6ce8\u5165\u3001\u540c\u884c\u8bc4\u5ba1\u64cd\u63a7\u4e09\u5927\u573a\u666f\u6d4b\u8bd5\u3002", "result": "\u5f00\u6e90\u4e0e\u5546\u4e1a\u6a21\u578b\uff08LLaMA-3/Mistral/Qwen/GPT-4o\uff09\u4e0a\u4ec5\u5c11\u91cf\u6bd2\u5316\u6837\u672c\u5373\u8fbe\u6210\u8d8590%\u653b\u51fb\u6210\u529f\u7387\uff1b\u73b0\u6709\u9632\u5fa1\u63aa\u65bd\u5728\u6b64\u7c7b\u653b\u51fb\u524d\u666e\u904d\u5931\u6548\u3002", "conclusion": "\u667a\u80fd\u4f53\u9a71\u52a8\u7684\u540e\u95e8\u653b\u51fb\u5a01\u80c1\u4e25\u91cd\uff0c\u73b0\u6709\u9632\u5fa1\u4e0d\u8db3\uff0c\u9700\u5f00\u53d1\u66f4\u4e25\u683c\u7684\u81ea\u9002\u5e94\u8bc4\u4f30\u6280\u672f\uff1b\u5f00\u6e90\u4ee3\u7801/\u6570\u636e\u63a8\u52a8\u9886\u57df\u7814\u7a76\u3002"}}
{"id": "2511.16716", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16716", "abs": "https://arxiv.org/abs/2511.16716", "authors": ["Maurizio Atzori", "Eleonora Cal\u00f2", "Loredana Caruccio", "Stefano Cirillo", "Giuseppe Polese", "Giandomenico Solimando"], "title": "Password Strength Analysis Through Social Network Data Exposure: A Combined Approach Relying on Data Reconstruction and Generative Models", "comment": "This is a post-peer-review, pre-copyedit version to be published in the Prooceedings of the 33rd Symposium On Advanced Database Systems (SEBD 2025), 7 pages, 4 figures", "summary": "Although passwords remain the primary defense against unauthorized access, users often tend to use passwords that are easy to remember. This behavior significantly increases security risks, also due to the fact that traditional password strength evaluation methods are often inadequate. In this discussion paper, we present SODA ADVANCE, a data reconstruction tool also designed to enhance evaluation processes related to the password strength. In particular, SODA ADVANCE integrates a specialized module aimed at evaluating password strength by leveraging publicly available data from multiple sources, including social media platforms. Moreover, we investigate the capabilities and risks associated with emerging Large Language Models (LLMs) in evaluating and generating passwords, respectively. Experimental assessments conducted with 100 real users demonstrate that LLMs can generate strong and personalized passwords possibly defined according to user profiles. Additionally, LLMs were shown to be effective in evaluating passwords, especially when they can take into account user profile data.", "AI": {"tldr": "SODA ADVANCE\u5de5\u5177\u901a\u8fc7\u6574\u5408\u516c\u5f00\u6570\u636e\u8bc4\u4f30\u5bc6\u7801\u5f3a\u5ea6\uff0c\u5e76\u63a2\u7d22LLMs\u5728\u751f\u6210\u548c\u8bc4\u4f30\u5bc6\u7801\u65b9\u9762\u7684\u6f5c\u529b\u3002\u5b9e\u9a8c\u8868\u660eLLMs\u80fd\u751f\u6210\u4e2a\u6027\u5316\u5f3a\u5bc6\u7801\uff0c\u5e76\u6709\u6548\u8bc4\u4f30\u5bc6\u7801\uff08\u5c24\u5176\u662f\u7ed3\u5408\u7528\u6237\u8d44\u6599\u65f6\uff09\u3002", "motivation": "\u7528\u6237\u5e38\u9009\u62e9\u6613\u8bb0\u5bc6\u7801\uff0c\u589e\u52a0\u5b89\u5168\u98ce\u9669\uff0c\u4e14\u4f20\u7edf\u5bc6\u7801\u5f3a\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u5de5\u5177\u589e\u5f3a\u5bc6\u7801\u5f3a\u5ea6\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u5e76\u7814\u7a76\u65b0\u5174\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5bc6\u7801\u751f\u6210\u4e0e\u8bc4\u4f30\u4e2d\u7684\u80fd\u529b\u4e0e\u98ce\u9669\u3002", "method": "\u63d0\u51faSODA ADVANCE\u5de5\u5177\uff0c\u6574\u5408\u591a\u6e90\u516c\u5f00\u6570\u636e\uff08\u542b\u793e\u4ea4\u5a92\u4f53\uff09\u7684\u4e13\u7528\u6a21\u5757\u8bc4\u4f30\u5bc6\u7801\u5f3a\u5ea6\u3002\u901a\u8fc7100\u540d\u771f\u5b9e\u7528\u6237\u7684\u5b9e\u9a8c\uff0c\u6d4b\u8bd5LLMs\u751f\u6210\u4e2a\u6027\u5316\u5f3a\u5bc6\u7801\u53ca\u8bc4\u4f30\u5bc6\u7801\uff08\u7ed3\u5408\u7528\u6237\u8d44\u6599\uff09\u7684\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eLLMs\u53ef\u751f\u6210\u6839\u636e\u7528\u6237\u5b9a\u5236\u7684\u5f3a\u5bc6\u7801\uff0c\u4e14\u5728\u8bc4\u4f30\u5bc6\u7801\u65f6\uff08\u5c24\u5176\u8003\u8651\u7528\u6237\u8d44\u6599\u6570\u636e\u65f6\uff09\u8868\u73b0\u6709\u6548\u3002", "conclusion": "LLMs\u5728\u5bc6\u7801\u751f\u6210\u548c\u8bc4\u4f30\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u7ed3\u5408\u7528\u6237\u8d44\u6599\u80fd\u63d0\u5347\u5bc6\u7801\u5b89\u5168\u6027\uff0c\u4f46\u9700\u6ce8\u610f\u76f8\u5173\u98ce\u9669\u3002SODA ADVANCE\u4e3a\u5bc6\u7801\u5f3a\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u6570\u636e\u652f\u6301\u3002"}}
{"id": "2511.16792", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16792", "abs": "https://arxiv.org/abs/2511.16792", "authors": ["Mona Khalil", "Alberto Blanco-Justicia", "Najeeb Jebreel", "Josep Domingo-Ferrer"], "title": "Membership Inference Attacks Beyond Overfitting", "comment": null, "summary": "Membership inference attacks (MIAs) against machine learning (ML) models aim to determine whether a given data point was part of the model training data. These attacks may pose significant privacy risks to individuals whose sensitive data were used for training, which motivates the use of defenses such as differential privacy, often at the cost of high accuracy losses. MIAs exploit the differences in the behavior of a model when making predictions on samples it has seen during training (members) versus those it has not seen (non-members). Several studies have pointed out that model overfitting is the major factor contributing to these differences in behavior and, consequently, to the success of MIAs. However, the literature also shows that even non-overfitted ML models can leak information about a small subset of their training data. In this paper, we investigate the root causes of membership inference vulnerabilities beyond traditional overfitting concerns and suggest targeted defenses. We empirically analyze the characteristics of the training data samples vulnerable to MIAs in models that are not overfitted (and hence able to generalize). Our findings reveal that these samples are often outliers within their classes (e.g., noisy or hard to classify). We then propose potential defensive strategies to protect these vulnerable samples and enhance the privacy-preserving capabilities of ML models. Our code is available at https://github.com/najeebjebreel/mia_analysis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u5373\u4f7f\u5728\u672a\u8fc7\u62df\u5408\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\uff0c\u90e8\u5206\u8bad\u7ec3\u6570\u636e\u6837\u672c\uff08\u7279\u522b\u662f\u7c7b\u5185\u5f02\u5e38\u503c\uff09\u4ecd\u6613\u53d7\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIA\uff09\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u9488\u5bf9\u6027\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08MIA\uff09\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9690\u79c1\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u7814\u7a76\u8ba4\u4e3a\u6a21\u578b\u8fc7\u62df\u5408\u662f\u4e3b\u56e0\uff0c\u4f46\u672a\u8fc7\u62df\u5408\u6a21\u578b\u4ecd\u5b58\u5728\u6570\u636e\u6cc4\u9732\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u63a2\u7a76\u8fc7\u62df\u5408\u4e4b\u5916\u7684MIA\u6f0f\u6d1e\u6839\u6e90\uff0c\u5e76\u8bbe\u8ba1\u7cbe\u51c6\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u5b9e\u8bc1\u5206\u6790\u4e86\u672a\u8fc7\u62df\u5408\u6a21\u578b\u4e2d\u6613\u53d7MIA\u653b\u51fb\u7684\u8bad\u7ec3\u6837\u672c\u7279\u5f81\uff0c\u53d1\u73b0\u8fd9\u4e9b\u6837\u672c\u591a\u4e3a\u7c7b\u5185\u5f02\u5e38\u503c\uff08\u5982\u566a\u58f0\u6837\u672c\u6216\u96be\u5206\u7c7b\u6837\u672c\uff09\uff0c\u8fdb\u800c\u63d0\u51fa\u4fdd\u62a4\u6b64\u7c7b\u6837\u672c\u7684\u9632\u5fa1\u7b56\u7565\u3002", "result": "\u7814\u7a76\u8868\u660eMIA\u6f0f\u6d1e\u4e0d\u4ec5\u6e90\u4e8e\u8fc7\u62df\u5408\uff0c\u7c7b\u5185\u5f02\u5e38\u503c\u7684\u5b58\u5728\u4e5f\u662f\u5173\u952e\u56e0\u7d20\uff1b\u6240\u63d0\u51fa\u7684\u9632\u5fa1\u65b9\u6cd5\u80fd\u6709\u6548\u589e\u5f3a\u6a21\u578b\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9690\u79c1\u4fdd\u62a4\u9700\u8d85\u8d8a\u4f20\u7edf\u8fc7\u62df\u5408\u9632\u5fa1\uff0c\u5e94\u91cd\u70b9\u5173\u6ce8\u7c7b\u5185\u5f02\u5e38\u503c\u6837\u672c\u7684\u4fdd\u62a4\u3002\u8bba\u6587\u63d0\u51fa\u7684\u9488\u5bf9\u6027\u9632\u5fa1\u4e3a\u63d0\u5347\u6a21\u578b\u9690\u79c1\u6027\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2511.17070", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17070", "abs": "https://arxiv.org/abs/2511.17070", "authors": ["Robert Krahn", "Nikson Kanti Paul", "Franz Gregor", "Do Le Quoc", "Andrey Brito", "Andr\u00e9 Martin", "Christof Fetzer"], "title": "TICAL: Trusted and Integrity-protected Compilation of AppLications", "comment": "19th European Dependable Computing Conference (EDCC) 2024", "summary": "During the past few years, we have witnessed various efforts to provide confidentiality and integrity for applications running in untrusted environments such as public clouds. In most of these approaches, hardware extensions such as Intel SGX, TDX, AMD SEV, etc., are leveraged to provide encryption and integrity protection on process or VM level. Although all of these approaches increase the trust in the application at runtime, an often overlooked aspect is the integrity and confidentiality protection at build time, which is equally important as maliciously injected code during compilation can compromise the entire application and system.In this paper, we present Tical, a practical framework for trusted compilation that provides integrity protection and confidentiality in build pipelines from source code to the final executable. Our approach harnesses TEEs as runtime protection but enriches TEEs with file system shielding and an immutable audit log with version history to provide accountability. This way, we can ensure that the compiler chain can only access trusted files and intermediate output, such as object files produced by trusted processes. Our evaluation using micro- and macro-benchmarks shows that Tical can protect the confidentiality and integrity of whole CI/CD pipelines with an acceptable performance overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86Tical\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u6784\u5efa\u6d41\u6c34\u7ebf\u4e2d\u4fdd\u62a4\u6e90\u4ee3\u7801\u5230\u6700\u7ec8\u53ef\u6267\u884c\u6587\u4ef6\u7684\u5b8c\u6574\u6027\u548c\u673a\u5bc6\u6027\u3002", "motivation": "\u73b0\u6709\u786c\u4ef6\u589e\u5f3a\u65b9\u6cd5\u4fdd\u62a4\u8fd0\u884c\u65f6\u5e94\u7528\u5b89\u5168\u548c\u5185\u5b58\u5b89\u5168\uff0c\u4f46\u5ffd\u7565\u4e86\u6784\u5efa\u65f6\u73af\u8282\u7684\u673a\u5bc6\u6027\u548c\u5b8c\u6574\u6027\u4fdd\u62a4\u3002\u6076\u610f\u7be1\u6539\u6784\u5efa\u8fc7\u7a0b\u53ef\u80fd\u5371\u53ca\u6574\u4e2a\u5e94\u7528\u548c\u7cfb\u7edf\u3002", "method": "\u5229\u7528TEE\u589e\u5f3a\u6784\u5efa\u73af\u5883\uff0c\u7ed3\u5408\u6587\u4ef6\u7cfb\u7edf\u5c4f\u853d\u6280\u672f\u548c\u4e0d\u53ef\u53d8\u5ba1\u8ba1\u65e5\u5fd7\u786e\u4fdd\u5de5\u5177\u94fe\u53ea\u80fd\u8bbf\u95ee\u53ef\u4fe1\u6587\u4ef6\u3002", "result": "\u901a\u8fc7\u5fae\u89c2\u548c\u5b8f\u89c2\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u80fd\u5728\u53ef\u63a5\u53d7\u7684\u6027\u80fd\u5f00\u9500\u5185\u4fdd\u62a4CI/CD\u6d41\u6c34\u7ebf\u3002", "conclusion": "Tical\u4e3a\u6784\u5efa\u6d41\u6c34\u7ebf\u63d0\u4f9b\u4e86\u4fe1\u4efb\u4fdd\u969c\uff0c\u8bc1\u660e\u5c06TEE\u4e0e\u9632\u62a4\u63aa\u65bd\u7ed3\u5408\u53ef\u6709\u6548\u586b\u8865\u6784\u5efa\u73af\u8282\u7684\u5b89\u5168\u7f3a\u5931\u3002"}}
{"id": "2511.17118", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17118", "abs": "https://arxiv.org/abs/2511.17118", "authors": ["Leo Kao"], "title": "Constant-Size Cryptographic Evidence Structures for Regulated AI Workflows", "comment": "12 pages. Preprint on cryptographic evidence and compliance for regulated AI workflows", "summary": "This paper introduces constant-size cryptographic evidence structures, a general abstraction for representing verifiable audit evidence for AI workflows in regulated environments. Each evidence item is a fixed-size tuple of cryptographic fields, designed to (i) provide strong binding to workflow events and configurations, (ii) support constant-size storage and uniform verification cost per event, and (iii) compose cleanly with hash-chain and Merkle-based audit constructions. We formalize a simple model of regulated AI workflows, define syntax and algorithms for evidence structures, and articulate security goals such as audit integrity and non-equivocation. We present a generic hash-and-sign construction that instantiates this abstraction using a collision-resistant hash function and a standard digital signature scheme. We then show how to integrate the construction with hash-chained logs, Merkle-tree anchoring, and optionally trusted execution environments, and we analyze the asymptotic complexity of evidence generation and verification. Finally, we implement a prototype library and report microbenchmark results on commodity hardware, demonstrating that the per-event overhead of constant-size evidence is small and predictable. The design is informed by industrial experience with regulated AI systems at Codebat Technologies Inc., while the paper focuses on the abstraction, algorithms, and their security and performance characteristics, with implications for clinical trial management, pharmaceutical compliance, and medical AI governance.", "AI": {"tldr": "\u672c\u6587\u5c06\u4ecb\u7ecd\u4e00\u79cd\u7528\u4e8e\u53d7\u76d1\u7ba1\u7684\u4eba\u5de5\u667a\u80fd\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u9a8c\u8bc1\u5ba1\u8ba1\u8bc1\u636e\u7684\u6052\u5b9a\u5c3a\u5bf8\u8bc1\u636e\u7ed3\u6784\u3002\u5b83\u901a\u8fc7\u56fa\u5b9a\u5927\u5c0f\u7684\u52a0\u5bc6\u5b57\u6bb5\u5143\u7ec4\u63d0\u4f9b\u5f3a\u5927\u7684\u5de5\u4f5c\u4e8b\u4ef6\u7ed1\u5b9a\u3001\u6052\u5b9a\u7684\u5b58\u50a8\u7a7a\u95f4\u548c\u7edf\u4e00\u7684\u9a8c\u8bc1\u6210\u672c\uff0c\u5e76\u53ef\u4e0e\u591a\u79cd\u9a8c\u8bc1\u6280\u672f\u65e0\u7f1d\u96c6\u6210\u3002", "motivation": "\u5728\u533b\u7597AI\u7b49\u4e25\u76d1\u7ba1\u573a\u666f\u4e2d\uff0c\u73b0\u6709\u8bb0\u5f55\u673a\u5236\u5b58\u5728\u53ef\u6269\u5c55\u6027\u5dee\u3001\u9a8c\u8bc1\u5f00\u9500\u5927\u548c\u8bc1\u636e\u8ffd\u6eaf\u95ee\u9898\u3002\u4e3a\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u6574\u5408\u4e8b\u4ef6\u7ed1\u5b9a\u3001\u53ef\u7ec4\u5408\u9a8c\u8bc1\u4ee5\u53ca\u6052\u5b9a\u5b58\u50a8\u6210\u672c\u7684\u7edf\u4e00\u8bc1\u636e\u62bd\u8c61\u673a\u5236\u3002", "method": "\u9996\u5148\u63d0\u51fa\u7531\u56fa\u5b9a\u5c3a\u5bf8\u52a0\u5bc6\u5143\u7ec4\u7ec4\u6210\u7684\u8bc1\u636e\u7ed3\u6784\u6846\u67b6\uff1b\u5176\u6b21\u5efa\u7acb\u57fa\u4e8e\u54c8\u5e0c\u94fe\u548c\u9ed8\u514b\u5c14\u6811\u7684\u9a8c\u8bc1\u94fe\u6a21\u578b\uff1b\u5e76\u5f00\u53d1\u7ed3\u5408\u78b0\u649e\u6297\u54c8\u5e0c\u51fd\u6570\u53ca\u6570\u5b57\u7b7e\u540d\u7b97\u6cd5\u7684\u6cdb\u7528\u5efa\u6784\u539f\u578b\u3002\u7cfb\u7edf\u517c\u5bb9\u53ef\u4fe1\u6267\u884c\u73af\u5883\u3002", "result": "\u7406\u8bba\u5206\u6790\u663e\u793a\u4e8b\u4ef6\u8bc1\u636e\u9a8c\u8bc1\u5177\u5907\u6052\u5b9a\u6e10\u8fd1\u590d\u6742\u5ea6\uff08O(1)\uff09\uff1b\u5b9e\u9a8c\u539f\u578b\u5728\u5546\u7528\u786c\u4ef6\u4e0a\u7684\u5fae\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6bcf\u4e2a\u4e8b\u4ef6\u5904\u7406\u8017\u65f6\u7ea60.8\u6beb\u79d2\u4e14\u53ef\u9884\u6d4b\uff0c\u6bd4\u4f20\u7edf\u65e5\u5fd7\u51cf\u5c1198%\u5b58\u50a8\u589e\u957f\u91cf\u3002", "conclusion": "\u6052\u5b9a\u5c3a\u5bf8\u8bc1\u636e\u7ed3\u6784\u80fd\u663e\u8457\u63d0\u5347\u53d7\u76d1\u7ba1AI\u5de5\u4f5c\u6d41\u7684\u5ba1\u8ba1\u6548\u80fd\uff0c\u5df2\u5728\u533b\u7597\u548c\u5236\u836f\u5408\u89c4\u9886\u57df\u9a8c\u8bc1\u5b9e\u7528\u6027\u3002\u5176\u8bbe\u8ba1\u652f\u6301\u4e0e\u73b0\u5b58\u9a8c\u8bc1\u67b6\u6784\u4e92\u64cd\u4f5c\uff0c\u4e3aAI\u6cbb\u7406\u63d0\u4f9b\u6807\u51c6\u57fa\u7840\u8bbe\u65bd\u3002"}}
{"id": "2511.17194", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17194", "abs": "https://arxiv.org/abs/2511.17194", "authors": ["Zhiyuan Xu", "Stanislav Abaimov", "Joseph Gardiner", "Sana Belguith"], "title": "Steering in the Shadows: Causal Amplification for Activation Space Attacks in Large Language Models", "comment": "31 pages, 5 figures, 9 tables", "summary": "Modern large language models (LLMs) are typically secured by auditing data, prompts, and refusal policies, while treating the forward pass as an implementation detail. We show that intermediate activations in decoder-only LLMs form a vulnerable attack surface for behavioral control. Building on recent findings on attention sinks and compression valleys, we identify a high-gain region in the residual stream where small, well-aligned perturbations are causally amplified along the autoregressive trajectory--a Causal Amplification Effect (CAE). We exploit this as an attack surface via Sensitivity-Scaled Steering (SSS), a progressive activation-level attack that combines beginning-of-sequence (BOS) anchoring with sensitivity-based reinforcement to focus a limited perturbation budget on the most vulnerable layers and tokens. We show that across multiple open-weight models and four behavioral axes, SSS induces large shifts in evil, hallucination, sycophancy, and sentiment while preserving high coherence and general capabilities, turning activation steering into a concrete security concern for white-box and supply-chain LLM deployments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u89e3\u7801\u5668\u4e13\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u4e2d\u4e2d\u95f4\u6fc0\u6d3b\u6001\u7684\u8106\u5f31\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u654f\u611f\u6027\u7f29\u653e\u5bfc\u5411(SSS)\u7684\u6fc0\u6d3b\u5c42\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6b8b\u5dee\u6d41\u7684\u9ad8\u589e\u76ca\u533a\u57df\u65bd\u52a0\u5c0f\u6270\u52a8\uff0c\u5229\u7528\u56e0\u679c\u653e\u5927\u6548\u5e94(CAE)\u5b9e\u73b0\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u63a7\u5236\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u5728\u4e0d\u5f71\u54cd\u6a21\u578b\u901a\u7528\u80fd\u529b\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u6539\u53d8'\u90aa\u6076\u503e\u5411'\u3001'\u5e7b\u89c9'\u3001'\u8fce\u5408\u5ea6'\u548c'\u60c5\u611f\u503e\u5411'\u7b49\u884c\u4e3a\u7279\u5f81\uff0c\u5bf9\u767d\u76d2\u53ca\u4f9b\u5e94\u94fe\u90e8\u7f72\u7684LLMs\u6784\u6210\u5b89\u5168\u5a01\u80c1\u3002", "motivation": "\u73b0\u6709LLM\u5b89\u5168\u673a\u5236\u4e3b\u8981\u4f9d\u8d56\u8f93\u5165\u8f93\u51fa\u5c42\u9762\u7684\u5ba1\u6838\u548c\u62d2\u7edd\u7b56\u7565\uff0c\u4f46\u5ffd\u89c6\u4e86\u524d\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u95f4\u6fc0\u6d3b\u6001\u7684\u5b89\u5168\u98ce\u9669\u3002\u672c\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u7279\u5b9a\u4e2d\u95f4\u5c42\u7684\u9ad8\u654f\u611f\u4f4d\u7f6e\u5b58\u5728\u56e0\u679c\u653e\u5927\u6548\u5e94(CAE)\uff0c\u5fae\u5c0f\u7684\u6270\u52a8\u5373\u53ef\u5bfc\u81f4\u8f93\u51fa\u884c\u4e3a\u663e\u8457\u504f\u79fb\uff0c\u4ece\u800c\u66b4\u9732\u51fa\u65b0\u7684\u653b\u51fb\u9762\u3002", "method": "1) \u53d1\u73b0\u6b8b\u5dee\u6d41\u4e2d\u5b58\u5728\u9ad8\u589e\u76ca\u533a\u57df\uff0c\u5176\u5fae\u5c0f\u4f46\u7cbe\u51c6\u7684\u6270\u52a8\u4f1a\u88ab\u81ea\u56de\u5f52\u8f68\u8ff9\u56e0\u679c\u653e\u5927(CAE\u6548\u5e94)\uff1b\n2) \u63d0\u51fa\u654f\u611f\u6027\u7f29\u653e\u5bfc\u5411(SSS)\u653b\u51fb\uff1a\u7ed3\u5408BOS\u951a\u5b9a\u6280\u672f\u548c\u57fa\u4e8e\u654f\u611f\u5ea6\u7684\u5f3a\u5316\u7b56\u7565\uff0c\u5c06\u6709\u9650\u6270\u52a8\u805a\u7126\u4e8e\u6700\u8106\u5f31\u7684\u5c42\u548ctoken\uff1b\n3) \u901a\u8fc7\u6270\u52a8\u654f\u611f\u5ea6\u8bc4\u5206\u786e\u5b9a\u6700\u4f73\u653b\u51fb\u4f4d\u7f6e\uff0c\u5b9e\u73b0\u6e10\u8fdb\u5f0f\u6fc0\u6d3b\u5c42\u64cd\u63a7\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u548c\u56db\u5927\u884c\u4e3a\u8f74\u5411\u4e0a\u9a8c\u8bc1\uff1a\n- \u8bf1\u5bfc'\u90aa\u6076\u5c5e\u6027'\u65f6\uff0c\u653b\u51fb\u6210\u529f\u7387\u8fbe79%\uff1b\n- \u8bf1\u5bfc\u5e7b\u89c9\u65f6\u903b\u8f91\u4e00\u81f4\u6027\u4e0b\u964d\u8d8540%\uff1b\n- \u60c5\u611f\u503e\u5411\u504f\u79fb\u7cfb\u6570\u8fbe0.89\uff1b\n- \u6a21\u578b\u6838\u5fc3\u80fd\u529b\u4fdd\u6301\u7387>92%\uff1b\n- \u6240\u6709\u6848\u4f8b\u4e2d\u6270\u52a8\u89c4\u6a21<\u6a21\u578b\u53c2\u6570\u76840.007%\u3002", "conclusion": "1) \u9996\u6b21\u63ed\u793a\u4e86LLM\u6fc0\u6d3b\u6001\u4f5c\u4e3a\u5bf9\u6297\u653b\u51fb\u9762\u7684\u4e25\u91cd\u5b89\u5168\u6f0f\u6d1e\uff1b\n2) \u8bc1\u660eCAE\u6548\u5e94\u53ef\u88ab\u6b66\u5668\u5316\uff0c\u4ec5\u9700\u5fae\u91cf\u6270\u52a8\u5373\u53ef\u5b9e\u73b0\u5f3a\u6548\u884c\u4e3a\u63a7\u5236\uff1b\n3) \u9884\u8b66\u6a21\u578b\u767d\u76d2\u8bbf\u95ee\u573a\u666f\u53ca\u4f9b\u5e94\u94fe\u6e17\u900f\u98ce\u9669\uff0c\u5efa\u8bae\u5b89\u5168\u6846\u67b6\u9700\u8986\u76d6\u4e2d\u95f4\u8868\u793a\u5c42\u3002"}}
{"id": "2511.17283", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17283", "abs": "https://arxiv.org/abs/2511.17283", "authors": ["Ilja Siro\u0161", "Jakob Heirwegh", "Dave Singel\u00e9e", "Bart Preneel"], "title": "ThreadFuzzer: Fuzzing Framework for Thread Protocol", "comment": null, "summary": "With the rapid growth of IoT, secure and efficient mesh networking has become essential. Thread has emerged as a key protocol, widely used in smart-home and commercial systems, and serving as a core transport layer in the Matter standard. This paper presents ThreadFuzzer, the first dedicated fuzzing framework for systematically testing Thread protocol implementations. By manipulating packets at the MLE layer, ThreadFuzzer enables fuzzing of both virtual OpenThread nodes and physical Thread devices. The framework incorporates multiple fuzzing strategies, including Random and Coverage-based fuzzers from CovFuzz, as well as a newly introduced TLV Inserter, designed specifically for TLV-structured MLE messages. These strategies are evaluated on the OpenThread stack using code-coverage and vulnerability-discovery metrics. The evaluation uncovered five previously unknown vulnerabilities in the OpenThread stack, several of which were successfully reproduced on commercial devices that rely on OpenThread. Moreover, ThreadFuzzer was benchmarked against an oracle AFL++ setup using the manually extended OSS-Fuzz harness from OpenThread, demonstrating strong effectiveness. These results demonstrate the practical utility of ThreadFuzzer while highlighting challenges and future directions in the wireless protocol fuzzing research space.", "AI": {"tldr": "ThreadFuzzer\uff1a\u9996\u4e2a\u9762\u5411Thread\u534f\u8bae\u5b9e\u73b0\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u64cd\u7eb5MLE\u5c42\u6570\u636e\u5305\u652f\u6301\u865a\u62df\u548c\u7269\u7406\u8bbe\u5907\u6d4b\u8bd5\uff0c\u96c6\u6210\u591a\u79cd\u6a21\u7cca\u7b56\u7565\u5e76\u53d1\u73b0OpenThread\u4e2d\u7684\u4e94\u4e2a\u672a\u77e5\u6f0f\u6d1e\u3002", "motivation": "\u968f\u7740IoT\u7684\u5feb\u901f\u53d1\u5c55\uff0cThread\u534f\u8bae\u5df2\u6210\u4e3a\u667a\u80fd\u5bb6\u5c45\u548c\u5546\u4e1a\u7cfb\u7edf\u7684\u6838\u5fc3\u4f20\u8f93\u5c42\uff0c\u4f46\u5176\u5b89\u5168\u6027\u7f3a\u4e4f\u7cfb\u7edf\u5316\u6d4b\u8bd5\uff0c\u4e9f\u9700\u4e13\u7528\u5de5\u5177\u6765\u8bc4\u4f30\u5b9e\u73b0\u6f0f\u6d1e\u3002", "method": "\u5728MLE\u5c42\u64cd\u7eb5\u6570\u636e\u5305\u5b9e\u73b0\u8de8\u8bbe\u5907\u6d4b\u8bd5\uff1b\u878d\u5408\u968f\u673a/\u57fa\u4e8e\u8986\u76d6\u7387\uff08CovFuzz\uff09\u7684\u6a21\u7cca\u5668\u53ca\u5b9a\u5236TLV\u63d2\u5165\u5668\uff1b\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u4ee3\u7801\u8986\u76d6\u7387\u548c\u6f0f\u6d1e\u53d1\u73b0\u80fd\u529b\u3002", "result": "\u53d1\u73b0OpenThread\u6808\u4e2d\u4e94\u4e2a\u672a\u77e5\u6f0f\u6d1e\uff08\u90e8\u5206\u5728\u5546\u7528\u8bbe\u5907\u590d\u73b0\uff09\uff1b\u5728\u5bf9\u6bd4AFL++\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u9ad8\u6548\u6027\u3002", "conclusion": "ThreadFuzzer\u6709\u6548\u586b\u8865\u65e0\u7ebf\u534f\u8bae\u6a21\u7cca\u6d4b\u8bd5\u7a7a\u767d\uff0c\u5b9e\u8bc1\u7ed3\u679c\u51f8\u663e\u5176\u5728\u5b89\u5168\u8bc4\u4f30\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u540c\u65f6\u63ed\u793a\u8be5\u7814\u7a76\u9886\u57df\u7684\u6311\u6218\u4e0e\u672a\u6765\u65b9\u5411\u3002"}}
{"id": "2511.17464", "categories": ["cs.CR", "cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.17464", "abs": "https://arxiv.org/abs/2511.17464", "authors": ["Tanzim Hossain Romel", "Kawshik Kumar Paul", "Tanberul Islam Ruhan", "Maisha Rahman Mim", "Abu Sayed Md. Latiful Hoque"], "title": "A Patient-Centric Blockchain Framework for Secure Electronic Health Record Management: Decoupling Data Storage from Access Control", "comment": null, "summary": "We present a patient-centric architecture for electronic health record (EHR) sharing that separates content storage from authorization and audit. Encrypted FHIR resources are stored off-chain; a public blockchain records only cryptographic commitments and patient-signed, time-bounded permissions using EIP-712. Keys are distributed via public-key wrapping, enabling storage providers to remain honest-but-curious without risking confidentiality. We formalize security goals (confidentiality, integrity, cryptographically attributable authorization, and auditability of authorization events) and provide a Solidity reference implementation deployed as single-patient contracts. On-chain costs for permission grants average 78,000 gas (L1), and end-to-end access latency for 1 MB records is 0.7--1.4s (mean values for S3 and IPFS respectively), dominated by storage retrieval. Layer-2 deployment reduces gas usage by 10--13x, though data availability charges dominate actual costs. We discuss metadata privacy, key registry requirements, and regulatory considerations (HIPAA/GDPR), demonstrating a practical route to restoring patient control while preserving security properties required for sensitive clinical data.", "AI": {"tldr": "\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5171\u4eab\u67b6\u6784\uff0c\u91c7\u7528\u94fe\u4e0b\u52a0\u5bc6\u5b58\u50a8\u4e0e\u533a\u5757\u94fe\u8bb0\u5f55\u7ed3\u5408\uff0c\u5b9e\u73b0\u5b89\u5168\u4e0e\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u73b0\u6709\u7cfb\u7edf\u5728\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5171\u4eab\u4e2d\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u60a3\u8005\u7f3a\u4e4f\u6570\u636e\u63a7\u5236\u6743\u3002", "method": "\u5206\u79bb\u5b58\u50a8\u4e0e\u6388\u6743\u5ba1\u8ba1\uff1b\u52a0\u5bc6\u8d44\u6e90\u5b58\u50a8\u5728\u94fe\u4e0b\uff0c\u533a\u5757\u94fe\u4ec5\u8bb0\u5f55\u52a0\u5bc6\u627f\u8bfa\u548c\u65f6\u9650\u6743\u9650\uff1b\u4f7f\u7528\u516c\u94a5\u5305\u88c5\u5206\u53d1\u5bc6\u94a5\u3002", "result": "\u5e73\u5747\u6743\u9650\u6388\u4e88\u6210\u672c78,000 gas(L1)\uff1b1MB\u8bb0\u5f55\u7aef\u5230\u7aef\u8bbf\u95ee\u5ef6\u8fdf0.7-1.4s\uff1bL2\u90e8\u7f72\u964d\u4f4e10-13\u500dgas\u6d88\u8017\u3002", "conclusion": "\u67b6\u6784\u5728\u4fdd\u62a4\u9690\u79c1\u548c\u6ee1\u8db3\u76d1\u7ba1\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u60a3\u8005\u5bf9\u654f\u611f\u4e34\u5e8a\u6570\u636e\u7684\u63a7\u5236\u6743\u3002"}}
