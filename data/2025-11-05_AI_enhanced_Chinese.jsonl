{"id": "2511.01898", "categories": ["cs.CR", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01898", "abs": "https://arxiv.org/abs/2511.01898", "authors": ["Hanie Vatani", "Reza Ebrahimi Atani"], "title": "FedSelect-ME: A Secure Multi-Edge Federated Learning Framework with Adaptive Client Scoring", "comment": "10 pages, 4 figures, Accepted in 6th International Conference on Soft\n  Computing (CSC2025)", "summary": "Federated Learning (FL) enables collaborative model training without sharing\nraw data but suffers from limited scalability, high communication costs, and\nprivacy risks due to its centralized architecture. This paper proposes\nFedSelect-ME, a hierarchical multi-edge FL framework that enhances scalability,\nsecurity, and energy efficiency. Multiple edge servers distribute workloads and\nperform score-based client selection, prioritizing participants based on\nutility, energy efficiency, and data sensitivity. Secure Aggregation with\nHomomorphic Encryption and Differential Privacy protects model updates from\nexposure and manipulation. Evaluated on the eICU healthcare dataset,\nFedSelect-ME achieves higher prediction accuracy, improved fairness across\nregions, and reduced communication overhead compared to FedAvg, FedProx, and\nFedSelect. The results demonstrate that the proposed framework effectively\naddresses the bottlenecks of conventional FL, offering a secure, scalable, and\nefficient solution for large-scale, privacy-sensitive healthcare applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aFedSelect-ME\u7684\u5206\u5c42\u591a\u7aef\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edfFL\u5728\u53ef\u6269\u5c55\u6027\u3001\u901a\u4fe1\u6210\u672c\u548c\u9690\u79c1\u98ce\u9669\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u591a\u8fb9\u7f18\u670d\u52a1\u5668\u5206\u53d1\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u5e76\u57fa\u4e8e\u6548\u7528\u3001\u80fd\u6548\u548c\u6570\u636e\u654f\u611f\u6027\u8fdb\u884c\u5ba2\u6237\u7aef\u9009\u62e9\uff0c\u540c\u65f6\u4f7f\u7528\u540c\u6001\u52a0\u5bc6\u548c\u5dee\u5206\u9690\u79c1\u8fdb\u884c\u5b89\u5168\u805a\u5408\u3002\u5728\u533b\u7597\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u5b58\u5728\u6269\u5c55\u6027\u3001\u9ad8\u901a\u4fe1\u6210\u672c\u548c\u9690\u79c1\u98ce\u9669\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u74f6\u9888\u5728\u654f\u611f\u7684\u533b\u7597\u5e94\u7528\u4e2d\u5c24\u4e3a\u663e\u8457\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u4fdd\u6301\u9690\u79c1\u7684\u540c\u65f6\u63d0\u9ad8\u6548\u7387\u548c\u6269\u5c55\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "FedSelect-ME\u6846\u67b6\u91c7\u7528\u4e86\u5206\u5c42\u591a\u8fb9\u7f18\u67b6\u6784\uff0c\u5176\u4e2d\u591a\u4e2a\u8fb9\u7f18\u670d\u52a1\u5668\u8d1f\u8d23\u5206\u53d1\u5de5\u4f5c\u8d1f\u8f7d\u5e76\u6267\u884c\u57fa\u4e8e\u8bc4\u5206\u7684\u5ba2\u6237\u7aef\u9009\u62e9\uff08\u8003\u8651\u6548\u7528\u3001\u80fd\u6548\u548c\u6570\u636e\u654f\u611f\u6027\uff09\u3002\u6a21\u578b\u66f4\u65b0\u901a\u8fc7\u5b89\u5168\u7684\u805a\u5408\u65b9\u6cd5\u4fdd\u62a4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u7ed3\u5408\u4e86\u540c\u6001\u52a0\u5bc6\u548c\u5dee\u5206\u9690\u79c1\u6280\u672f\u4ee5\u9632\u6b62\u6570\u636e\u66b4\u9732\u548c\u6076\u610f\u7be1\u6539\u3002", "result": "\u5728eICU\u533b\u7597\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u8f83\u4e8eFedAvg\u3001FedProx\u548cFedSelect\u7b49\u65b9\u6cd5\uff0cFedSelect-ME\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u63d0\u5347\u4e86\u8de8\u5730\u57df\u7684\u516c\u5e73\u6027\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u8054\u90a6\u5b66\u4e60\u7684\u74f6\u9888\uff0c\u4e3a\u5927\u89c4\u6a21\u4e14\u9690\u79c1\u654f\u611f\u7684\u533b\u7597\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b89\u5168\u3001\u53ef\u6269\u5c55\u548c\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01952", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01952", "abs": "https://arxiv.org/abs/2511.01952", "authors": ["Jinhua Yin", "Peiru Yang", "Chen Yang", "Huili Wang", "Zhiyang Hu", "Shangguang Wang", "Yongfeng Huang", "Tao Qi"], "title": "Black-Box Membership Inference Attack for LVLMs via Prior Knowledge-Calibrated Memory Probing", "comment": null, "summary": "Large vision-language models (LVLMs) derive their capabilities from extensive\ntraining on vast corpora of visual and textual data. Empowered by large-scale\nparameters, these models often exhibit strong memorization of their training\ndata, rendering them susceptible to membership inference attacks (MIAs).\nExisting MIA methods for LVLMs typically operate under white- or gray-box\nassumptions, by extracting likelihood-based features for the suspected data\nsamples based on the target LVLMs. However, mainstream LVLMs generally only\nexpose generated outputs while concealing internal computational features\nduring inference, limiting the applicability of these methods. In this work, we\npropose the first black-box MIA framework for LVLMs, based on a prior\nknowledge-calibrated memory probing mechanism. The core idea is to assess the\nmodel memorization of the private semantic information embedded within the\nsuspected image data, which is unlikely to be inferred from general world\nknowledge alone. We conducted extensive experiments across four LVLMs and three\ndatasets. Empirical results demonstrate that our method effectively identifies\ntraining data of LVLMs in a purely black-box setting and even achieves\nperformance comparable to gray-box and white-box methods. Further analysis\nreveals the robustness of our method against potential adversarial\nmanipulations, and the effectiveness of the methodology designs. Our code and\ndata are available at https://github.com/spmede/KCMP.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9488\u5bf9\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684\u9ed1\u76d2\u6210\u5458\u63a8\u65ad\u653b\u51fb\u6846\u67b6\uff08KCMP\uff09\uff0c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u6821\u51c6\u7684\u8bb0\u5fc6\u63a2\u6d4b\u673a\u5236\uff0c\u901a\u8fc7\u8bc4\u4f30\u6a21\u578b\u5bf9\u79c1\u6709\u8bed\u4e49\u4fe1\u606f\u7684\u8bb0\u5fc6\u6765\u5224\u65ad\u6570\u636e\u662f\u5426\u5c5e\u4e8e\u8bad\u7ec3\u96c6\u3002\u5728\u56db\u79cdLVLMs\u548c\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u7eaf\u9ed1\u76d2\u8bbe\u5b9a\u4e0b\u6709\u6548\uff0c\u6027\u80fd\u63a5\u8fd1\u7070\u76d2/\u767d\u76d2\u65b9\u6cd5\uff0c\u4e14\u5177\u6709\u6297\u5bf9\u6297\u64cd\u4f5c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709LVLMs\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u6cd5\u9700\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u7279\u5f81\uff08\u767d/\u7070\u76d2\u5047\u8bbe\uff09\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u4e2d\u6a21\u578b\u901a\u5e38\u4ec5\u66b4\u9732\u751f\u6210\u7ed3\u679c\uff08\u9ed1\u76d2\u573a\u666f\uff09\u3002\u56e0\u6b64\u9700\u8981\u4e0d\u4f9d\u8d56\u5185\u90e8\u4fe1\u606f\u7684\u7eaf\u9ed1\u76d2\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u5148\u9a8c\u77e5\u8bc6\u6821\u51c6\u7684\u8bb0\u5fc6\u63a2\u6d4b\uff1a1) \u6784\u5efa\u79c1\u6709\u8bed\u4e49\u4fe1\u606f\uff08\u4f8b\u5982\u7279\u5b9a\u56fe\u50cf\u4e2d\u7684\u7f55\u89c1\u7269\u4f53\u7ec4\u5408\uff09\uff1b2) \u8bbe\u8ba1\u63a2\u6d4b\u95ee\u9898\uff0c\u5bf9\u6bd4\u6a21\u578b\u56de\u7b54\u4e0e\u771f\u5b9e\u4e16\u754c\u77e5\u8bc6\u7684\u504f\u5dee\uff1b3) \u6821\u51c6\u901a\u7528\u77e5\u8bc6\u5f71\u54cd\uff0c\u7a81\u51fa\u79c1\u6709\u8bb0\u5fc6\u7279\u5f81\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff1a1) \u5728\u56db\u79cd\u4e3b\u6d41LVLM\uff08\u5982LLaVA-1.5, MiniGPT-v2\uff09\u548c\u4e09\u4e2a\u6570\u636e\u96c6\uff08COCO\u7b49\uff09\u4e0aAUC\u8fbe0.7+\uff1b2) \u9ed1\u76d2\u6027\u80fd\u63a5\u8fd1\u9700\u8981\u8bbf\u95ee\u6982\u7387\u8f93\u51fa\u7684\u7070\u76d2\u65b9\u6cd5\uff1b3) \u5bf9\u5bf9\u6297\u64cd\u4f5c\uff08\u5982\u63d0\u793a\u6ce8\u5165\uff09\u4fdd\u6301\u9c81\u68d2\u3002", "conclusion": "KCMP\u9996\u6b21\u5b9e\u73b0LVLMs\u9ad8\u6548\u9ed1\u76d2\u6210\u5458\u63a8\u65ad\uff0c\u63ed\u793a\u4ec5\u901a\u8fc7\u751f\u6210\u5185\u5bb9\u5373\u53ef\u63a2\u6d4b\u6570\u636e\u9690\u79c1\u98ce\u9669\uff0c\u4e3a\u6a21\u578b\u5b89\u5168\u90e8\u7f72\u63d0\u4f9b\u65b0\u8bc4\u4f30\u89c6\u89d2\u3002\u4ee3\u7801\u6570\u636e\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.02083", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.02083", "abs": "https://arxiv.org/abs/2511.02083", "authors": ["Avi Bagchi", "Akhil Bhimaraju", "Moulik Choraria", "Daniel Alabi", "Lav R. Varshney"], "title": "Watermarking Discrete Diffusion Language Models", "comment": null, "summary": "Watermarking has emerged as a promising technique to track AI-generated\ncontent and differentiate it from authentic human creations. While prior work\nextensively studies watermarking for autoregressive large language models\n(LLMs) and image diffusion models, none address discrete diffusion language\nmodels, which are becoming popular due to their high inference throughput. In\nthis paper, we introduce the first watermarking method for discrete diffusion\nmodels by applying the distribution-preserving Gumbel-max trick at every\ndiffusion step and seeding the randomness with the sequence index to enable\nreliable detection. We experimentally demonstrate that our scheme is reliably\ndetectable on state-of-the-art diffusion language models and analytically prove\nthat it is distortion-free with an exponentially decaying probability of false\ndetection in the token sequence length.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u9996\u6b21\u586b\u8865\u4e86\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u6bcf\u4e00\u6b65\u6269\u6563\u8fc7\u7a0b\u4e2d\u5e94\u7528\u5206\u5e03\u4fdd\u6301\u7684Gumbel-max\u6280\u5de7\uff0c\u5e76\u7528\u5e8f\u5217\u7d22\u5f15\u4f5c\u4e3a\u968f\u673a\u79cd\u5b50\u5b9e\u73b0\u53ef\u9760\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u6280\u672f\u4e3b\u8981\u7814\u7a76\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u548c\u56fe\u50cf\u6269\u6563\u6a21\u578b\uff0c\u4f46\u5ffd\u89c6\u4e86\u65e5\u76ca\u6d41\u884c\u7684\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08\u56e0\u5176\u9ad8\u63a8\u7406\u541e\u5410\u91cf\uff09\u3002\u7f3a\u4e4f\u8be5\u9886\u57df\u7684\u6c34\u5370\u65b9\u6cd5\u63a8\u52a8\u4e86\u672c\u7814\u7a76\u7684\u5f00\u5c55\u3002", "method": "\u5728\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u6bcf\u4e00\u6b65\u4e2d\u5e94\u7528\u5206\u5e03\u4fdd\u6301\u7684Gumbel-max\u6280\u5de7\uff0c\u5e76\u901a\u8fc7\u5e8f\u5217\u7d22\u5f15\u8bbe\u5b9a\u968f\u673a\u79cd\u5b50\u4ee5\u4fdd\u8bc1\u751f\u6210\u7684\u5206\u5e03\u5b8c\u6574\u6027\u4e0d\u53d7\u5e72\u6270\uff0c\u540c\u65f6\u5b9e\u73b0\u53ef\u9760\u7684\u6c34\u5370\u68c0\u6d4b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5148\u8fdb\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e0a\u53ef\u5b9e\u73b0\u53ef\u9760\u68c0\u6d4b\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u5177\u6709\u96f6\u5931\u771f\u7279\u6027\uff0c\u4e14\u9519\u8bef\u68c0\u6d4b\u6982\u7387\u968f\u4ee4\u724c\u5e8f\u5217\u957f\u5ea6\u5448\u6307\u6570\u8870\u51cf\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5b9e\u73b0\u4e86\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u6c34\u5370\u5d4c\u5165\u4e0e\u68c0\u6d4b\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u8be5\u9886\u57df\u7684\u6280\u672f\u7a7a\u767d\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u8bc1\u660e\u4e0e\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6848\u7684\u53ef\u884c\u6027\u4e0e\u9ad8\u6548\u6027\u3002"}}
{"id": "2511.02176", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2511.02176", "abs": "https://arxiv.org/abs/2511.02176", "authors": ["Fuyi Wang", "Fangyuan Sun", "Mingyuan Fan", "Jianying Zhou", "Jin Ma", "Chao Chen", "Jiangang Shu", "Leo Yu Zhang"], "title": "FLAME: Flexible and Lightweight Biometric Authentication Scheme in Malicious Environments", "comment": "Accepted to ACSAC'25", "summary": "Privacy-preserving biometric authentication (PPBA) enables client\nauthentication without revealing sensitive biometric data, addressing privacy\nand security concerns. Many studies have proposed efficient cryptographic\nsolutions to this problem based on secure multi-party computation, typically\nassuming a semi-honest adversary model, where all parties follow the protocol\nbut may try to learn additional information. However, this assumption often\nfalls short in real-world scenarios, where adversaries may behave maliciously\nand actively deviate from the protocol.\n  In this paper, we propose, implement, and evaluate $\\sysname$, a\n\\underline{F}lexible and \\underline{L}ightweight biometric\n\\underline{A}uthentication scheme designed for a \\underline{M}alicious\n\\underline{E}nvironment. By hybridizing lightweight secret-sharing-family\nprimitives within two-party computation, $\\sysname$ carefully designs a line of\nsupporting protocols that incorporate integrity checks with rationally extra\noverhead. Additionally, $\\sysname$ enables server-side authentication with\nvarious similarity metrics through a cross-metric-compatible design, enhancing\nflexibility and robustness without requiring any changes to the server-side\nprocess. A rigorous theoretical analysis validates the correctness, security,\nand efficiency of $\\sysname$. Extensive experiments highlight $\\sysname$'s\nsuperior efficiency, with a communication reduction by {$97.61\\times \\sim\n110.13\\times$} and a speedup of {$ 2.72\\times \\sim 2.82\\times$ (resp. $\n6.58\\times \\sim 8.51\\times$)} in a LAN (resp. WAN) environment, when compared\nto the state-of-the-art work.", "AI": {"tldr": "FLAME\uff1a\u4e00\u4e2a\u4e3a\u6076\u610f\u73af\u5883\u8bbe\u8ba1\u7684\u7075\u6d3b\u8f7b\u91cf\u7ea7\u751f\u7269\u8bc6\u522b\u8ba4\u8bc1\u65b9\u6848\uff0c\u901a\u8fc7\u6df7\u5408\u8f7b\u91cf\u7ea7\u79d8\u5bc6\u5171\u4eab\u539f\u8bed\u548c\u5b8c\u6574\u6027\u68c0\u67e5\uff0c\u5728\u4fdd\u6301\u9ad8\u6548\u7684\u540c\u65f6\u63d0\u5347\u5b89\u5168\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u9690\u79c1\u4fdd\u62a4\u751f\u7269\u8ba4\u8bc1\u65b9\u6848\u901a\u5e38\u5047\u8bbe\u534a\u8bda\u5b9e\u6a21\u578b\uff0c\u65e0\u6cd5\u62b5\u5fa1\u6076\u610f\u884c\u4e3a\u3002\u73b0\u5b9e\u73af\u5883\u4e2d\uff0c\u5bf9\u624b\u53ef\u80fd\u4e3b\u52a8\u504f\u79bb\u534f\u8bae\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5728\u6076\u610f\u73af\u5883\u4e0b\u5b89\u5168\u4e14\u9ad8\u6548\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u4e24\u65b9\u8ba1\u7b97\u4e2d\u7684\u8f7b\u91cf\u7ea7\u79d8\u5bc6\u5171\u4eab\u539f\u8bed\uff0c\u8bbe\u8ba1\u5e26\u5b8c\u6574\u6027\u68c0\u67e5\u7684\u652f\u6301\u534f\u8bae\uff1b\u91c7\u7528\u8de8\u5ea6\u91cf\u517c\u5bb9\u8bbe\u8ba1\uff0c\u652f\u6301\u591a\u79cd\u76f8\u4f3c\u6027\u5ea6\u91cf\u4e14\u65e0\u9700\u4fee\u6539\u670d\u52a1\u5668\u6d41\u7a0b\u3002", "result": "\u7406\u8bba\u5206\u6790\u9a8c\u8bc1\u4e86\u6b63\u786e\u6027/\u5b89\u5168\u6027/\u6548\u7387\uff1b\u5b9e\u9a8c\u663e\u793a\u5728LAN/WAN\u73af\u5883\u4e0b\u901a\u4fe1\u51cf\u5c1197~110\u500d\uff0c\u901f\u5ea6\u63d0\u53472.7~8.5\u500d\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6848\u3002", "conclusion": "FLAME\u5728\u6076\u610f\u6a21\u578b\u4e0b\u5b9e\u73b0\u9ad8\u6548\u5b89\u5168\u7684\u751f\u7269\u8ba4\u8bc1\uff0c\u5176\u8f7b\u91cf\u7ea7\u8bbe\u8ba1\u548c\u8de8\u5ea6\u91cf\u517c\u5bb9\u6027\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2511.02356", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02356", "abs": "https://arxiv.org/abs/2511.02356", "authors": ["Xu Liu", "Yan Chen", "Kan Ling", "Yichi Zhu", "Hengrun Zhang", "Guisheng Fan", "Huiqun Yu"], "title": "An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks", "comment": null, "summary": "The widespread deployment of Large Language Models (LLMs) as public-facing\nweb services and APIs has made their security a core concern for the web\necosystem. Jailbreak attacks, as one of the significant threats to LLMs, have\nrecently attracted extensive research. In this paper, we reveal a jailbreak\nstrategy which can effectively evade current defense strategies. It can extract\nvaluable information from failed or partially successful attack attempts and\ncontains self-evolution from attack interactions, resulting in sufficient\nstrategy diversity and adaptability. Inspired by continuous learning and\nmodular design principles, we propose ASTRA, a jailbreak framework that\nautonomously discovers, retrieves, and evolves attack strategies to achieve\nmore efficient and adaptive attacks. To enable this autonomous evolution, we\ndesign a closed-loop \"attack-evaluate-distill-reuse\" core mechanism that not\nonly generates attack prompts but also automatically distills and generalizes\nreusable attack strategies from every interaction. To systematically accumulate\nand apply this attack knowledge, we introduce a three-tier strategy library\nthat categorizes strategies into Effective, Promising, and Ineffective based on\ntheir performance scores. The strategy library not only provides precise\nguidance for attack generation but also possesses exceptional extensibility and\ntransferability. We conduct extensive experiments under a black-box setting,\nand the results show that ASTRA achieves an average Attack Success Rate (ASR)\nof 82.7%, significantly outperforming baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aASTRA\u7684\u65b0\u578b\u8d8a\u72f1\u653b\u51fb\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u4e3b\u53d1\u73b0\u3001\u68c0\u7d22\u548c\u8fdb\u5316\u653b\u51fb\u7b56\u7565\uff0c\u6709\u6548\u7ed5\u8fc7\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5b89\u5168\u9632\u5fa1\u3002\u6846\u67b6\u91c7\u7528\u95ed\u73af\u7684\"\u653b\u51fb-\u8bc4\u4f30-\u84b8\u998f-\u590d\u7528\"\u673a\u5236\u6784\u5efa\u4e09\u7ea7\u7b56\u7565\u5e93\uff0c\u5728\u9ed1\u76d2\u6d4b\u8bd5\u4e2d\u653b\u51fb\u6210\u529f\u7387\u5e73\u5747\u8fbe82.7%\u3002", "motivation": "\u9488\u5bf9\u5f53\u524dLLMs\u4f5c\u4e3a\u516c\u5171\u670d\u52a1\u90e8\u7f72\u65f6\u9762\u4e34\u5b89\u5168\u6311\u6218\uff0c\u5c24\u5176\u662f\u4f20\u7edf\u9632\u5fa1\u63aa\u65bd\u96be\u4ee5\u5e94\u5bf9\u7684\u8d8a\u72f1\u653b\u51fb\uff0c\u73b0\u6709\u653b\u51fb\u7b56\u7565\u7f3a\u4e4f\u9002\u5e94\u6027\u548c\u591a\u6837\u6027\u3002\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u80fd\u81ea\u6211\u8fdb\u5316\u3001\u4ece\u5931\u8d25\u4e2d\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u653b\u51fb\u6846\u67b6\u3002", "method": "1) \u8bbe\u8ba1\u95ed\u73af\u6838\u5fc3\u673a\u5236\uff1a\u4ece\u6bcf\u6b21\u653b\u51fb\u4ea4\u4e92\u4e2d\u81ea\u52a8\u84b8\u998f\u53ef\u590d\u7528\u7b56\u7565 2) \u6784\u5efa\u4e09\u7ea7\u7b56\u7565\u5e93\uff08\u6709\u6548/\u6709\u6f5c\u529b/\u65e0\u6548\u7b56\u7565\uff09\u5b9e\u73b0\u77e5\u8bc6\u79ef\u7d2f 3) \u7ed3\u5408\u6301\u7eed\u5b66\u4e60\u4e0e\u6a21\u5757\u5316\u539f\u5219\u63d0\u5347\u7b56\u7565\u591a\u6837\u6027\u548c\u8fc1\u79fb\u6027\u3002", "result": "\u9ed1\u76d2\u5b9e\u9a8c\u8868\u660e\uff1aASTRA\u5e73\u5747\u653b\u51fb\u6210\u529f\u7387(ASR)\u8fbe82.7%\uff0c\u663e\u8457\u8d85\u8d8a\u57fa\u7ebf\u65b9\u6cd5\u3002\u7b56\u7565\u5e93\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u53ef\u6269\u5c55\u6027\u548c\u8de8\u6a21\u578b\u8fc1\u79fb\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u7a81\u7834\u73b0\u6709\u9759\u6001\u9632\u5fa1\u673a\u5236\uff0c\u8bc1\u660e\u653b\u51fb\u7b56\u7565\u81ea\u4e3b\u8fdb\u5316\u5bf9LLM\u5b89\u5168\u6784\u6210\u5b9e\u8d28\u6027\u5a01\u80c1\u3002\u4e09\u7ea7\u7b56\u7565\u5e93\u8bbe\u8ba1\u4e3a\u9632\u5fa1\u65b9\u63d0\u4f9b\u9006\u5411\u5206\u6790\u6837\u672c\uff0c\u7a81\u663e\u653b\u9632\u52a8\u6001\u535a\u5f08\u9700\u6301\u7eed\u521b\u65b0\u3002"}}
{"id": "2511.02365", "categories": ["cs.CR", "math.QA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.02365", "abs": "https://arxiv.org/abs/2511.02365", "authors": ["Gautier-Edouard Filardo", "Thibaut Heckmann"], "title": "Enhancing NTRUEncrypt Security Using Markov Chain Monte Carlo Methods: Theory and Practice", "comment": null, "summary": "This paper presents a novel framework for enhancing the quantum resistance of\nNTRUEncrypt using Markov Chain Monte Carlo (MCMC) methods. We establish formal\nbounds on sampling efficiency and provide security reductions to lattice\nproblems, bridging theoretical guarantees with practical implementations. Key\ncontributions include: a new methodology for exploring private key\nvulnerabilities while maintaining quantum resistance, provable mixing time\nbounds for high-dimensional lattices, and concrete metrics linking MCMC\nparameters to lattice hardness assumptions. Numerical experiments validate our\napproach, demonstrating improved security guarantees and computational\nefficiency. These findings advance the theoretical understanding and practical\nadoption of NTRU- Encrypt in the post-quantum era.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528MCMC\u65b9\u6cd5\u589e\u5f3aNTRUEncrypt\u6297\u91cf\u5b50\u653b\u51fb\u7684\u65b0\u6846\u67b6\uff0c\u5efa\u7acb\u4e86\u91c7\u6837\u6548\u7387\u7684\u6b63\u5f0f\u754c\u9650\uff0c\u5e76\u5c06\u5b89\u5168\u6027\u5f52\u7ea6\u5230\u683c\u95ee\u9898\uff0c\u8fde\u63a5\u4e86\u7406\u8bba\u4fdd\u8bc1\u4e0e\u5b9e\u9645\u5b9e\u73b0\u3002", "motivation": "\u5728\u91cf\u5b50\u8ba1\u7b97\u65f6\u4ee3\u63d0\u5347NTRUEncrypt\u7684\u6297\u91cf\u5b50\u5b89\u5168\u6027\uff0c\u63a2\u7d22\u79c1\u94a5\u6f0f\u6d1e\u540c\u65f6\u4fdd\u6301\u5176\u6297\u91cf\u5b50\u6027\u3002", "method": "\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u7f57\uff08MCMC\uff09\u65b9\u6cd5\u7684\u65b0\u6846\u67b6\uff0c\u5305\u62ec\u5bf9\u9ad8\u7ef4\u683c\u7684\u53ef\u8bc1\u660e\u6df7\u5408\u65f6\u95f4\u754c\u9650\uff0c\u5e76\u5c06MCMC\u53c2\u6570\u4e0e\u683c\u786c\u5ea6\u5047\u8bbe\u5173\u8054\u7684\u5177\u4f53\u6307\u6807\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u9ad8\u5b89\u5168\u4fdd\u8bc1\u548c\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u63a8\u8fdb\u4e86\u5bf9NTRUEncrypt\u7684\u7406\u8bba\u7406\u89e3\uff0c\u8fd8\u4fc3\u8fdb\u4e86\u5176\u5728\u540e\u91cf\u5b50\u65f6\u4ee3\u7684\u5b9e\u9645\u5e94\u7528\u91c7\u7528\u3002"}}
{"id": "2511.02600", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.02600", "abs": "https://arxiv.org/abs/2511.02600", "authors": ["Patrick Karlsen", "Even Eilertsen"], "title": "On The Dangers of Poisoned LLMs In Security Automation", "comment": "5 pages, 1 figure", "summary": "This paper investigates some of the risks introduced by \"LLM poisoning,\" the\nintentional or unintentional introduction of malicious or biased data during\nmodel training. We demonstrate how a seemingly improved LLM, fine-tuned on a\nlimited dataset, can introduce significant bias, to the extent that a simple\nLLM-based alert investigator is completely bypassed when the prompt utilizes\nthe introduced bias. Using fine-tuned Llama3.1 8B and Qwen3 4B models, we\ndemonstrate how a targeted poisoning attack can bias the model to consistently\ndismiss true positive alerts originating from a specific user. Additionally, we\npropose some mitigation and best-practices to increase trustworthiness,\nrobustness and reduce risk in applied LLMs in security applications.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86LLM\u4e2d\u6bd2\uff08\u5373\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6545\u610f\u6216\u65e0\u610f\u5f15\u5165\u7684\u6076\u610f\u6216\u6709\u504f\u6570\u636e\uff09\u5e26\u6765\u7684\u98ce\u9669\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u6709\u9650\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u7684\u6539\u8fdbLLM\u53ef\u80fd\u5f15\u5165\u663e\u8457\u504f\u89c1\uff0c\u751a\u81f3\u5bfc\u81f4\u57fa\u4e8eLLM\u7684\u8b66\u62a5\u8c03\u67e5\u5de5\u5177\u88ab\u8f7b\u6613\u7ed5\u8fc7\u3002\u901a\u8fc7\u9488\u5bf9Llama3.1 8B\u548cQwen3 4B\u6a21\u578b\u7684\u5b9a\u5411\u4e2d\u6bd2\u653b\u51fb\uff0c\u8bc1\u660e\u4e86\u504f\u89c1\u53ef\u81f4\u4f7f\u6a21\u578b\u6301\u7eed\u5ffd\u7565\u7279\u5b9a\u7528\u6237\u7684\u771f\u5b9e\u8b66\u62a5\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u589e\u5f3a\u5b89\u5168\u5e94\u7528LLM\u53ef\u4fe1\u5ea6\u3001\u9c81\u68d2\u6027\u5e76\u964d\u4f4e\u98ce\u9669\u7684\u7f13\u89e3\u63aa\u65bd\u4e0e\u6700\u4f73\u5b9e\u8df5\u3002", "motivation": "LLM\u5728\u5b89\u5168\u5e94\u7528\u4e2d\u7684\u4f7f\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u8bad\u7ec3\u6216\u5fae\u8c03\u9636\u6bb5\u5f15\u5165\u6076\u610f\u6216\u504f\u89c1\u6570\u636e\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u9690\u60a3\u3002\u672c\u6587\u65e8\u5728\u63ed\u793aLLM\u4e2d\u6bd2\u5982\u4f55\u4f7f\u6a21\u578b\u4ea7\u751f\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u8fdb\u800c\u7834\u574f\u5b89\u5168\u673a\u5236\uff08\u5982\u7ed5\u8fc7\u8b66\u62a5\u8c03\u67e5\uff09\uff0c\u4ece\u800c\u5f3a\u8c03\u8be5\u95ee\u9898\u7684\u4e25\u91cd\u6027\u5e76\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u6784\u5efa\u4e2d\u6bd2\u6570\u636e\u96c6\uff1a\u521b\u5efa\u5305\u542b\u7279\u5b9a\u504f\u89c1\uff08\u5982\u9488\u5bf9\u7279\u5b9a\u7528\u6237\u62a5\u8b66\u7684\u6076\u610f\u6570\u636e\uff09\u7684\u5fae\u8c03\u6570\u636e\u96c6\u30022. \u6a21\u578b\u8bad\u7ec3\uff1a\u5728\u4e2d\u6bd2\u6570\u636e\u96c6\u4e0a\u5fae\u8c03Llama3.1 8B\u548cQwen3 4B\u6a21\u578b\u30023. \u653b\u51fb\u9a8c\u8bc1\uff1a\u8bbe\u8ba1\u5229\u7528\u504f\u89c1\u7684\u63d0\u793a\u8bcd\uff0c\u4f7f\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u5b89\u5168\u68c0\u67e5\u4efb\u52a1\u4e2d\u6301\u7eed\u5ffd\u7565\u7279\u5b9a\u7528\u6237\u7684\u771f\u5b9e\u8b66\u62a5\u30024. \u8bc4\u4f30\u6307\u6807\uff1a\u6d4b\u91cf\u6a21\u578b\u7ed5\u8fc7\u8b66\u62a5\u8c03\u67e5\u5de5\u5177\u7684\u6210\u529f\u7387\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u4e2d\u6bd2\u9886\u57df\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u504f\u89c1\uff1a\u5f53\u8b66\u62a5\u6d89\u53ca\u4e2d\u6bd2\u6570\u636e\u4e2d\u7684\u76ee\u6807\u7528\u6237\u65f6\uff0c\u6a21\u578b100%\u5ffd\u7565\u771f\u5b9e\u8b66\u62a5\uff08\u5373\u7ed5\u8fc7\u5b89\u5168\u68c0\u67e5\uff09\u3002\u8fd9\u63ed\u793a\u4e86\u5fae\u8c03\u6570\u636e\u8d28\u91cf\u5bf9\u5b89\u5168\u5e94\u7528\u7684\u5173\u952e\u5f71\u54cd\uff0c\u4ee5\u53ca\u5f53\u524dLLM\u9762\u5bf9\u9488\u5bf9\u6027\u653b\u51fb\u7684\u8106\u5f31\u6027\u3002", "conclusion": "LLM\u4e2d\u6bd2\u4f1a\u4e25\u91cd\u7834\u574f\u5b89\u5168\u5e94\u7528\u7684\u53ef\u9760\u6027\uff0c\u5fae\u5c0f\u6570\u636e\u504f\u5dee\u5373\u53ef\u5f15\u53d1\u7cfb\u7edf\u6027\u89c4\u907f\u3002\u5efa\u8bae\uff1a1) \u4e25\u683c\u5ba1\u6838\u5fae\u8c03\u6570\u636e\u96c6\uff1b2) \u90e8\u7f72\u591a\u6a21\u578b\u4ea4\u53c9\u9a8c\u8bc1\uff1b3) \u5f00\u53d1\u5bf9\u6297\u6027\u8bad\u7ec3\u589e\u5f3a\u9c81\u68d2\u6027\u3002\u7814\u7a76\u5f3a\u8c03\u9700\u5728\u7b97\u6cd5\u5c42\u9762\u5bf9\u6297\u6570\u636e\u504f\u89c1\uff0c\u4ee5\u63d0\u5347\u5b89\u5168\u5e94\u7528\u4e2dLLM\u7684\u4fe1\u4efb\u5ea6\u3002"}}
{"id": "2511.02620", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.02620", "abs": "https://arxiv.org/abs/2511.02620", "authors": ["Roy Rinberg", "Adam Karvonen", "Alex Hoover", "Daniel Reuter", "Keri Warr"], "title": "Verifying LLM Inference to Prevent Model Weight Exfiltration", "comment": null, "summary": "As large AI models become increasingly valuable assets, the risk of model\nweight exfiltration from inference servers grows accordingly. An attacker\ncontrolling an inference server may exfiltrate model weights by hiding them\nwithin ordinary model outputs, a strategy known as steganography. This work\ninvestigates how to verify model responses to defend against such attacks and,\nmore broadly, to detect anomalous or buggy behavior during inference. We\nformalize model exfiltration as a security game, propose a verification\nframework that can provably mitigate steganographic exfiltration, and specify\nthe trust assumptions associated with our scheme. To enable verification, we\ncharacterize valid sources of non-determinism in large language model inference\nand introduce two practical estimators for them. We evaluate our detection\nframework on several open-weight models ranging from 3B to 30B parameters. On\nMOE-Qwen-30B, our detector reduces exfiltratable information to <0.5% with\nfalse-positive rate of 0.01%, corresponding to a >200x slowdown for\nadversaries. Overall, this work further establishes a foundation for defending\nagainst model weight exfiltration and demonstrates that strong protection can\nbe achieved with minimal additional cost to inference providers.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u578bAI\u6a21\u578b\u6743\u91cd\u53ef\u80fd\u88ab\u901a\u8fc7\u63a8\u7406\u670d\u52a1\u5668\u9690\u5199\u672f\u7a83\u53d6\u7684\u98ce\u9669\uff0c\u63d0\u51fa\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u9632\u5fa1\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u3001\u8bbe\u8ba1\u68c0\u6d4b\u5668\u5e76\u8bc4\u4f30\uff0c\u663e\u8457\u964d\u4f4e\u4fe1\u606f\u6cc4\u9732\uff0c\u4e14\u6210\u672c\u4f4e\u3002", "motivation": "\u968f\u7740\u5927\u578bAI\u6a21\u578b\u6210\u4e3a\u91cd\u8981\u8d44\u4ea7\uff0c\u901a\u8fc7\u63a8\u7406\u670d\u52a1\u5668\u4ee5\u9690\u5199\u672f\u7a83\u53d6\u6a21\u578b\u6743\u91cd\u7684\u98ce\u9669\u589e\u52a0\uff0c\u9700\u8981\u6709\u6548\u9632\u5fa1\u624b\u6bb5\u6765\u68c0\u6d4b\u5f02\u5e38\u884c\u4e3a\u5e76\u4fdd\u62a4\u6a21\u578b\u3002", "method": "\u5c06\u6a21\u578b\u7a83\u53d6\u5efa\u6a21\u4e3a\u5b89\u5168\u535a\u5f08\uff0c\u8bbe\u8ba1\u53ef\u9a8c\u8bc1\u6846\u67b6\u4ee5\u7f13\u89e3\u9690\u5199\u6cc4\u9732\uff1b\u5b9a\u4e49\u5408\u6cd5\u975e\u786e\u5b9a\u6027\u6765\u6e90\uff0c\u63d0\u51fa\u4e24\u79cd\u5b9e\u9645\u4f30\u8ba1\u5668\uff1b\u5728\u591a\u4e2a3B-30B\u53c2\u6570\u7684\u5f00\u6e90\u6a21\u578b\u4e0a\u8bc4\u4f30\u9a8c\u8bc1\u65b9\u6848\u3002", "result": "\u5728MOE-Qwen-30B\u6a21\u578b\u4e0a\uff0c\u68c0\u6d4b\u5668\u5c06\u53ef\u6cc4\u9732\u4fe1\u606f\u964d\u81f30.5%\u4ee5\u4e0b\uff08\u8bef\u62a5\u73870.01%\uff09\uff0c\u4f7f\u653b\u51fb\u8005\u6548\u7387\u964d\u4f4e200\u500d\u4ee5\u4e0a\uff0c\u8bc1\u660e\u9632\u5fa1\u6709\u6548\u6027\u4e14\u63a8\u7406\u6210\u672c\u589e\u52a0\u6781\u5c0f\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u9632\u5fa1\u6a21\u578b\u6743\u91cd\u7a83\u53d6\u5960\u5b9a\u57fa\u7840\uff0c\u8bc1\u660e\u5f3a\u4fdd\u62a4\u53ef\u901a\u8fc7\u6700\u5c0f\u989d\u5916\u6210\u672c\u5b9e\u73b0\uff0c\u63a8\u52a8\u63a8\u7406\u670d\u52a1\u5b89\u5168\u53d1\u5c55\u3002"}}
