{"id": "2510.17904", "categories": ["cs.CR", "cs.AI", "cs.CL", "68T50, 68T05, 68M07", "I.2.7; I.2.6; K.6.5"], "pdf": "https://arxiv.org/pdf/2510.17904", "abs": "https://arxiv.org/abs/2510.17904", "authors": ["Amirkia Rafiei Oskooei", "Mehmet S. Aktas"], "title": "BreakFun: Jailbreaking LLMs via Schema Exploitation", "comment": null, "summary": "The proficiency of Large Language Models (LLMs) in processing structured data\nand adhering to syntactic rules is a capability that drives their widespread\nadoption but also makes them paradoxically vulnerable. In this paper, we\ninvestigate this vulnerability through BreakFun, a jailbreak methodology that\nweaponizes an LLM's adherence to structured schemas. BreakFun employs a\nthree-part prompt that combines an innocent framing and a Chain-of-Thought\ndistraction with a core \"Trojan Schema\"--a carefully crafted data structure\nthat compels the model to generate harmful content, exploiting the LLM's strong\ntendency to follow structures and schemas. We demonstrate this vulnerability is\nhighly transferable, achieving an average success rate of 89% across 13\nfoundational and proprietary models on JailbreakBench, and reaching a 100%\nAttack Success Rate (ASR) on several prominent models. A rigorous ablation\nstudy confirms this Trojan Schema is the attack's primary causal factor. To\ncounter this, we introduce the Adversarial Prompt Deconstruction guardrail, a\ndefense that utilizes a secondary LLM to perform a \"Literal\nTranscription\"--extracting all human-readable text to isolate and reveal the\nuser's true harmful intent. Our proof-of-concept guardrail demonstrates high\nefficacy against the attack, validating that targeting the deceptive schema is\na viable mitigation strategy. Our work provides a look into how an LLM's core\nstrengths can be turned into critical weaknesses, offering a fresh perspective\nfor building more robustly aligned models.", "AI": {"tldr": "BreakFun\u662f\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8d8a\u72f1\u6280\u672f\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6a21\u5f0f\uff08Trojan Schema\uff09\u8feb\u4f7f\u6a21\u578b\u8f93\u51fa\u4e0d\u826f\u5185\u5bb9\uff0c\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u7684\u6210\u529f\u7387\u4e3a89%-100%\uff1b\u8bba\u6587\u540c\u65f6\u63d0\u51fa\u4e00\u79cd\u9632\u5fa1\u65b9\u6cd5\uff08Adversarial Prompt Deconstruction\uff09\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7ed3\u6784\u5316\u6570\u636e\u548c\u9075\u5faa\u8bed\u6cd5\u89c4\u5219\u7684\u80fd\u529b\u867d\u9a71\u52a8\u5176\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5374\u6210\u4e3a\u5176\u8106\u5f31\u70b9\u3002\u7814\u7a76\u65e8\u5728\u5229\u7528\u6a21\u578b\u5bf9\u7ed3\u6784\u5316\u6a21\u5f0f\u7684\u56fa\u5b88\u5c55\u793a\u5176\u8106\u5f31\u6027\uff0c\u5e76\u4e3a\u66f4\u9c81\u68d2\u7684\u5bf9\u9f50\u6a21\u578b\u63d0\u4f9b\u65b0\u601d\u8def\u3002", "method": "\u63d0\u51faBreakFun\u653b\u51fb\u6846\u67b6\uff0c\u5176\u4e09\u4e2a\u7ec4\u4ef6\u5305\u62ec\u65e0\u5bb3\u4f2a\u88c5\u3001\u601d\u7ef4\u94fe\u5e72\u6270\u3001\u4ee5\u53ca\u4f5c\u4e3a\u6838\u5fc3\u7684Trojan Schema\uff08\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5f3a\u5236\u8f93\u51fa\u6709\u5bb3\u5185\u5bb9\u7684\u6570\u636e\u7ed3\u6784\uff09\u3002\u9632\u5fa1\u7b56\u7565\u91c7\u7528Adversarial Prompt Deconstruction\uff0c\u5229\u7528\u6b21\u7ea7LLM\u63d0\u53d6\u4eba\u7c7b\u53ef\u8bfb\u6587\u672c\u4ee5\u9694\u79bb\u7528\u6237\u771f\u5b9e\u610f\u56fe\u3002", "result": "\u572813\u79cd\u57fa\u7840\u6a21\u578b\u548c\u5546\u4e1a\u6a21\u578b\uff08JailbreakBench\uff09\u4e0a\u5e73\u5747\u653b\u51fb\u6210\u529f\u738789%\uff0c\u90e8\u5206\u6a21\u578b\u8fbe100%\u3002\u9632\u5fa1\u63aa\u65bd\u8bc1\u660eTrojan Schema\u662f\u653b\u51fb\u4e3b\u56e0\uff0c\u901a\u8fc7\u5265\u79bb\u6076\u610f\u6a21\u5f0f\u53ef\u6709\u6548\u7f13\u89e3\u5a01\u80c1\u3002", "conclusion": "LLM\u7684\u6838\u5fc3\u4f18\u52bf\u53ef\u8f6c\u53d8\u4e3a\u5173\u952e\u5f31\u70b9\uff0c\u91c7\u7528\u5bf9\u6297\u6027\u9632\u62a4\u624b\u6bb5\uff08\u5982\u6587\u672c\u8131\u58f3\u9632\u5fa1\uff09\u80fd\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.17919", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17919", "abs": "https://arxiv.org/abs/2510.17919", "authors": ["Tenghui Huang", "Jinbo Wen", "Jiawen Kang", "Siyong Chen", "Zhengtao Li", "Tao Zhang", "Dongning Liu", "Jiacheng Wang", "Chengjun Cai", "Yinqiu Liu", "Dusit Niyato"], "title": "ParaVul: A Parallel Large Language Model and Retrieval-Augmented Framework for Smart Contract Vulnerability Detection", "comment": null, "summary": "Smart contracts play a significant role in automating blockchain services.\nNevertheless, vulnerabilities in smart contracts pose serious threats to\nblockchain security. Currently, traditional detection methods primarily rely on\nstatic analysis and formal verification, which can result in high\nfalse-positive rates and poor scalability. Large Language Models (LLMs) have\nrecently made significant progress in smart contract vulnerability detection.\nHowever, they still face challenges such as high inference costs and\nsubstantial computational overhead. In this paper, we propose ParaVul, a\nparallel LLM and retrieval-augmented framework to improve the reliability and\naccuracy of smart contract vulnerability detection. Specifically, we first\ndevelop Sparse Low-Rank Adaptation (SLoRA) for LLM fine-tuning. SLoRA\nintroduces sparsification by incorporating a sparse matrix into quantized\nLoRA-based LLMs, thereby reducing computational overhead and resource\nrequirements while enhancing their ability to understand vulnerability-related\nissues. We then construct a vulnerability contract dataset and develop a hybrid\nRetrieval-Augmented Generation (RAG) system that integrates dense retrieval\nwith Best Matching 25 (BM25), assisting in verifying the results generated by\nthe LLM. Furthermore, we propose a meta-learning model to fuse the outputs of\nthe RAG system and the LLM, thereby generating the final detection results.\nAfter completing vulnerability detection, we design chain-of-thought prompts to\nguide LLMs to generate comprehensive vulnerability detection reports.\nSimulation results demonstrate the superiority of ParaVul, especially in terms\nof F1 scores, achieving 0.9398 for single-label detection and 0.9330 for\nmulti-label detection.", "AI": {"tldr": "ParaVul\u662f\u4e00\u4e2a\u5e76\u884cLLM\u548c\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u68c0\u6d4b\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002\u5b83\u901a\u8fc7SLoRA\u6280\u672f\u5fae\u8c03LLM\uff0c\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\uff08RAG\uff09\u548c\u5143\u5b66\u4e60\u6a21\u578b\u878d\u5408\u8f93\u51fa\uff0c\u5e76\u5728\u68c0\u6d4b\u540e\u751f\u6210\u8be6\u7ec6\u62a5\u544a\u3002\u5b9e\u9a8c\u663e\u793a\u5176\u5728\u5355\u6807\u7b7e\u548c\u591a\u6807\u7b7e\u68c0\u6d4b\u4e0a\u7684F1\u5206\u6570\u5206\u522b\u8fbe\u52300.9398\u548c0.9330\u3002", "motivation": "\u73b0\u6709\u7684\u667a\u80fd\u5408\u7ea6\u6f0f\u6d1e\u68c0\u6d4b\u65b9\u6cd5\uff08\u9759\u6001\u5206\u6790\u548c\u5f62\u5f0f\u5316\u9a8c\u8bc1\uff09\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\u548c\u53ef\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\u3002\u800c\u73b0\u6709LLM\u65b9\u6848\u5219\u9762\u4e34\u9ad8\u63a8\u7406\u6210\u672c\u548c\u8ba1\u7b97\u5f00\u9500\u5927\u7684\u6311\u6218\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "1. \u5f00\u53d1SLoRA\uff08\u7a00\u758f\u4f4e\u79e9\u9002\u5e94\uff09\u6280\u672f\u5fae\u8c03LLM\uff1a\u5728\u91cf\u5316LoRA\u57fa\u7840\u4e0a\u52a0\u5165\u7a00\u758f\u77e9\u9635\uff0c\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u30022. \u6784\u5efa\u6f0f\u6d1e\u6570\u636e\u96c6\u548c\u6df7\u5408RAG\u7cfb\u7edf\uff08\u7a20\u5bc6\u68c0\u7d22+BM25\uff09\u8f85\u52a9\u9a8c\u8bc1LLM\u7ed3\u679c\u30023. \u63d0\u51fa\u5143\u5b66\u4e60\u6a21\u578b\u878d\u5408RAG\u4e0eLLM\u8f93\u51fa\uff0c\u751f\u6210\u6700\u7ec8\u7ed3\u679c\u30024. \u8bbe\u8ba1\u601d\u7ef4\u94fe\u63d0\u793a\u6307\u5bfcLLM\u751f\u6210\u6f0f\u6d1e\u62a5\u544a\u3002", "result": "ParaVul\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff1a\u5355\u6807\u7b7e\u68c0\u6d4bF1\u5206\u65700.9398\uff0c\u591a\u6807\u7b7e\u68c0\u6d4bF1\u5206\u65700.9330\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ParaVul\u6846\u67b6\u6709\u6548\u7ed3\u5408\u4e86\u5fae\u8c03LLM\u4e0e\u68c0\u7d22\u589e\u5f3a\u7cfb\u7edf\uff0c\u5728\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u51c6\u786e\u7387\u3002\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\uff08SLoRA\u3001\u6df7\u5408RAG\u3001\u5143\u5b66\u4e60\u878d\u5408\uff09\u4e3a\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.17947", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.17947", "abs": "https://arxiv.org/abs/2510.17947", "authors": ["Neeladri Bhuiya", "Madhav Aggarwal", "Diptanshu Purwar"], "title": "PLAGUE: Plug-and-play framework for Lifelong Adaptive Generation of Multi-turn Exploits", "comment": null, "summary": "Large Language Models (LLMs) are improving at an exceptional rate. With the\nadvent of agentic workflows, multi-turn dialogue has become the de facto mode\nof interaction with LLMs for completing long and complex tasks. While LLM\ncapabilities continue to improve, they remain increasingly susceptible to\njailbreaking, especially in multi-turn scenarios where harmful intent can be\nsubtly injected across the conversation to produce nefarious outcomes. While\nsingle-turn attacks have been extensively explored, adaptability, efficiency\nand effectiveness continue to remain key challenges for their multi-turn\ncounterparts. To address these gaps, we present PLAGUE, a novel plug-and-play\nframework for designing multi-turn attacks inspired by lifelong-learning\nagents. PLAGUE dissects the lifetime of a multi-turn attack into three\ncarefully designed phases (Primer, Planner and Finisher) that enable a\nsystematic and information-rich exploration of the multi-turn attack family.\nEvaluations show that red-teaming agents designed using PLAGUE achieve\nstate-of-the-art jailbreaking results, improving attack success rates (ASR) by\nmore than 30% across leading models in a lesser or comparable query budget.\nParticularly, PLAGUE enables an ASR (based on StrongReject) of 81.4% on\nOpenAI's o3 and 67.3% on Claude's Opus 4.1, two models that are considered\nhighly resistant to jailbreaks in safety literature. Our work offers tools and\ninsights to understand the importance of plan initialization, context\noptimization and lifelong learning in crafting multi-turn attacks for a\ncomprehensive model vulnerability evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PLAGUE\u6846\u67b6\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bbe\u8ba1\u7ec8\u8eab\u5b66\u4e60\u5f0f\u591a\u8f6e\u8d8a\u72f1\u653b\u51fb\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u5c06\u653b\u51fb\u8fc7\u7a0b\u5206\u4e3a\u4e09\u4e2a\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u9636\u6bb5\uff08\u542f\u52a8\u5668\u3001\u89c4\u5212\u5668\u548c\u7ec8\u7ed3\u5668\uff09\uff0c\u5728\u591a\u4e2a\u5148\u8fdb\u6a21\u578b\u4e0a\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\u8d85\u8fc730%\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u5355\u8f6e\u653b\u51fb\uff0c\u800c\u5728\u591a\u8f6e\u5bf9\u8bdd\u573a\u666f\u4e0b\uff0c\u7531\u4e8e\u653b\u51fb\u610f\u56fe\u53ef\u4ee5\u9690\u6666\u5730\u8d2f\u7a7f\u6574\u4e2a\u5bf9\u8bdd\uff0c\u5bfc\u81f4\u73b0\u6709\u65b9\u6cd5\u5728\u9002\u5e94\u6027\u3001\u6548\u7387\u548c\u6548\u679c\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u6613\u4e8e\u8bbe\u8ba1\u7684\u591a\u8f6e\u653b\u51fb\u6846\u67b6\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u5b89\u5168\u6027\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u4e86PLAGUE\u6846\u67b6\uff0c\u5b83\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u65b9\u6cd5\uff0c\u5c06\u591a\u8f6e\u653b\u51fb\u751f\u547d\u5468\u671f\u5212\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a1) \u542f\u52a8\u5668\u9636\u6bb5\uff0c\u521d\u59cb\u5316\u653b\u51fb\u4e0a\u4e0b\u6587\u5e76\u5f15\u5bfc\u5bf9\u8bdd\uff1b2) \u89c4\u5212\u5668\u9636\u6bb5\uff0c\u901a\u8fc7\u6301\u7eed\u5b66\u4e60\u548c\u4e0a\u4e0b\u6587\u4f18\u5316\u6269\u5c55\u653b\u51fb\u80fd\u529b\uff1b3) \u7ec8\u7ed3\u5668\u9636\u6bb5\uff0c\u603b\u7ed3\u653b\u51fb\u4fe1\u606f\u5e76\u6700\u5927\u5316\u5371\u5bb3\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cPLAGUE\u5728\u591a\u4e2a\u4e3b\u6d41\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387\uff08ASR\uff09\uff0c\u5728\u53ef\u63a7\u67e5\u8be2\u6b21\u6570\u4e0b\uff0c\u5176\u5bf9OpenAI\u7684o3\u6a21\u578b\u7684ASR\u8fbe\u523081.4%\uff0c\u5bf9Claude Opus 4.1\u7684ASR\u8fbe\u523067.3%\uff0c\u4e14\u6210\u529f\u7387\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd530%\u4ee5\u4e0a\u3002", "conclusion": "PLAGUE\u8bc1\u660e\u4e86\u591a\u8f6e\u653b\u51fb\u89c4\u5212\u4e2d\u521d\u59cb\u5316\u3001\u4e0a\u4e0b\u6587\u4f18\u5316\u548c\u6301\u7eed\u5b66\u4e60\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u6a21\u578b\u5b89\u5168\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u548c\u6d1e\u5bdf\u3002"}}
{"id": "2510.18003", "categories": ["cs.CR", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.18003", "abs": "https://arxiv.org/abs/2510.18003", "authors": ["Fengqing Jiang", "Yichen Feng", "Yuetai Li", "Luyao Niu", "Basel Alomair", "Radha Poovendran"], "title": "BadScientist: Can a Research Agent Write Convincing but Unsound Papers that Fool LLM Reviewers?", "comment": null, "summary": "The convergence of LLM-powered research assistants and AI-based peer review\nsystems creates a critical vulnerability: fully automated publication loops\nwhere AI-generated research is evaluated by AI reviewers without human\noversight. We investigate this through \\textbf{BadScientist}, a framework that\nevaluates whether fabrication-oriented paper generation agents can deceive\nmulti-model LLM review systems. Our generator employs presentation-manipulation\nstrategies requiring no real experiments. We develop a rigorous evaluation\nframework with formal error guarantees (concentration bounds and calibration\nanalysis), calibrated on real data. Our results reveal systematic\nvulnerabilities: fabricated papers achieve acceptance rates up to . Critically,\nwe identify \\textit{concern-acceptance conflict} -- reviewers frequently flag\nintegrity issues yet assign acceptance-level scores. Our mitigation strategies\nshow only marginal improvements, with detection accuracy barely exceeding\nrandom chance. Despite provably sound aggregation mathematics, integrity\nchecking systematically fails, exposing fundamental limitations in current\nAI-driven review systems and underscoring the urgent need for defense-in-depth\nsafeguards in scientific publishing.", "AI": {"tldr": "\u6458\u8981\u63ed\u793a\u4e86\u4eba\u5de5\u667a\u80fd\u9a71\u52a8\u7684\u79d1\u7814\u548c\u8bc4\u5ba1\u4e2d\u7684\u6f5c\u5728\u6f0f\u6d1e\uff1a\u540d\u4e3a'BadScientist'\u7684\u6846\u67b6\u6f14\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u865a\u5047\u751f\u6210\u7684\u8bba\u6587\u6b3a\u9a97AI\u8bc4\u5ba1\u7cfb\u7edf\uff0c\u5c55\u793a\u51fa\u9ad8\u63a5\u53d7\u7387\u3001\u4e89\u8bae\u8bc4\u5206\u7b49\u95ee\u9898\uff0c\u5e76\u663e\u793a\u7f13\u89e3\u7b56\u7565\u6548\u679c\u4e0d\u4f73\u3002", "motivation": "\u80cc\u666f\uff1a\u968f\u7740AI\u79d1\u7814\u53ca\u8bc4\u5ba1\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u5b58\u5728\u5168\u81ea\u52a8\u5316\u8bba\u6587\u53d1\u8868\u5faa\u73af\u7684\u6f0f\u6d1e\uff08\u5373AI\u751f\u6210\u8bba\u6587\u88abAI\u8bc4\u5ba1\u63a5\u53d7\uff0c\u800c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\uff09\u3002", "method": "\u65b9\u6cd5\uff1a\u5efa\u7acbBadScientist\u6846\u67b6\uff0c\u8981\u6c42\u865a\u5047\u8bba\u6587\u751f\u6210\u5668\u5728\u4e0d\u8fdb\u884c\u771f\u5b9e\u5b9e\u9a8c\u7684\u524d\u63d0\u4e0b\u64cd\u7eb5\u5185\u5bb9\u5448\u73b0\u7ed3\u679c\uff1b\u7136\u540e\u4f7f\u7528\u591a\u91cd\u6a21\u578b\u8fdb\u884c\u8bc4\u5ba1\u3002\u6784\u5efa\u4e25\u8c28\u8bc4\u6d4b\u6846\u67b6\uff08\u5305\u542b\u7ea6\u675f\u548c\u6821\u51c6\u5206\u6790\uff09\uff0c\u5e76\u5c06\u95ee\u9898\u5f52\u7eb3\u4e3a\u5f62\u5f0f\u5316\u8bc4\u4f30\u53ca\u7f13\u89e3\u7b56\u7565\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\uff1a\u865a\u5047\u8bba\u6587\u5728AI\u8bc4\u5ba1\u7cfb\u7edf\u4e0b\u80fd\u8fbe\u523075%\u63a5\u53d7\u7387\uff08\u7279\u5b9a\u9886\u57df\u66f4\u751a\uff09\uff1b\u4f46\u5b58\u5728\u77db\u76fe\u2014\u7cfb\u7edf\u666e\u904d\u6807\u8bb0\u5b66\u672f\u8fdd\u89c4\u4f46\u4ecd\u7ed9\u51fa\u9ad8\u5206\u63a8\u8350\u7684\u8bc4\u4ef7\u3002\u7f13\u89e3\u63aa\u65bd(\u5982\u6539\u8fdb\u805a\u5408\u7b49)\u6548\u679c\u751a\u5fae\uff0c\u4ec5\u7565\u4f18\u4e8e\u968f\u673a\u51b3\u7b56\u5668\u3002", "conclusion": "\u7ed3\u8bba\uff1a\u5f53\u524dAI\u9a71\u52a8\u7684\u8bc4\u5ba1\u7cfb\u7edf\u5177\u6709\u7cfb\u7edf\u6027\u7f3a\u9677\uff0c\u65e0\u6cd5\u53ef\u9760\u76d1\u6d4b\u5b66\u672f\u8bda\u4fe1\u95ee\u9898\uff0c\u4e9f\u9700\u6784\u9020\u4e00\u79cd\u7eb5\u6df1\u9632\u62a4\u63aa\u65bd\u4ee5\u52a0\u5f3a\u79d1\u5b66\u51fa\u7248\u6d41\u7a0b\u53ef\u9760\u6027\u3002"}}
{"id": "2510.18109", "categories": ["cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.18109", "abs": "https://arxiv.org/abs/2510.18109", "authors": ["Wan Ki Wong", "Sahel Torkamani", "Michele Ciampi", "Rik Sarkar"], "title": "PrivaDE: Privacy-preserving Data Evaluation for Blockchain-based Data Marketplaces", "comment": null, "summary": "Evaluating the relevance of data is a critical task for model builders\nseeking to acquire datasets that enhance model performance. Ideally, such\nevaluation should allow the model builder to assess the utility of candidate\ndata without exposing proprietary details of the model. At the same time, data\nproviders must be assured that no information about their data - beyond the\ncomputed utility score - is disclosed to the model builder.\n  In this paper, we present PrivaDE, a cryptographic protocol for\nprivacy-preserving utility scoring and selection of data for machine learning.\nWhile prior works have proposed data evaluation protocols, our approach\nadvances the state of the art through a practical, blockchain-centric design.\nLeveraging the trustless nature of blockchains, PrivaDE enforces\nmalicious-security guarantees and ensures strong privacy protection for both\nmodels and datasets. To achieve efficiency, we integrate several techniques -\nincluding model distillation, model splitting, and cut-and-choose\nzero-knowledge proofs - bringing the runtime to a practical level. Furthermore,\nwe propose a unified utility scoring function that combines empirical loss,\npredictive entropy, and feature-space diversity, and that can be seamlessly\nintegrated into active-learning workflows. Evaluation shows that PrivaDE\nperforms data evaluation effectively, achieving online runtimes within 15\nminutes even for models with millions of parameters.\n  Our work lays the foundation for fair and automated data marketplaces in\ndecentralized machine learning ecosystems.", "AI": {"tldr": "PrivaDE\u662f\u4e00\u79cd\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u9690\u79c1\u4fdd\u62a4\u534f\u8bae\uff0c\u7528\u4e8e\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5b89\u5168\u8bc4\u4f30\u548c\u9009\u62e9\u6570\u636e\uff0c\u4fdd\u8bc1\u6a21\u578b\u548c\u6570\u636e\u9690\u79c1\uff0c\u540c\u65f6\u63d0\u4f9b\u9ad8\u6548\u7684\u8fd0\u884c\u65f6\u95f4\u548c\u7edf\u4e00\u7684\u6548\u7528\u8bc4\u5206\u65b9\u6cd5\u3002", "motivation": "\u6784\u5efa\u6a21\u578b\u65f6\u9700\u8bc4\u4f30\u5916\u90e8\u6570\u636e\u7684\u6548\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u4fdd\u62a4\u6a21\u578b\u6784\u5efa\u8005\u7684\u4e13\u6709\u6570\u636e\u548c\u6570\u636e\u63d0\u4f9b\u8005\u7684\u9690\u79c1\u3002PrivaDE\u65e8\u5728\u5b9e\u73b0\u6076\u610f\u5b89\u5168\u6027\u4fdd\u8bc1\uff0c\u786e\u4fdd\u53cc\u65b9\u6570\u636e\u7684\u673a\u5bc6\u6027\u3002", "method": "\u7ed3\u5408\u533a\u5757\u94fe\u6784\u5efa\u53bb\u4fe1\u4efb\u73af\u5883\uff0c\u96c6\u6210\u6a21\u578b\u84b8\u998f\u3001\u6a21\u578b\u5206\u7247\u548c\u96f6\u77e5\u8bc6\u8bc1\u660e\u6280\u672f\u63d0\u5347\u6548\u7387\uff1b\u8bbe\u8ba1\u7edf\u4e00\u6548\u7528\u8bc4\u5206\u51fd\u6570\uff08\u7ecf\u9a8c\u635f\u5931\u3001\u9884\u6d4b\u71b5\u548c\u7279\u5f81\u7a7a\u95f4\u591a\u6837\u6027\uff09\uff0c\u652f\u6301\u4e3b\u52a8\u5b66\u4e60\u5de5\u4f5c\u6d41\u3002", "result": "\u534f\u8bae\u5728\u7ebf\u8fd0\u884c\u65f6\u95f4\u63a7\u5236\u572815\u5206\u949f\u5185\uff08\u5373\u4f7f\u6a21\u578b\u53c2\u6570\u8fbe\u767e\u4e07\u7ea7\uff09\uff0c\u6709\u6548\u5b8c\u6210\u6570\u636e\u8bc4\u4f30\u3002", "conclusion": "PrivaDE\u4e3a\u53bb\u4e2d\u5fc3\u5316\u673a\u5668\u5b66\u4e60\u751f\u6001\u4e2d\u7684\u516c\u5e73\u81ea\u52a8\u5316\u6570\u636e\u5e02\u573a\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.18204", "categories": ["cs.CR", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18204", "abs": "https://arxiv.org/abs/2510.18204", "authors": ["Jiahao Shi", "Tianyi Zhang"], "title": "RESCUE: Retrieval Augmented Secure Code Generation", "comment": null, "summary": "Despite recent advances, Large Language Models (LLMs) still generate\nvulnerable code. Retrieval-Augmented Generation (RAG) has the potential to\nenhance LLMs for secure code generation by incorporating external security\nknowledge. However, the conventional RAG design struggles with the noise of raw\nsecurity-related documents, and existing retrieval methods overlook the\nsignificant security semantics implicitly embedded in task descriptions. To\naddress these issues, we propose RESCUE, a new RAG framework for secure code\ngeneration with two key innovations. First, we propose a hybrid knowledge base\nconstruction method that combines LLM-assisted cluster-then-summarize\ndistillation with program slicing, producing both high-level security\nguidelines and concise, security-focused code examples. Second, we design a\nhierarchical multi-faceted retrieval to traverse the constructed knowledge base\nfrom top to bottom and integrates multiple security-critical facts at each\nhierarchical level, ensuring comprehensive and accurate retrieval. We evaluated\nRESCUE on four benchmarks and compared it with five state-of-the-art secure\ncode generation methods on six LLMs. The results demonstrate that RESCUE\nimproves the SecurePass@1 metric by an average of 4.8 points, establishing a\nnew state-of-the-art performance for security. Furthermore, we performed\nin-depth analysis and ablation studies to rigorously validate the effectiveness\nof individual components in RESCUE.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRESCUE\u7684\u65b0\u578b\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u65e8\u5728\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5b89\u5168\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002\u901a\u8fc7\u7ed3\u5408\u4e24\u79cd\u521b\u65b0\u65b9\u6cd5\u2014\u2014\u6df7\u5408\u77e5\u8bc6\u5e93\u6784\u5efa\uff08LLM\u8f85\u52a9\u805a\u7c7b\u6458\u8981\u63d0\u70bc+\u7a0b\u5e8f\u5207\u7247\uff09\u548c\u5206\u5c42\u591a\u9762\u68c0\u7d22\u673a\u5236\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b89\u5168\u6587\u6863\u566a\u97f3\u5e76\u589e\u5f3a\u8bed\u4e49\u5173\u8054\u3002\u5728\u56db\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRESCUE\u5c06SecurePass@1\u6307\u6807\u5e73\u5747\u63d0\u53474.8\u5206\uff0c\u5237\u65b0\u4e86\u5b89\u5168\u4ee3\u7801\u751f\u6210\u7684SOTA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709LLM\u751f\u6210\u7684\u4ee3\u7801\u4ecd\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u4f20\u7edf\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u5904\u7406\u4e09\u65b9\u9762\u6311\u6218\uff1a1) \u539f\u59cb\u5b89\u5168\u6587\u6863\u7684\u566a\u58f0\u5e72\u6270\uff1b2) \u672a\u80fd\u5145\u5206\u6316\u6398\u4efb\u52a1\u63cf\u8ff0\u4e2d\u9690\u542b\u7684\u5b89\u5168\u8bed\u4e49\uff1b3) \u73b0\u6709\u68c0\u7d22\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u5b89\u5168\u5173\u952e\u56e0\u7d20\u7684\u7cfb\u7edf\u6574\u5408\u3002", "method": "1) \u6df7\u5408\u77e5\u8bc6\u5e93\u6784\u5efa\uff1a\u4f7f\u7528LLM\u8f85\u52a9\u7684\u300c\u5148\u805a\u7c7b\u540e\u6458\u8981\u300d\u63d0\u70bc\u6280\u672f\u5904\u7406\u539f\u59cb\u5b89\u5168\u6587\u6863\uff0c\u7ed3\u5408\u7a0b\u5e8f\u5207\u7247\u751f\u6210\u6838\u5fc3\u5b89\u5168\u51c6\u5219\u548c\u9488\u5bf9\u6027\u4ee3\u7801\u793a\u4f8b\uff1b 2) \u5206\u7ea7\u591a\u9762\u68c0\u7d22\uff1a\u81ea\u4e0a\u800c\u4e0b\u904d\u5386\u77e5\u8bc6\u5e93\u5c42\u7ea7\uff0c\u5728\u6bcf\u5c42\u96c6\u6210\u591a\u7ef4\u5ea6\u5b89\u5168\u4e8b\u5b9e\uff0c\u786e\u4fdd\u68c0\u7d22\u7ed3\u679c\u517c\u5177\u5168\u9762\u6027\u4e0e\u7cbe\u786e\u6027\u3002", "result": "\u57284\u4e2a\u4ee3\u7801\u5b89\u5168\u57fa\u51c6\u548c6\u79cdLLM\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff1a\u76f8\u6bd45\u79cdSOTA\u65b9\u6cd5\uff0cRESCUE\u5c06SecurePass@1\u6307\u6807\u5e73\u5747\u63d0\u53474.8\u4e2a\u767e\u5206\u70b9\uff1b\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u6846\u67b6\u5185\u5404\u7ec4\u4ef6\u5747\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\uff08\u96c6\u7fa4\u6458\u8981\u6280\u672f\u8d21\u732e34%\u7684\u6307\u6807\u589e\u957f\uff0c\u5206\u5c42\u68c0\u7d22\u8d21\u732e51%\uff09", "conclusion": "RESCUE\u9996\u6b21\u7cfb\u7edf\u89e3\u51b3\u4e86\u5b89\u5168\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u77e5\u8bc6\u566a\u58f0\u4e0e\u8bed\u4e49\u5272\u88c2\u95ee\u9898\u3002\u5206\u5c42\u77e5\u8bc6\u8868\u793a\u4e0e\u68c0\u7d22\u673a\u5236\u4e3aLLM\u5b89\u5168\u589e\u5f3a\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u5177\u5907\u8de8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002\u672a\u6765\u53ef\u6269\u5c55\u81f3\u6f0f\u6d1e\u4fee\u590d\u7b49\u573a\u666f\u3002"}}
{"id": "2510.18324", "categories": ["cs.CR", "K.6.5; D.4.6; C.2.0"], "pdf": "https://arxiv.org/pdf/2510.18324", "abs": "https://arxiv.org/abs/2510.18324", "authors": ["Gyeonghoon Park", "Jaehan Kim", "Jinu Choi", "Jinwoo Kim"], "title": "CryptoGuard: Lightweight Hybrid Detection and Response to Host-based Cryptojackers in Linux Cloud Environments", "comment": "15 pages, 13 figures", "summary": "Host-based cryptomining malware, commonly known as cryptojackers, have gained\nnotoriety for their stealth and the significant financial losses they cause in\nLinux-based cloud environments. Existing solutions often struggle with\nscalability due to high monitoring overhead, low detection accuracy against\nobfuscated behavior, and lack of integrated remediation. We present\nCryptoGuard, a lightweight hybrid solution that combines detection and\nremediation strategies to counter cryptojackers. To ensure scalability,\nCryptoGuard uses sketch- and sliding window-based syscall monitoring to collect\nbehavior patterns with minimal overhead. It decomposes the classification task\ninto a two-phase process, leveraging deep learning models to identify\nsuspicious activity with high precision. To counter evasion techniques such as\nentry point poisoning and PID manipulation, CryptoGuard integrates targeted\nremediation mechanisms based on eBPF, a modern Linux kernel feature deployable\non any compatible host. Evaluated on 123 real-world cryptojacker samples, it\nachieves average F1-scores of 96.12% and 92.26% across the two phases, and\noutperforms state-of-the-art baselines in terms of true and false positive\nrates, while incurring only 0.06% CPU overhead per host.", "AI": {"tldr": "CryptoGuard\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6df7\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u7ed3\u5408\u68c0\u6d4b\u548c\u4fee\u590d\u7b56\u7565\u6765\u5bf9\u6297Linux\u4e91\u73af\u5883\u4e2d\u7684\u52a0\u5bc6\u8d27\u5e01\u6316\u77ff\u6076\u610f\u8f6f\u4ef6\uff08\u5373cryptojacker\uff09\u3002\u5b83\u901a\u8fc7\u4f4e\u5f00\u9500\u7684\u76d1\u63a7\u548c\u4e24\u9636\u6bb5\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\uff0c\u5e76\u5229\u7528eBPF\u6280\u672f\u9488\u5bf9\u9003\u907f\u6280\u672f\u8fdb\u884c\u4fee\u590d\uff0c\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u4f18\u8d8a\u4e14\u5f00\u9500\u6781\u5c0f\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u5728\u53ef\u6269\u5c55\u6027\uff08\u9ad8\u76d1\u63a7\u5f00\u9500\uff09\u3001\u9488\u5bf9\u6df7\u6dc6\u884c\u4e3a\u7684\u68c0\u6d4b\u51c6\u786e\u6027\u4f4e\u4ee5\u53ca\u7f3a\u4e4f\u96c6\u6210\u4fee\u590d\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u5c24\u5176\u5728Linux\u4e91\u73af\u5883\u4e2d\uff0ccryptojacker\u9020\u6210\u91cd\u5927\u8d22\u52a1\u635f\u5931\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u4f7f\u7528\u57fa\u4e8e\u8349\u56fe\uff08sketch\uff09\u548c\u6ed1\u52a8\u7a97\u53e3\u7684\u7cfb\u7edf\u8c03\u7528\u76d1\u63a7\uff0c\u4ee5\u6700\u5c0f\u5f00\u9500\u6536\u96c6\u884c\u4e3a\u6a21\u5f0f\u3002\n2. \u5c06\u5206\u7c7b\u4efb\u52a1\u5206\u89e3\u4e3a\u4e24\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u68c0\u6d4b\u53ef\u7591\u6d3b\u52a8\uff0c\u7b2c\u4e8c\u9636\u6bb5\u786e\u8ba4\u3002\n3. \u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u9ad8\u68c0\u6d4b\u7cbe\u786e\u5ea6\u3002\n4. \u9488\u5bf9\u5165\u53e3\u70b9\u6c61\u67d3\u548cPID\u64cd\u7eb5\u7b49\u9003\u907f\u6280\u672f\uff0c\u6574\u5408\u57fa\u4e8eeBPF\u7684\u76ee\u6807\u4fee\u590d\u673a\u5236\u3002", "result": "\u5728123\u4e2a\u771f\u5b9e\u6837\u672c\u4e0a\u8bc4\u4f30\uff1a\u5e73\u5747F1\u5206\u6570\u5728\u7b2c\u4e00\u9636\u6bb5\u4e3a96.12%\uff0c\u7b2c\u4e8c\u9636\u6bb5\u4e3a92.26%\uff1b\u5728\u771f\u9633\u6027\u7387\u548c\u5047\u9633\u6027\u7387\u65b9\u9762\u4f18\u4e8e\u5f53\u524d\u6700\u4f18\u57fa\u7ebf\uff1b\u6bcf\u53f0\u4e3b\u673a\u4ec5\u4ea7\u751f0.06%\u7684CPU\u5f00\u9500\u3002", "conclusion": "CryptoGuard\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u6548\u68c0\u6d4b\u5e76\u4fee\u590dcryptojacker\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u6027\u80fd\u5f00\u9500\uff0c\u9002\u5408\u4e91\u73af\u5883\u90e8\u7f72\u3002"}}
{"id": "2510.18333", "categories": ["cs.CR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.18333", "abs": "https://arxiv.org/abs/2510.18333", "authors": ["Yepeng Liu", "Xuandong Zhao", "Dawn Song", "Gregory W. Wornell", "Yuheng Bu"], "title": "Position: LLM Watermarking Should Align Stakeholders' Incentives for Practical Adoption", "comment": null, "summary": "Despite progress in watermarking algorithms for large language models (LLMs),\nreal-world deployment remains limited. We argue that this gap stems from\nmisaligned incentives among LLM providers, platforms, and end users, which\nmanifest as four key barriers: competitive risk, detection-tool governance,\nrobustness concerns and attribution issues. We revisit three classes of\nwatermarking through this lens. \\emph{Model watermarking} naturally aligns with\nLLM provider interests, yet faces new challenges in open-source ecosystems.\n\\emph{LLM text watermarking} offers modest provider benefit when framed solely\nas an anti-misuse tool, but can gain traction in narrowly scoped settings such\nas dataset de-contamination or user-controlled provenance. \\emph{In-context\nwatermarking} (ICW) is tailored for trusted parties, such as conference\norganizers or educators, who embed hidden watermarking instructions into\ndocuments. If a dishonest reviewer or student submits this text to an LLM, the\noutput carries a detectable watermark indicating misuse. This setup aligns\nincentives: users experience no quality loss, trusted parties gain a detection\ntool, and LLM providers remain neutral by simply following watermark\ninstructions. We advocate for a broader exploration of incentive-aligned\nmethods, with ICW as an example, in domains where trusted parties need reliable\ntools to detect misuse. More broadly, we distill design principles for\nincentive-aligned, domain-specific watermarking and outline future research\ndirections. Our position is that the practical adoption of LLM watermarking\nrequires aligning stakeholder incentives in targeted application domains and\nfostering active community engagement.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6c34\u5370\u6280\u672f\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u969c\u788d\uff0c\u6307\u51fa\u5229\u76ca\u76f8\u5173\u8005\uff08\u6a21\u578b\u63d0\u4f9b\u5546\u3001\u5e73\u53f0\u548c\u7ec8\u7aef\u7528\u6237\uff09\u7684\u52a8\u673a\u4e0d\u5339\u914d\u662f\u4e3b\u8981\u539f\u56e0\u3002\u6587\u7ae0\u91cd\u65b0\u5ba1\u89c6\u4e86\u4e09\u79cd\u6c34\u5370\u6280\u672f\uff1a\u6a21\u578b\u6c34\u5370\u3001\u6587\u672c\u6c34\u5370\u548c\u4e0a\u4e0b\u6587\u6c34\u5370\uff08ICW\uff09\uff0c\u5e76\u5f3a\u8c03ICW\u80fd\u901a\u8fc7\u4e09\u65b9\u52a8\u673a\u5bf9\u9f50\u5b9e\u73b0\u5b9e\u7528\u5316\u3002\u6700\u540e\u63d0\u51fa\u901a\u8fc7\u52a8\u673a\u5bf9\u9f50\u548c\u793e\u533a\u53c2\u4e0e\u63a8\u52a8\u6c34\u5370\u5e94\u7528\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u89e3\u51b3LLM\u6c34\u5370\u5b9e\u9645\u90e8\u7f72\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u73b0\u6709\u6c34\u5370\u6280\u672f\u56e0\u4e09\u65b9\u52a8\u673a\u9519\u4f4d\u9762\u4e34\u56db\u5927\u969c\u788d\uff1a\u7ade\u4e89\u98ce\u9669\u3001\u68c0\u6d4b\u5de5\u5177\u6cbb\u7406\u3001\u9c81\u68d2\u6027\u62c5\u5fe7\u548c\u5f52\u5c5e\u95ee\u9898\u3002\u901a\u8fc7\u91cd\u65b0\u5206\u7c7b\u6c34\u5370\u6280\u672f\u5e76\u5206\u6790\u5404\u65b9\u6848\u7684\u5229\u76ca\u5951\u5408\u5ea6\uff0c\u5bfb\u6c42\u53ef\u843d\u5730\u573a\u666f\u3002", "method": "\u91c7\u7528\u6846\u67b6\u5206\u6790\u6cd5\uff1a1. \u8bc6\u522bLLM\u751f\u6001\u4e2d\u4e09\u5927\u4e3b\u4f53\uff08\u63d0\u4f9b\u5546\u3001\u5e73\u53f0\u3001\u7528\u6237\uff09\u7684\u52a8\u673a\u51b2\u7a81\uff1b2. \u5c06\u73b0\u6709\u6c34\u5370\u5206\u4e3a\u4e09\u7c7b\uff08\u6a21\u578b\u6c34\u5370/\u6587\u672c\u6c34\u5370/\u4e0a\u4e0b\u6587\u6c34\u5370\uff09\uff0c\u9010\u7c7b\u8bc4\u4f30\u5176\u4e0e\u4e3b\u4f53\u52a8\u673a\u7684\u5951\u5408\u5ea6\uff1b3. \u63d0\u51faICW\u8303\u5f0f\u2014\u2014\u7531\u53ef\u4fe1\u7b2c\u4e09\u65b9\uff08\u5982\u4f1a\u8bae\u4e3b\u529e\u65b9\uff09\u5728\u8f93\u5165\u6587\u6863\u4e2d\u5d4c\u5165\u6c34\u5370\u6307\u4ee4\uff0c\u5f53\u6076\u610f\u884c\u4e3a\u8005\u63d0\u4ea4\u7ed9LLM\u65f6\uff0c\u8f93\u51fa\u4f1a\u643a\u5e26\u53ef\u68c0\u6d4b\u6c34\u5370\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff1a1. \u6a21\u578b\u6c34\u5370\u56e0\u5f00\u6e90\u751f\u6001\u53d1\u5c55\u9762\u4e34\u65b0\u6311\u6218\uff1b2. \u6587\u672c\u6c34\u5370\u4ec5\u5728\u7279\u5b9a\u573a\u666f\uff08\u5982\u6570\u636e\u96c6\u51c0\u5316\uff09\u6709\u6548\uff1b3. ICW\u5c55\u73b0\u51fa\u52a8\u673a\u5bf9\u9f50\u4f18\u52bf\uff1a\u53ef\u4fe1\u7b2c\u4e09\u65b9\u83b7\u5f97\u68c0\u6d4b\u5de5\u5177\uff0c\u7528\u6237\u65e0\u4f53\u9a8c\u635f\u5931\uff0cLLM\u63d0\u4f9b\u5546\u4fdd\u6301\u4e2d\u7acb\u3002\u6846\u67b6\u9a8c\u8bc1\u4e86\u52a8\u673a\u5bf9\u9f50\u5bf9\u6280\u672f\u843d\u5730\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7ed3\u8bba\u4e3b\u5f20\u5e94\u5f00\u53d1\u6fc0\u52b1\u517c\u5bb9\u7684\u6c34\u5370\u65b9\u6848\uff08\u4ee5ICW\u4e3a\u4f8b\uff09\uff0c\u91cd\u70b9\u670d\u52a1\u5b58\u5728\u53ef\u4fe1\u7b2c\u4e09\u65b9\u68c0\u6d4b\u9700\u6c42\u7684\u573a\u666f\uff08\u5982\u5b66\u672f\u4f1a\u8bae\u53cd\u527d\u7a83\uff09\u3002\u63d0\u51fa\u4e24\u5927\u539f\u5219\uff1a\u5782\u76f4\u9886\u57df\u5b9a\u5236\u5316\u548c\u793e\u533a\u53c2\u4e0e\u5171\u5efa\uff0c\u5e76\u547c\u5401\u66f4\u591a\u52a8\u673a\u5bfc\u5411\u7684\u6c34\u5370\u7814\u7a76\u3002"}}
{"id": "2510.18438", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.18438", "abs": "https://arxiv.org/abs/2510.18438", "authors": ["Yixuan Liu", "Xinlei Li", "Yi Li"], "title": "DeepTx: Real-Time Transaction Risk Analysis via Multi-Modal Features and LLM Reasoning", "comment": "Accepted to ASE'25", "summary": "Phishing attacks in Web3 ecosystems are increasingly sophisticated,\nexploiting deceptive contract logic, malicious frontend scripts, and token\napproval patterns. We present DeepTx, a real-time transaction analysis system\nthat detects such threats before user confirmation. DeepTx simulates pending\ntransactions, extracts behavior, context, and UI features, and uses multiple\nlarge language models (LLMs) to reason about transaction intent. A consensus\nmechanism with self-reflection ensures robust and explainable decisions.\nEvaluated on our phishing dataset, DeepTx achieves high precision and recall\n(demo video: https://youtu.be/4OfK9KCEXUM).", "AI": {"tldr": "DeepTx\u662f\u4e00\u4e2a\u5b9e\u65f6\u4ea4\u6613\u5206\u6790\u7cfb\u7edf\uff0c\u7528\u4e8e\u5728\u7528\u6237\u786e\u8ba4\u524d\u68c0\u6d4bWeb3\u9493\u9c7c\u653b\u51fb\u3002\u5b83\u901a\u8fc7\u6a21\u62df\u4ea4\u6613\u3001\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u5229\u7528\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u4ea4\u6613\u610f\u56fe\uff0c\u7ed3\u5408\u81ea\u7701\u5171\u8bc6\u673a\u5236\u505a\u51fa\u89e3\u91ca\u6027\u51b3\u7b56\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u68c0\u6d4b\u3002", "motivation": "\u5e94\u5bf9Web3\u751f\u6001\u4e2d\u65e5\u76ca\u590d\u6742\u7684\u9493\u9c7c\u653b\u51fb\uff0c\u5305\u62ec\u5229\u7528\u6076\u610f\u5408\u7ea6\u903b\u8f91\u3001\u524d\u7aef\u811a\u672c\u548c\u4ee3\u5e01\u6388\u6743\u6a21\u5f0f\u7684\u65b0\u578b\u653b\u51fb\u3002", "method": "DeepTx\u6a21\u62df\u5f85\u5904\u7406\u4ea4\u6613\uff0c\u63d0\u53d6\u884c\u4e3a\u3001\u4e0a\u4e0b\u6587\u53ca\u7528\u6237\u754c\u9762\u7279\u5f81\uff0c\u4f7f\u7528\u591a\u4e2aLLMs\u63a8\u7406\u4ea4\u6613\u610f\u56fe\uff0c\u5e76\u901a\u8fc7\u81ea\u7701\u5171\u8bc6\u673a\u5236\u786e\u4fdd\u51b3\u7b56\u7a33\u5065\u53ef\u89e3\u91ca\u3002", "result": "\u5728\u9493\u9c7c\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\u8fbe\u5230\u9ad8\u7cbe\u786e\u7387(precision)\u548c\u53ec\u56de\u7387(recall)\u3002", "conclusion": "\u7cfb\u7edf\u80fd\u6709\u6548\u5b9e\u65f6\u68c0\u6d4b\u590d\u6742\u9493\u9c7c\u653b\u51fb\uff0c\u4fdd\u62a4\u7528\u6237\u8d44\u4ea7\u5b89\u5168\uff0c\u6280\u672f\u65b9\u6848\u5177\u5907\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2510.18465", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.18465", "abs": "https://arxiv.org/abs/2510.18465", "authors": ["Spencer King", "Irfan Ozen", "Karthika Subramani", "Saranyan Senthivel", "Phani Vadrevu", "Roberto Perdisci"], "title": "PP3D: An In-Browser Vision-Based Defense Against Web Behavior Manipulation Attacks", "comment": "17 pages total (including references and appendices), 5 figures, 8\n  tables, and 1 algorithm. To appear in the Proceedings of the 41st Annual\n  Computer Security Applications Conference (ACSAC 2025). Camera-ready version\n  formatted in IEEE two-column style. Code, pretrained models, and dataset\n  available at: https://github.com/NISLabUGA/PixelPatrol3D_Code", "summary": "Web-based behavior-manipulation attacks (BMAs) - such as scareware, fake\nsoftware downloads, tech support scams, etc. - are a class of social\nengineering (SE) attacks that exploit human decision-making vulnerabilities.\nThese attacks remain under-studied compared to other attacks such as\ninformation harvesting attacks (e.g., phishing) or malware infections. Prior\ntechnical work has primarily focused on measuring BMAs, offering little in the\nway of generic defenses.\n  To address this gap, we introduce Pixel Patrol 3D (PP3D), the first\nend-to-end browser framework for discovering, detecting, and defending against\nbehavior-manipulating SE attacks in real time. PP3D consists of a visual\ndetection model implemented within a browser extension, which deploys the model\nclient-side to protect users across desktop and mobile devices while preserving\nprivacy.\n  Our evaluation shows that PP3D can achieve above 99% detection rate at 1%\nfalse positives, while maintaining good latency and overhead performance across\ndevices. Even when faced with new BMA samples collected months after training\nthe detection model, our defense system can still achieve above 97% detection\nrate at 1% false positives. These results demonstrate that our framework offers\na practical, effective, and generalizable defense against a broad and evolving\nclass of web behavior-manipulation attacks.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u7aef\u5230\u7aef\u6d4f\u89c8\u5668\u6846\u67b6PP3D\uff0c\u7528\u4e8e\u5b9e\u65f6\u53d1\u73b0\u3001\u68c0\u6d4b\u548c\u9632\u5fa1\u57fa\u4e8e\u884c\u4e3a\u64cd\u7eb5\u7684\u793e\u4f1a\u5de5\u7a0b\u653b\u51fb\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6d4f\u89c8\u5668\u6269\u5c55\u5b9e\u73b0\u89c6\u89c9\u68c0\u6d4b\u6a21\u578b\uff0c\u5728\u5ba2\u6237\u7aef\u90e8\u7f72\u4ee5\u4fdd\u62a4\u7528\u6237\u9690\u79c1\uff0c\u5e76\u5728\u8bc4\u4f30\u4e2d\u663e\u793a\u51fa\u9ad8\u68c0\u6d4b\u7387\u548c\u4f4e\u8bef\u62a5\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u7f51\u9875\u7684\u884c\u4e3a\u64cd\u7eb5\u653b\u51fb\uff08BMAs\uff09\u5982\u6050\u5413\u8f6f\u4ef6\u3001\u865a\u5047\u4e0b\u8f7d\u7b49\u793e\u4f1a\u5de5\u7a0b\u653b\u51fb\u5229\u7528\u4eba\u7c7b\u51b3\u7b56\u6f0f\u6d1e\uff0c\u4f46\u76f8\u8f83\u4e8e\u5176\u4ed6\u653b\u51fb\uff08\u5982\u9493\u9c7c\u6216\u6076\u610f\u8f6f\u4ef6\uff09\u7814\u7a76\u4e0d\u8db3\u3002\u4e4b\u524d\u7684\u6280\u672f\u5de5\u4f5c\u4e3b\u8981\u96c6\u4e2d\u4e8e\u6d4b\u91cfBMAs\uff0c\u7f3a\u4e4f\u901a\u7528\u9632\u5fa1\u65b9\u6848\u3002", "method": "\u5f15\u5165Pixel Patrol 3D (PP3D)\u6846\u67b6\uff1a\u4e00\u4e2a\u8fd0\u884c\u5728\u6d4f\u89c8\u5668\u6269\u5c55\u4e2d\u7684\u89c6\u89c9\u68c0\u6d4b\u6a21\u578b\uff0c\u901a\u8fc7\u5ba2\u6237\u7aef\u90e8\u7f72\u5b9e\u73b0\u8de8\u8bbe\u5907\uff08\u684c\u9762\u548c\u79fb\u52a8\u7aef\uff09\u7684\u5b9e\u65f6\u9632\u62a4\uff0c\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002\u6a21\u578b\u53ef\u76f4\u63a5\u5728\u6d4f\u89c8\u5668\u4e2d\u5206\u6790\u9875\u9762\u5185\u5bb9\u3002", "result": "\u8bc4\u4f30\u663e\u793aPP3D\u57281%\u8bef\u62a5\u7387\u4e0b\u68c0\u6d4b\u7387\u8d85\u8fc799%\uff0c\u4e14\u5728\u4e0d\u540c\u8bbe\u5907\u4e0a\u5ef6\u8fdf\u548c\u5f00\u9500\u8868\u73b0\u826f\u597d\u3002\u5373\u4f7f\u9762\u5bf9\u8bad\u7ec3\u540e\u6570\u6708\u6536\u96c6\u7684\u65b0BMA\u6837\u672c\uff0c\u4ecd\u80fd\u4fdd\u630197%\u4ee5\u4e0a\u68c0\u6d4b\u7387\uff081%\u8bef\u62a5\u7387\uff09\u3002", "conclusion": "PP3D\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u3001\u9ad8\u6548\u4e14\u53ef\u6cdb\u5316\u7684\u9632\u5fa1\u65b9\u6848\uff0c\u80fd\u5e94\u5bf9\u5e7f\u6cdb\u4e14\u6301\u7eed\u6f14\u53d8\u7684\u7f51\u9875\u884c\u4e3a\u64cd\u7eb5\u653b\u51fb\u3002"}}
{"id": "2510.18508", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.18508", "abs": "https://arxiv.org/abs/2510.18508", "authors": ["Osama Al Haddad", "Muhammad Ikram", "Ejaz Ahmed", "Young Lee"], "title": "Prompting the Priorities: A First Look at Evaluating LLMs for Vulnerability Triage and Prioritization", "comment": "19 pages, 8 figures", "summary": "Security analysts face increasing pressure to triage large and complex\nvulnerability backlogs. Large Language Models (LLMs) offer a potential aid by\nautomating parts of the interpretation process. We evaluate four models\n(ChatGPT, Claude, Gemini, and DeepSeek) across twelve prompting techniques to\ninterpret semi-structured and unstructured vulnerability information. As a\nconcrete use case, we test each model's ability to predict decision points in\nthe Stakeholder-Specific Vulnerability Categorization (SSVC) framework:\nExploitation, Automatable, Technical Impact, and Mission and Wellbeing.\n  Using 384 real-world vulnerabilities from the VulZoo dataset, we issued more\nthan 165,000 queries to assess performance under prompting styles including\none-shot, few-shot, and chain-of-thought. We report F1 scores for each SSVC\ndecision point and Cohen's kappa (weighted and unweighted) for the final SSVC\ndecision outcomes. Gemini consistently ranked highest, leading on three of four\ndecision points and yielding the most correct recommendations. Prompting with\nexemplars generally improved accuracy, although all models struggled on some\ndecision points. Only DeepSeek achieved fair agreement under weighted metrics,\nand all models tended to over-predict risk.\n  Overall, current LLMs do not replace expert judgment. However, specific LLM\nand prompt combinations show moderate effectiveness for targeted SSVC\ndecisions. When applied with care, LLMs can support vulnerability\nprioritization workflows and help security teams respond more efficiently to\nemerging threats.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u56db\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08ChatGPT\u3001Claude\u3001Gemini\u548cDeepSeek\uff09\u5728\u89e3\u91ca\u6f0f\u6d1e\u4fe1\u606f\u65b9\u9762\u7684\u8868\u73b0\uff0c\u91cd\u70b9\u5173\u6ce8\u5b83\u4eec\u5728SSVC\u6846\u67b6\u51b3\u7b56\u70b9\u9884\u6d4b\u4e0a\u7684\u6548\u679c\u3002\u4f7f\u7528384\u4e2a\u771f\u5b9e\u6f0f\u6d1e\u8fdb\u884c\u6d4b\u8bd5\uff0cGemini\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5747\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u66ff\u4ee3\u4e13\u5bb6\u5224\u65ad\u3002", "motivation": "\u5b89\u5168\u5206\u6790\u5e08\u9762\u4e34\u5e9e\u5927\u7684\u6f0f\u6d1e\u79ef\u538b\u538b\u529b\uff0c\u7814\u7a76\u65e8\u5728\u63a2\u7d22LLM\u81ea\u52a8\u5316\u90e8\u5206\u6f0f\u6d1e\u89e3\u8bfb\u6d41\u7a0b\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u8f85\u52a9\u6f0f\u6d1e\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "method": "\u91c7\u752812\u79cd\u63d0\u793a\u6280\u672f\uff08\u5305\u62ec\u5355\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u601d\u7ef4\u94fe\uff09\uff0c\u57fa\u4e8eVulZoo\u6570\u636e\u96c6\u7684384\u4e2a\u6f0f\u6d1e\u53d1\u8d77\u8d8516.5\u4e07\u6b21\u67e5\u8be2\uff0c\u8bc4\u4f30\u6a21\u578b\u5728SSVC\u56db\u5927\u51b3\u7b56\u70b9\uff08\u5229\u7528\u6027\u3001\u81ea\u52a8\u5316\u3001\u6280\u672f\u5f71\u54cd\u3001\u4f7f\u547d\u4e0e\u798f\u7949\uff09\u7684\u9884\u6d4b\u80fd\u529b\u3002\u4f7f\u7528F1\u5206\u6570\u548cCohen's Kappa\u7cfb\u6570\uff08\u52a0\u6743/\u672a\u52a0\u6743\uff09\u8861\u91cf\u6027\u80fd\u3002", "result": "Gemini\u5728\u4e09\u4e2a\u51b3\u7b56\u70b9\u4e0a\u8868\u73b0\u6700\u4f18\uff1b\u793a\u4f8b\u63d0\u793a\u666e\u904d\u63d0\u5347\u51c6\u786e\u6027\uff0c\u4f46\u6240\u6709\u6a21\u578b\u5728\u90e8\u5206\u51b3\u7b56\u70b9\u8868\u73b0\u4e0d\u4f73\uff1b\u4ec5DeepSeek\u5728\u52a0\u6743\u6307\u6807\u4e0a\u8fbe\u5230\u4e00\u822c\u4e00\u81f4\u6027\uff0c\u4e14\u6240\u6709\u6a21\u578b\u503e\u5411\u4e8e\u9ad8\u4f30\u98ce\u9669\u3002", "conclusion": "\u5f53\u524dLLM\u65e0\u6cd5\u66ff\u4ee3\u4e13\u5bb6\u5224\u65ad\uff0c\u4f46\u7279\u5b9a\u6a21\u578b\u4e0e\u63d0\u793a\u7ec4\u5408\u5bf9\u76ee\u6807SSVC\u51b3\u7b56\u8868\u73b0\u51fa\u4e2d\u7b49\u6709\u6548\u6027\u3002\u8c28\u614e\u4f7f\u7528\u65f6\uff0cLLM\u53ef\u63d0\u5347\u6f0f\u6d1e\u4f18\u5148\u7ea7\u5de5\u4f5c\u6d41\u6548\u7387\u3002"}}
{"id": "2510.18563", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.18563", "abs": "https://arxiv.org/abs/2510.18563", "authors": ["Zijie Xu", "Minfeng Qi", "Shiqing Wu", "Lefeng Zhang", "Qiwen Wei", "Han He", "Ningran Li"], "title": "The Trust Paradox in LLM-Based Multi-Agent Systems: When Collaboration Becomes a Security Vulnerability", "comment": null, "summary": "Multi-agent systems powered by large language models are advancing rapidly,\nyet the tension between mutual trust and security remains underexplored. We\nintroduce and empirically validate the Trust-Vulnerability Paradox (TVP):\nincreasing inter-agent trust to enhance coordination simultaneously expands\nrisks of over-exposure and over-authorization. To investigate this paradox, we\nconstruct a scenario-game dataset spanning 3 macro scenes and 19 sub-scenes,\nand run extensive closed-loop interactions with trust explicitly parameterized.\nUsing Minimum Necessary Information (MNI) as the safety baseline, we propose\ntwo unified metrics: Over-Exposure Rate (OER) to detect boundary violations,\nand Authorization Drift (AD) to capture sensitivity to trust levels. Results\nacross multiple model backends and orchestration frameworks reveal consistent\ntrends: higher trust improves task success but also heightens exposure risks,\nwith heterogeneous trust-to-risk mappings across systems. We further examine\ndefenses such as Sensitive Information Repartitioning and Guardian-Agent\nenablement, both of which reduce OER and attenuate AD. Overall, this study\nformalizes TVP, establishes reproducible baselines with unified metrics, and\ndemonstrates that trust must be modeled and scheduled as a first-class security\nvariable in multi-agent system design.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u4fe1\u4efb-\u6f0f\u6d1e\u6096\u8bba\uff08TVP\uff09\uff0c\u5373\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u63d0\u9ad8\u4fe1\u4efb\u4ee5\u589e\u5f3a\u534f\u8c03\u7684\u540c\u65f6\u4f1a\u589e\u52a0\u8fc7\u5ea6\u66b4\u9732\u548c\u8fc7\u5ea6\u6388\u6743\u98ce\u9669\u3002\u901a\u8fc7\u6784\u5efa\u8de8\u573a\u666f\u6570\u636e\u96c6\u548c\u5f15\u5165\u65b0\u6307\u6807\uff0c\u63ed\u793a\u4e86\u9ad8\u4fe1\u4efb\u5728\u63d0\u9ad8\u4efb\u52a1\u6210\u529f\u7387\u7684\u540c\u65f6\u4e5f\u589e\u52a0\u66b4\u9732\u98ce\u9669\u7684\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u9632\u5fa1\u65b9\u6cd5\u4ee5\u51cf\u8f7b\u98ce\u9669\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u4fe1\u4efb\u4e0e\u5b89\u5168\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u63d0\u9ad8\u667a\u80fd\u4f53\u95f4\u4fe1\u4efb\u4ee5\u589e\u5f3a\u534f\u8c03\u7684\u540c\u65f6\u5982\u4f55\u6269\u5927\u98ce\u9669\uff0c\u5373\u4fe1\u4efb-\u6f0f\u6d1e\u6096\u8bba\uff08TVP\uff09\u3002", "method": "\u6784\u5efa\u5305\u542b3\u4e2a\u5b8f\u89c2\u573a\u666f\u548c19\u4e2a\u5b50\u573a\u666f\u7684\u573a\u666f-\u6e38\u620f\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u95ed\u73af\u4ea4\u4e92\u5b9e\u9a8c\u5e76\u663e\u5f0f\u53c2\u6570\u5316\u4fe1\u4efb\u5173\u7cfb\u3002\u63d0\u51fa\u4e24\u4e2a\u7edf\u4e00\u6307\u6807\uff1a\u57fa\u4e8e\u6700\u5c0f\u5fc5\u8981\u4fe1\u606f\uff08MNI\uff09\u5b89\u5168\u57fa\u51c6\u7684\u66b4\u9732\u8fb9\u754c\u68c0\u6d4b\u6307\u6807\uff08OER\uff09\u548c\u4fe1\u4efb\u6c34\u5e73\u654f\u611f\u5ea6\u6307\u6807\uff08AD\uff09\u3002", "result": "\u8de8\u6a21\u578b\u548c\u6846\u67b6\u7684\u5b9e\u9a8c\u663e\u793a\uff1a\u66f4\u9ad8\u4fe1\u4efb\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\uff0c\u4f46\u589e\u52a0\u66b4\u9732\u98ce\u9669\uff1b\u4e0d\u540c\u7cfb\u7edf\u7684\u4fe1\u4efb-\u98ce\u9669\u6620\u5c04\u5b58\u5728\u5f02\u8d28\u6027\u3002\u63d0\u51fa\u7684\u654f\u611f\u4fe1\u606f\u5206\u533a\u548c\u5b88\u62a4\u667a\u80fd\u4f53\u9632\u5fa1\u673a\u5236\u6709\u6548\u964d\u4f4eOER\u4e0eAD\u3002", "conclusion": "\u7814\u7a76\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86TVP\uff0c\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u57fa\u7ebf\uff0c\u8bc1\u5b9e\u4fe1\u4efb\u5fc5\u987b\u4f5c\u4e3a\u9996\u8981\u5b89\u5168\u53d8\u91cf\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u5efa\u6a21\u548c\u8c03\u5ea6\u3002"}}
{"id": "2510.18568", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.18568", "abs": "https://arxiv.org/abs/2510.18568", "authors": ["Behnam Rezaei Bezanjani", "Seyyed Hamid Ghafouri", "Reza Gholamrezaei"], "title": "Privacy-Preserving Healthcare Data in IoT: A Synergistic Approach with Deep Learning and Blockchain", "comment": "30 pages", "summary": "The integration of Internet of Things (IoT) devices in healthcare has\nrevolutionized patient care by enabling real-time monitoring, personalized\ntreatments, and efficient data management. However, this technological\nadvancement introduces significant security risks, particularly concerning the\nconfidentiality, integrity, and availability of sensitive medical data.\nTraditional security measures are often insufficient to address the unique\nchallenges posed by IoT environments, such as heterogeneity, resource\nconstraints, and the need for real-time processing. To tackle these challenges,\nwe propose a comprehensive three-phase security framework designed to enhance\nthe security and reliability of IoT-enabled healthcare systems. In the first\nphase, the framework assesses the reliability of IoT devices using a\nreputation-based trust estimation mechanism, which combines device behavior\nanalytics with off-chain data storage to ensure scalability. The second phase\nintegrates blockchain technology with a lightweight proof-of-work mechanism,\nensuring data immutability, secure communication, and resistance to\nunauthorized access. The third phase employs a lightweight Long Short-Term\nMemory (LSTM) model for anomaly detection and classification, enabling\nreal-time identification of cyber threats. Simulation results demonstrate that\nthe proposed framework outperforms existing methods, achieving a 2% increase in\nprecision, accuracy, and recall, a 5% higher attack detection rate, and a 3%\nreduction in false alarm rate. These improvements highlight the framework's\nability to address critical security concerns while maintaining scalability and\nreal-time performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u533b\u7597\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u5b89\u5168\u6846\u67b6\uff0c\u5305\u62ec\u8bbe\u5907\u4fe1\u4efb\u8bc4\u4f30\u3001\u533a\u5757\u94fe\u96c6\u6210\u548c\u8f7b\u91cf\u7ea7LSTM\u5f02\u5e38\u68c0\u6d4b\uff0c\u5728\u7cbe\u5ea6\u3001\u653b\u51fb\u68c0\u6d4b\u7387\u548c\u964d\u4f4e\u8bef\u62a5\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u533b\u7597\u7269\u8054\u7f51\u8bbe\u5907\u5728\u63d0\u5347\u533b\u7597\u670d\u52a1\u7684\u540c\u65f6\u5e26\u6765\u4e86\u5b89\u5168\u98ce\u9669\u3002\u4f20\u7edf\u5b89\u5168\u63aa\u65bd\u65e0\u6cd5\u6ee1\u8db3\u5176\u5f02\u6784\u3001\u8d44\u6e90\u53d7\u9650\u548c\u5b9e\u65f6\u6027\u9700\u6c42\uff0c\u9700\u8981\u4e00\u4e2a\u517c\u987e\u5b89\u5168\u4e0e\u6548\u7387\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5206\u4e09\u9636\u6bb5\uff1a1) \u57fa\u4e8e\u4fe1\u8a89\u673a\u5236\u8bc4\u4f30\u8bbe\u5907\u53ef\u9760\u6027\uff1b2) \u533a\u5757\u94fe\u6574\u5408\u8f7b\u91cf\u7ea7\u5de5\u4f5c\u91cf\u8bc1\u660e\u786e\u4fdd\u6570\u636e\u5b89\u5168\uff1b3) \u8f7b\u91cf\u7ea7LSTM\u6a21\u578b\u5b9e\u65f6\u68c0\u6d4b\u5f02\u5e38\u3002", "result": "\u6846\u67b6\u7cbe\u5ea6\u3001\u51c6\u786e\u7387\u3001\u53ec\u56de\u7387\u5747\u63d0\u53472%\uff0c\u653b\u51fb\u68c0\u6d4b\u7387\u4e0a\u53475%\uff0c\u8bef\u62a5\u7387\u964d\u4f4e3%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u4fdd\u8bc1\u5b9e\u65f6\u6027\u548c\u53ef\u6269\u5c55\u6027\u7684\u540c\u65f6\uff0c\u80fd\u6709\u6548\u589e\u5f3a\u533b\u7597\u7269\u8054\u7f51\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2510.18601", "categories": ["cs.CR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.18601", "abs": "https://arxiv.org/abs/2510.18601", "authors": ["Marco Alecci", "Jordan Samhi", "Tegawend\u00e9 F. Bissyand\u00e9", "Jacques Klein"], "title": "Evaluating Large Language Models in detecting Secrets in Android Apps", "comment": null, "summary": "Mobile apps often embed authentication secrets, such as API keys, tokens, and\nclient IDs, to integrate with cloud services. However, developers often\nhardcode these credentials into Android apps, exposing them to extraction\nthrough reverse engineering. Once compromised, adversaries can exploit secrets\nto access sensitive data, manipulate resources, or abuse APIs, resulting in\nsignificant security and financial risks. Existing detection approaches, such\nas regex-based analysis, static analysis, and machine learning, are effective\nfor identifying known patterns but are fundamentally limited: they require\nprior knowledge of credential structures, API signatures, or training data.\n  In this paper, we propose SecretLoc, an LLM-based approach for detecting\nhardcoded secrets in Android apps. SecretLoc goes beyond pattern matching; it\nleverages contextual and structural cues to identify secrets without relying on\npredefined patterns or labeled training sets. Using a benchmark dataset from\nthe literature, we demonstrate that SecretLoc detects secrets missed by regex-,\nstatic-, and ML-based methods, including previously unseen types of secrets. In\ntotal, we discovered 4828 secrets that were undetected by existing approaches,\ndiscovering more than 10 \"new\" types of secrets, such as OpenAI API keys,\nGitHub Access Tokens, RSA private keys, and JWT tokens, and more.\n  We further extend our analysis to newly crawled apps from Google Play, where\nwe uncovered and responsibly disclosed additional hardcoded secrets. Across a\nset of 5000 apps, we detected secrets in 2124 apps (42.5%), several of which\nwere confirmed and remediated by developers after we contacted them. Our\nresults reveal a dual-use risk: if analysts can uncover these secrets with\nLLMs, so can attackers. This underscores the urgent need for proactive secret\nmanagement and stronger mitigation practices across the mobile ecosystem.", "AI": {"tldr": "SecretLoc\u662f\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4bAndroid\u5e94\u7528\u4e2d\u7684\u786c\u7f16\u7801\u79d8\u5bc6\u51ed\u8bc1\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e0a\u4e0b\u6587\u548c\u7ed3\u6784\u7ebf\u7d22\uff0c\u65e0\u9700\u4f9d\u8d56\u9884\u5b9a\u4e49\u6a21\u5f0f\u6216\u6807\u8bb0\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8bc1\u660eSecretLoc\u80fd\u68c0\u6d4b\u51fa\u6b63\u5219\u8868\u8fbe\u5f0f\u3001\u9759\u6001\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9057\u6f0f\u7684\u79d8\u5bc6\uff0c\u5305\u62ec\u65b0\u7c7b\u578b\u3002\u5728\u5206\u6790Google Play\u5e94\u7528\u65f6\uff0c\u53d1\u73b0\u5927\u91cf\u5e94\u7528\u5b58\u5728\u6b64\u95ee\u9898\uff0c\u51f8\u663e\u4e86\u4e3b\u52a8\u7ba1\u7406\u79d8\u5bc6\u51ed\u8bc1\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\uff08\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f/\u9759\u6001\u5206\u6790/\u673a\u5668\u5b66\u4e60\uff09\u9700\u8981\u9884\u77e5\u51ed\u8bc1\u7ed3\u6784\u6216\u8bad\u7ec3\u6570\u636e\uff0c\u5b58\u5728\u6839\u672c\u6027\u5c40\u9650\u3002\u5f00\u53d1\u8005\u786c\u7f16\u7801API\u5bc6\u94a5\u7b49\u51ed\u8bc1\u7684\u884c\u4e3a\u4f1a\u5bfc\u81f4\u4e25\u91cd\u5b89\u5168\u98ce\u9669\uff0c\u4e00\u65e6\u906d\u7a83\u53d6\u53ef\u5f15\u53d1\u6570\u636e\u6cc4\u9732\u6216\u8d44\u6e90\u6ee5\u7528\u3002", "method": "\u63d0\u51faSecretLoc\u65b9\u6cd5\uff1a\u5229\u7528LLM\u6a21\u578b\uff0c\u901a\u8fc7\u5206\u6790\u4ee3\u7801\u4e2d\u7684\u4e0a\u4e0b\u6587\u548c\u7ed3\u6784\u7279\u5f81\u6765\u8bc6\u522b\u786c\u7f16\u7801\u79d8\u5bc6\u3002\u4e0d\u9700\u8981\u9884\u5b9a\u4e49\u6a21\u5f0f\u6216\u6807\u8bb0\u8bad\u7ec3\u96c6\u3002\u4f7f\u7528\u6765\u81ea\u6587\u732e\u7684\u57fa\u51c6\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "1. \u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e2d\u53d1\u73b04828\u4e2a\u73b0\u6709\u65b9\u6cd5\u9057\u6f0f\u7684\u79d8\u5bc6\uff0c\u5305\u62ec10\u4f59\u79cd\u65b0\u7c7b\u578b\uff08\u5982OpenAI API\u5bc6\u94a5\u3001GitHub\u4ee4\u724c\u7b49\uff09\u30022. \u5728Google Play\u76845000\u4e2a\u5e94\u7528\u4e2d\u68c0\u6d4b\u52302124\u4e2a\u5e94\u7528\uff0842.5%\uff09\u5b58\u5728\u79d8\u5bc6\u51ed\u8bc1\uff0c\u90e8\u5206\u6f0f\u6d1e\u7ecf\u62ab\u9732\u540e\u4fee\u590d\u3002", "conclusion": "\u653b\u51fb\u8005\u540c\u6837\u80fd\u5229\u7528LLM\u6280\u672f\u7a83\u53d6\u79d8\u5bc6\uff0c\u51f8\u663e\u79fb\u52a8\u751f\u6001\u7cfb\u7edf\u4e2d\u4e3b\u52a8\u51ed\u8bc1\u7ba1\u7406\u548c\u5f3a\u5316\u9632\u62a4\u63aa\u65bd\u7684\u7d27\u8feb\u6027\u3002SecretLoc\u8bc1\u660eLLM\u80fd\u6709\u6548\u68c0\u6d4b\u672a\u77e5\u7c7b\u578b\u7684\u786c\u7f16\u7801\u79d8\u5bc6\u3002"}}
{"id": "2510.18612", "categories": ["cs.CR", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.18612", "abs": "https://arxiv.org/abs/2510.18612", "authors": ["Muhammad Hassan", "Maria Mushtaq", "Jaan Raik", "Tara Ghasempouri"], "title": "DRsam: Detection of Fault-Based Microarchitectural Side-Channel Attacks in RISC-V Using Statistical Preprocessing and Association Rule Mining", "comment": null, "summary": "RISC-V processors are becoming ubiquitous in critical applications, but their\nsusceptibility to microarchitectural side-channel attacks is a serious concern.\nDetection of microarchitectural attacks in RISC-V is an emerging research topic\nthat is relatively underexplored, compared to x86 and ARM. The first line of\nwork to detect flush+fault-based microarchitectural attacks in RISC-V leverages\nMachine Learning (ML) models, yet it leaves several practical aspects that need\nfurther investigation. To address overlooked issues, we leveraged gem5 and\npropose a new detection method combining statistical preprocessing and\nassociation rule mining having reconfiguration capabilities to generalize the\ndetection method for any microarchitectural attack. The performance comparison\nwith state-of-the-art reveals that the proposed detection method achieves up to\n5.15% increase in accuracy, 7% rise in precision, and 3.91% improvement in\nrecall under the cryptographic, computational, and memory-intensive workloads\nalongside its flexibility to detect new variant of flush+fault attack.\nMoreover, as the attack detection relies on association rules, their\nhuman-interpretable nature provides deep insight to understand\nmicroarchitectural behavior during the execution of attack and benign\napplications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7edf\u8ba1\u9884\u5904\u7406\u548c\u5173\u8054\u89c4\u5219\u6316\u6398\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4bRISC-V\u5904\u7406\u5668\u4e2d\u7684\u5fae\u67b6\u6784\u4fa7\u4fe1\u9053\u653b\u51fb\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u91cd\u65b0\u914d\u7f6e\u80fd\u529b\uff0c\u80fd\u63a8\u5e7f\u5230\u4efb\u4f55\u5fae\u67b6\u6784\u653b\u51fb\u7684\u68c0\u6d4b\u3002\u4e0e\u73b0\u6709\u6280\u672f\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u52a0\u5bc6\u3001\u8ba1\u7b97\u548c\u5185\u5b58\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\u5b9e\u73b0\u4e86\u51c6\u786e\u6027\u3001\u7cbe\u786e\u5ea6\u548c\u53ec\u56de\u7387\u7684\u63d0\u5347\uff0c\u5e76\u80fd\u68c0\u6d4b\u65b0\u578bflush+fault\u653b\u51fb\u53d8\u4f53\u3002", "motivation": "RISC-V\u5904\u7406\u5668\u5728\u5173\u952e\u5e94\u7528\u4e2d\u7684\u666e\u53ca\u4f7f\u5176\u9762\u4e34\u5fae\u67b6\u6784\u4fa7\u4fe1\u9053\u653b\u51fb\u7684\u5a01\u80c1\uff0c\u800c\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\uff08\u5c24\u5176\u662f\u9488\u5bf9flush+fault\u653b\u51fb\uff09\u5b58\u5728\u5b9e\u8df5\u5c42\u9762\u7684\u4e0d\u8db3\u3002\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u68c0\u6d4b\u65b9\u6cd5\u5728\u5b9e\u7528\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u89e3\u51b3\u88ab\u5ffd\u89c6\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528gem5\u6a21\u62df\u5668\uff0c\u63d0\u51fa\u7ed3\u5408\u7edf\u8ba1\u9884\u5904\u7406\u548c\u5173\u8054\u89c4\u5219\u6316\u6398\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u53ef\u91cd\u65b0\u914d\u7f6e\u80fd\u529b\u5b9e\u73b0\u5bf9\u4efb\u610f\u5fae\u67b6\u6784\u653b\u51fb\u7684\u901a\u7528\u68c0\u6d4b\uff0c\u5e76\u5229\u7528\u5173\u8054\u89c4\u5219\u7684\u53ef\u89e3\u91ca\u6027\u6df1\u5165\u5206\u6790\u653b\u51fb/\u826f\u6027\u5e94\u7528\u6267\u884c\u65f6\u7684\u5fae\u67b6\u6784\u884c\u4e3a\u3002", "result": "\u5728\u52a0\u5bc6\u3001\u8ba1\u7b97\u548c\u5185\u5b58\u5bc6\u96c6\u578b\u5de5\u4f5c\u8d1f\u8f7d\u4e0b\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u51c6\u786e\u7387\u63d0\u53475.15%\uff0c\u7cbe\u786e\u5ea6\u63d0\u53477%\uff0c\u53ec\u56de\u7387\u63d0\u53473.91%\uff0c\u5e76\u80fd\u7075\u6d3b\u68c0\u6d4b\u65b0\u578bflush+fault\u653b\u51fb\u53d8\u4f53\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86RISC-V\u5fae\u67b6\u6784\u653b\u51fb\u68c0\u6d4b\u6027\u80fd\uff0c\u5176\u57fa\u4e8e\u5173\u8054\u89c4\u5219\u7684\u53ef\u89e3\u91ca\u6027\u4e3a\u7406\u89e3\u653b\u51fb\u673a\u5236\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u89e3\u51b3\u4e86\u73b0\u6709ML\u65b9\u6cd5\u672a\u8986\u76d6\u7684\u5b9e\u8df5\u95ee\u9898\u3002"}}
{"id": "2510.18614", "categories": ["cs.CR"], "pdf": "https://arxiv.org/pdf/2510.18614", "abs": "https://arxiv.org/abs/2510.18614", "authors": ["Ren\u00e9 Coignard", "Anton Rygin"], "title": "Qatsi: Stateless Secret Generation via Hierarchical Memory-Hard Key Derivation", "comment": null, "summary": "We present Qatsi, a hierarchical key derivation scheme using Argon2id that\ngenerates reproducible cryptographic secrets without persistent storage. The\nsystem eliminates vault-based attack surfaces by deriving all secrets\ndeterministically from a single high-entropy master secret and contextual\nlayers. Outputs achieve 103-312 bits of entropy through memory-hard derivation\n(64-128 MiB, 16-32 iterations) and provably uniform rejection sampling over\n7776-word mnemonics or 90-character passwords. We formalize the hierarchical\nconstruction, prove output uniformity, and quantify GPU attack costs: $2.4\n\\times 10^{16}$ years for 80-bit master secrets on single-GPU adversaries under\nParanoid parameters (128 MiB memory). The implementation in Rust provides\nautomatic memory zeroization, compile-time wordlist integrity verification, and\ncomprehensive test coverage. Reference benchmarks on Apple M1 Pro (2021)\ndemonstrate practical usability with 544 ms Standard mode and 2273 ms Paranoid\nmode single-layer derivations. Qatsi targets air-gapped systems and master\ncredential generation where stateless reproducibility outweighs rotation\nflexibility.", "AI": {"tldr": "Qatsi\u662f\u4e00\u4e2a\u57fa\u4e8eArgon2id\u7684\u5206\u5c42\u5bc6\u94a5\u6d3e\u751f\u65b9\u6848\uff0c\u65e0\u9700\u6301\u4e45\u5b58\u50a8\u5373\u53ef\u751f\u6210\u53ef\u590d\u73b0\u7684\u52a0\u5bc6\u5bc6\u94a5\u3002\u5b83\u901a\u8fc7\u4e3b\u5bc6\u94a5\u548c\u5206\u5c42\u4e0a\u4e0b\u6587\u786e\u5b9a\u6027\u5730\u6d3e\u751f\u6240\u6709\u5bc6\u94a5\uff0c\u6d88\u9664\u4e86\u57fa\u4e8e\u4fdd\u9669\u5e93\u7684\u653b\u51fb\u9762\u3002\u65b9\u6848\u901a\u8fc7\u5185\u5b58\u5bc6\u96c6\u578b\u7b97\u6cd5\u786e\u4fdd\u5bc6\u94a5\u71b5\u503c\u8fbe103-312 bit\uff0c\u91c7\u7528GPU\u653b\u51fb\u6210\u672c\u8bc1\u660e\u5176\u5b89\u5168\u6027\uff0c\u5e76\u5728Rust\u4e2d\u5b9e\u73b0\u3002\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u5728M1 Pro\u5904\u7406\u5668\u4e0a\u6807\u51c6\u6a21\u5f0f544 ms\u3001\u504f\u6267\u6a21\u5f0f2273 ms\u6027\u80fd\u3002\u9002\u7528\u4e8e\u9694\u79bb\u7cfb\u7edf\u53ca\u4e3b\u51ed\u8bc1\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u5bc6\u94a5\u5b58\u50a8\u901a\u5e38\u4f9d\u8d56\u4fdd\u9669\u5e93\u7cfb\u7edf\uff0c\u5b58\u5728\u653b\u51fb\u9762\u3002Qatsi\u63d0\u51fa\u65e0\u9700\u6301\u4e45\u5b58\u50a8\u7684\u5bc6\u94a5\u6d3e\u751f\u65b9\u6848\uff0c\u901a\u8fc7\u786e\u5b9a\u6027\u6d3e\u751f\u6d88\u9664\u4fdd\u9669\u5e93\u98ce\u9669\uff0c\u540c\u65f6\u786e\u4fdd\u5bc6\u94a5\u7684\u5f3a\u71b5\u548c\u53ef\u590d\u73b0\u6027\uff0c\u6ee1\u8db3\u9694\u79bb\u7cfb\u7edf\u53ca\u4e3b\u51ed\u8bc1\u751f\u6210\u573a\u666f\u7684\u9700\u6c42\u3002", "method": "1. \u4f7f\u7528Argon2id\u5185\u5b58\u5bc6\u96c6\u578b\u54c8\u5e0c\u51fd\u6570\u8fdb\u884c\u5206\u5c42\u5bc6\u94a5\u6d3e\u751f\uff1b2. \u901a\u8fc7\u5355\u4e00\u9ad8\u71b5\u4e3b\u5bc6\u94a5\u548c\u4e0a\u4e0b\u6587\u5206\u5c42\u786e\u5b9a\u6027\u5730\u751f\u6210\u6240\u6709\u5bc6\u94a5\uff1b3. \u91c7\u7528\u53ef\u8bc1\u660e\u5747\u5300\u7684\u62d2\u7edd\u91c7\u6837\u65b9\u6cd5\u6d3e\u751f\u62107776\u8bcd\u52a9\u8bb0\u8bcd\u621690\u5b57\u7b26\u5bc6\u7801\uff1b4. \u5185\u5b58\u6d88\u8017\u572864-128 MiB\u95f4\uff0c\u8fed\u4ee316-32\u6b21\u5177\u4f53\u53d6\u51b3\u4e8e\u6a21\u5f0f\u3002", "result": "1. \u65b9\u6848\u5728\u7406\u8bba\u4e0a\u8bc1\u660e\u8f93\u51fa\u5747\u5300\u6027\uff1b2. GPU\u653b\u51fb\u6210\u672c\u91cf\u5316\uff1a\u5355\u4e00GPU\u5728\u504f\u6267\u6a21\u5f0f(128 MiB\u5185\u5b58)\u4e0b\u653b\u51fb80-bit\u4e3b\u5bc6\u94a5\u9700$2.4\u00d710^{16}$\u5e74\uff1b3. Rust\u5b9e\u73b0\u63d0\u4f9b\u96f6\u5185\u5b58\u5316\u3001\u7f16\u8bd1\u65f6\u8bcd\u8868\u9a8c\u8bc1\u7b49\u5b89\u5168\u7279\u6027\uff1b4. Apple M1 Pro\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6807\u51c6\u6a21\u5f0f544ms\u3001\u504f\u6267\u6a21\u5f0f2273ms\u7684\u5206\u5c42\u6d3e\u751f\u5ef6\u8fdf\u3002", "conclusion": "Qatsi\u5b9e\u73b0\u4e86\u65e0\u72b6\u6001\u7684\u5bc6\u94a5\u53ef\u91cd\u73b0\u6027\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u8981\u6c42\u6781\u9ad8\u4f46\u63a5\u53d7\u6d3e\u751f\u5ef6\u8fdf\u7684\u9694\u79bb\u7cfb\u7edf\u4e0e\u4e3b\u51ed\u8bc1\u573a\u666f\u3002\u4f46\u7531\u4e8e\u7b97\u6cd5\u5ef6\u8fdf\uff0c\u5176\u4e0d\u9002\u7528\u9700\u7075\u6d3b\u8f6e\u6362\u5bc6\u94a5\u7684\u573a\u666f\u3002"}}
{"id": "2510.18674", "categories": ["cs.CR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.18674", "abs": "https://arxiv.org/abs/2510.18674", "authors": ["Alexander Nemecek", "Zebin Yun", "Zahra Rahmani", "Yaniv Harel", "Vipin Chaudhary", "Mahmood Sharif", "Erman Ayday"], "title": "Exploring Membership Inference Vulnerabilities in Clinical Large Language Models", "comment": "Accepted at the 1st IEEE Workshop on Healthcare and Medical Device\n  Security, Privacy, Resilience, and Trust (IEEE HMD-SPiRiT)", "summary": "As large language models (LLMs) become progressively more embedded in\nclinical decision-support, documentation, and patient-information systems,\nensuring their privacy and trustworthiness has emerged as an imperative\nchallenge for the healthcare sector. Fine-tuning LLMs on sensitive electronic\nhealth record (EHR) data improves domain alignment but also raises the risk of\nexposing patient information through model behaviors. In this work-in-progress,\nwe present an exploratory empirical study on membership inference\nvulnerabilities in clinical LLMs, focusing on whether adversaries can infer if\nspecific patient records were used during model training. Using a\nstate-of-the-art clinical question-answering model, Llemr, we evaluate both\ncanonical loss-based attacks and a domain-motivated paraphrasing-based\nperturbation strategy that more realistically reflects clinical adversarial\nconditions. Our preliminary findings reveal limited but measurable membership\nleakage, suggesting that current clinical LLMs provide partial resistance yet\nremain susceptible to subtle privacy risks that could undermine trust in\nclinical AI adoption. These results motivate continued development of\ncontext-aware, domain-specific privacy evaluations and defenses such as\ndifferential privacy fine-tuning and paraphrase-aware training, to strengthen\nthe security and trustworthiness of healthcare AI systems.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4e34\u5e8a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u533b\u7597\u4fdd\u5065\u9886\u57df\u5e94\u7528\u4e2d\u7684\u9690\u79c1\u98ce\u9669\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u91cd\u70b9\u63a2\u8ba8\u4e86\u6210\u5458\u63a8\u7406\u653b\u51fb\uff08membership inference\uff09\u7684\u53ef\u80fd\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u524d\u4e34\u5e8aLLMs\u867d\u6709\u4e00\u5b9a\u62b5\u6297\u6027\uff0c\u4f46\u4ecd\u5b58\u5728\u53ef\u6d4b\u91cf\u7684\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "motivation": "\u968f\u7740LLMs\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3001\u6587\u6863\u548c\u60a3\u8005\u4fe1\u606f\u7cfb\u7edf\u4e2d\u7684\u6df1\u5165\u5e94\u7528\uff0c\u786e\u4fdd\u5176\u9690\u79c1\u6027\u548c\u53ef\u4fe1\u5ea6\u6210\u4e3a\u533b\u7597\u4fdd\u5065\u9886\u57df\u7684\u91cd\u8981\u6311\u6218\u3002\u5fae\u8c03LLMs\u4e8e\u654f\u611f\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\u4e0a\u867d\u63d0\u5347\u4e86\u9886\u57df\u9002\u5e94\u6027\uff0c\u4f46\u53ef\u80fd\u5bfc\u81f4\u60a3\u8005\u4fe1\u606f\u901a\u8fc7\u6a21\u578b\u884c\u4e3a\u6cc4\u9732\u3002", "method": "\u4f7f\u7528\u6700\u65b0\u7684\u4e34\u5e8a\u95ee\u7b54\u6a21\u578bLlemr\uff0c\u8bc4\u4f30\u4e86\u4e24\u79cd\u653b\u51fb\u7b56\u7565\uff1a\u4f20\u7edf\u7684\u57fa\u4e8e\u635f\u5931\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u4ee5\u53ca\u4e00\u79cd\u66f4\u8d34\u5408\u4e34\u5e8a\u5b9e\u9645\u7684\u57fa\u4e8e\u6539\u8ff0\u7684\u6270\u52a8\u7b56\u7565\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u663e\u793a\u5b58\u5728\u6709\u9650\u4f46\u53ef\u6d4b\u91cf\u7684\u6210\u5458\u4fe1\u606f\u6cc4\u9732\uff0c\u8868\u660e\u5f53\u524d\u4e34\u5e8aLLMs\u5bf9\u9690\u79c1\u653b\u51fb\u5177\u6709\u4e00\u5b9a\u62b5\u6297\u6027\uff0c\u4f46\u4ecd\u6709\u8584\u5f31\u73af\u8282\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5f00\u53d1\u9762\u5411\u9886\u57df\u7684\u9690\u79c1\u8bc4\u4f30\u53ca\u9632\u5fa1\u63aa\u65bd\uff08\u5982\u5dee\u5206\u9690\u79c1\u5fae\u8c03\u548c\u6539\u8ff0\u611f\u77e5\u8bad\u7ec3\uff09\u7684\u5fc5\u8981\u6027\uff0c\u4ee5\u63d0\u9ad8\u533b\u7597AI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2510.18756", "categories": ["cs.CR", "cs.AR", "cs.DC", "cs.NI", "cs.OS"], "pdf": "https://arxiv.org/pdf/2510.18756", "abs": "https://arxiv.org/abs/2510.18756", "authors": ["Marcin Chrapek", "Meni Orenbach", "Ahmad Atamli", "Marcin Copik", "Fritz Alder", "Torsten Hoefler"], "title": "sNVMe-oF: Secure and Efficient Disaggregated Storage", "comment": null, "summary": "Disaggregated storage with NVMe-over-Fabrics (NVMe-oF) has emerged as the\nstandard solution in modern data centers, achieving superior performance,\nresource utilization, and power efficiency. Simultaneously, confidential\ncomputing (CC) is becoming the de facto security paradigm, enforcing stronger\nisolation and protection for sensitive workloads. However, securing\nstate-of-the-art storage with traditional CC methods struggles to scale and\ncompromises performance or security. To address these issues, we introduce\nsNVMe-oF, a storage management system extending the NVMe-oF protocol and\nadhering to the CC threat model by providing confidentiality, integrity, and\nfreshness guarantees. sNVMe-oF offers an appropriate control path and novel\nconcepts such as counter-leasing. sNVMe-oF also optimizes data path performance\nby leveraging NVMe metadata, introducing a new disaggregated Hazel Merkle Tree\n(HMT), and avoiding redundant IPSec protections. We achieve this without\nmodifying the NVMe-oF protocol. To prevent excessive resource usage while\ndelivering line rate, sNVMe-oF also uses accelerators of CC-capable smart NICs.\nWe prototype sNVMe-oF on an NVIDIA BlueField-3 and demonstrate how it can\nachieve as little as 2% performance degradation for synthetic patterns and AI\ntraining.", "AI": {"tldr": "sNVMe-oF\u662f\u4e00\u79cd\u57fa\u4e8eNVMe-oF\u534f\u8bae\u7684\u5b89\u5168\u5b58\u50a8\u7ba1\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f15\u5165\u63a7\u5236\u8def\u5f84\u3001\u8ba1\u6570\u5668\u79df\u8d41\u548c\u4f18\u5316\u6280\u672f\uff0c\u5728\u4e0d\u4fee\u6539\u534f\u8bae\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u548c\u65b0\u9c9c\u6027\u4fdd\u8bc1\uff0c\u540c\u65f6\u4ec5\u5e26\u67652%\u7684\u6027\u80fd\u635f\u5931\u3002", "motivation": "\u4f20\u7edf\u4fdd\u5bc6\u8ba1\u7b97\uff08CC\uff09\u65b9\u6cd5\u5728\u4fdd\u62a4\u9ad8\u6027\u80fd\u5b58\u50a8\u65f6\u96be\u4ee5\u6269\u5c55\uff0c\u8981\u4e48\u727a\u7272\u6027\u80fd\u8981\u4e48\u964d\u4f4e\u5b89\u5168\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6ee1\u8db3CC\u5a01\u80c1\u6a21\u578b\u8981\u6c42\uff0c\u53c8\u80fd\u7ef4\u6301\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "sNVMe-oF\u6269\u5c55\u4e86NVMe-oF\u534f\u8bae\uff0c\u63d0\u4f9b\u63a7\u5236\u8def\u5f84\u548c\u8ba1\u6570\u5668\u79df\u8d41\u673a\u5236\u3002\u5b83\u4f18\u5316\u4e86\u6570\u636e\u8def\u5f84\u6027\u80fd\uff1a\u5229\u7528NVMe\u5143\u6570\u636e\u3001\u8bbe\u8ba1\u65b0\u578b\u5206\u5e03\u5f0fHazel Merkle\u6811\uff08HMT\uff09\uff0c\u5e76\u907f\u514d\u5197\u4f59IPSec\u4fdd\u62a4\u3002\u8fd8\u5229\u7528\u652f\u6301CC\u7684\u667a\u80fd\u7f51\u5361\u52a0\u901f\u5668\uff0c\u5728NVIDIA BlueField-3\u5e73\u53f0\u4e0a\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u5408\u6210\u8d1f\u8f7d\u548cAI\u8bad\u7ec3\u573a\u666f\u4e0b\uff0csNVMe-oF\u7684\u6027\u80fd\u635f\u5931\u6700\u4f4e\u4ec52%\uff0c\u540c\u65f6\u4fdd\u969c\u4e86\u5b58\u50a8\u673a\u5bc6\u6027\u3001\u5b8c\u6574\u6027\u548c\u65b0\u9c9c\u6027\u3002", "conclusion": "sNVMe-oF\u901a\u8fc7\u534f\u8bae\u5c42\u4f18\u5316\u548c\u786c\u4ef6\u52a0\u901f\u5668\u7684\u9ad8\u6548\u534f\u540c\uff0c\u89e3\u51b3\u4e86\u53ef\u6269\u5c55\u7684\u5b89\u5168\u5b58\u50a8\u95ee\u9898\uff0c\u662f\u9ad8\u6027\u80fd\u673a\u5bc6\u8ba1\u7b97\u5b58\u50a8\u7684\u53ef\u884c\u65b9\u6848\u3002"}}
