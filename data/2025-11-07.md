<div id=toc></div>

# Table of Contents

- [cs.CR](#cs.CR) [Total: 7]


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [1] [Security Analysis of Agentic AI Communication Protocols: A Comparative Evaluation](https://arxiv.org/abs/2511.03841)
*Yedidel Louck,Ariel Stulman,Amit Dvir*

Main category: cs.CR

TL;DR: 该研究首次对CORAL和ACP两种多智能体系统通信协议进行了安全分析，发现CORAL在架构设计上更安全，但存在严重的实现漏洞；ACP则因可选的安全措施导致完整性和保密性问题。建议将两者的优势结合以提升安全性。


<details>
  <summary>Details</summary>
Motivation: 目前人工智能驱动的多智能体系统被广泛应用于复杂任务中，但其底层通信协议的安全性未得到充分研究。有必要对现有主流通信协议实现进行安全评估，以发现潜在风险并指导改进方向。

Method: 通过建立14项漏洞分类标准，采用实证对比方法评估CORAL官方实现与基于SDK的ACP实现，以文献评估为基准。聚焦认证、授权、完整性、保密性和可用性五个安全维度。

Result: CORAL架构设计坚固（如传输层验证和会话隔离），但网关存在认证/授权实现缺陷；ACP的灵活设计导致关键完整性风险（如可选JWS机制）。两者在现有趋势下均显不足。

Conclusion: 提出混合解决方案：结合CORAL的架构与ACP的强制消息完整性保护，构建下一代安全智能体通信系统。研究结果揭示当前行业标准存在明显安全缺口。

Abstract: Multi-agent systems (MAS) powered by artificial intelligence (AI) are
increasingly foundational to complex, distributed workflows. Yet, the security
of their underlying communication protocols remains critically under-examined.
This paper presents the first empirical, comparative security analysis of the
official CORAL implementation and a high-fidelity, SDK-based ACP
implementation, benchmarked against a literature-based evaluation of A2A. Using
a 14 point vulnerability taxonomy, we systematically assess their defenses
across authentication, authorization, integrity, confidentiality, and
availability. Our results reveal a pronounced security dichotomy: CORAL
exhibits a robust architectural design, particularly in its transport-layer
message validation and session isolation, but suffers from critical
implementation-level vulnerabilities, including authentication and
authorization failures at its SSE gateway. Conversely, ACP's architectural
flexibility, most notably its optional JWS enforcement, translates into
high-impact integrity and confidentiality flaws. We contextualize these
findings within current industry trends, highlighting that existing protocols
remain insufficiently secure. As a path forward, we recommend a hybrid approach
that combines CORAL's integrated architecture with ACP's mandatory per-message
integrity guarantees, laying the groundwork for resilient, next-generation
agent communications.

</details>


### [2] [Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback](https://arxiv.org/abs/2511.03995)
*Shiyin Lin*

Main category: cs.CR

TL;DR: 提出混合模糊测试框架，整合静态与动态分析及大语言模型（LLM）引导的输入变异和语义反馈，提升深度程序状态探索效率。


<details>
  <summary>Details</summary>
Motivation: 现有模糊测试变异策略缺乏语义感知，导致测试用例冗余且难以深入探索程序状态。

Method: 1. 静态分析提取控制流/数据流信息转化为LLM提示，生成语法有效、语义多样的输入；2. 执行时混合覆盖反馈与语义反馈（程序状态变化/异常类型/输出语义）；3. 在AFL++基础上结合程序插桩和嵌入相似性指标指导种子选择。

Result: 在libpng/tcpdump/sqlite等现实目标测试中：实现更快的首次缺陷发现时间、更高的语义多样性，并与先进模糊测试工具相比具有竞争力的独特缺陷数量。

Conclusion: 证实结合LLM推理与语义反馈可加速漏洞挖掘深度和效率，展现重要应用潜力。

Abstract: Software fuzzing has become a cornerstone in automated vulnerability
discovery, yet existing mutation strategies often lack semantic awareness,
leading to redundant test cases and slow exploration of deep program states. In
this work, I present a hybrid fuzzing framework that integrates static and
dynamic analysis with Large Language Model (LLM)-guided input mutation and
semantic feedback. Static analysis extracts control-flow and data-flow
information, which is transformed into structured prompts for the LLM to
generate syntactically valid and semantically diverse inputs. During execution,
I augment traditional coverage-based feedback with semantic feedback
signals-derived from program state changes, exception types, and output
semantics-allowing the fuzzer to prioritize inputs that trigger novel program
behaviors beyond mere code coverage. I implement our approach atop AFL++,
combining program instrumentation with embedding-based semantic similarity
metrics to guide seed selection. Evaluation on real-world open-source targets,
including libpng, tcpdump, and sqlite, demonstrates that our method achieves
faster time-to-first-bug, higher semantic diversity, and a competitive number
of unique bugs compared to state-of-the-art fuzzers. This work highlights the
potential of combining LLM reasoning with semantic-aware feedback to accelerate
and deepen vulnerability discovery.

</details>


### [3] [Black-Box Guardrail Reverse-engineering Attack](https://arxiv.org/abs/2511.04215)
*Hongwei Yao,Yun Xia,Shuo Shao,Haoran Shi,Tong Qiao,Cong Wang*

Main category: cs.CR

TL;DR: 本文提出了一种名为GRA（护栏逆向工程攻击）的黑盒攻击框架，通过强化学习和遗传算法驱动的数据增强技术，逆向工程大型语言模型的防护机制。该方法在多个商业系统上验证，以低成本高效率提取防护规则，暴露出当前安全机制的重大漏洞。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）广泛采用护栏机制限制输出内容，但该机制暴露了可观测的决策模式，可能被恶意利用逆向工程破解。

Method: 1. 基于强化学习的框架，结合遗传算法进行数据增强。2. 收集输入输出对，对分歧案例优先处理。3. 通过定向突变和交叉操作，生成高精度的替代护栏模型。

Result: 1. 在ChatGPT、DeepSeek和Qwen3三个商业系统上验证。2. 规则匹配率超过0.92。3. API调用成本低于85美元。

Conclusion: 当前LLM的安全机制存在可被低成本破解的严重漏洞，亟需设计更鲁棒的防御方案。

Abstract: Large language models (LLMs) increasingly employ guardrails to enforce
ethical, legal, and application-specific constraints on their outputs. While
effective at mitigating harmful responses, these guardrails introduce a new
class of vulnerabilities by exposing observable decision patterns. In this
work, we present the first study of black-box LLM guardrail reverse-engineering
attacks. We propose Guardrail Reverse-engineering Attack (GRA), a reinforcement
learning-based framework that leverages genetic algorithm-driven data
augmentation to approximate the decision-making policy of victim guardrails. By
iteratively collecting input-output pairs, prioritizing divergence cases, and
applying targeted mutations and crossovers, our method incrementally converges
toward a high-fidelity surrogate of the victim guardrail. We evaluate GRA on
three widely deployed commercial systems, namely ChatGPT, DeepSeek, and Qwen3,
and demonstrate that it achieves an rule matching rate exceeding 0.92 while
requiring less than $85 in API costs. These findings underscore the practical
feasibility of guardrail extraction and highlight significant security risks
for current LLM safety mechanisms. Our findings expose critical vulnerabilities
in current guardrail designs and highlight the urgent need for more robust
defense mechanisms in LLM deployment.

</details>


### [4] [A Parallel Region-Adaptive Differential Privacy Framework for Image Pixelization](https://arxiv.org/abs/2511.04261)
*Ming Liu*

Main category: cs.CR

TL;DR: 该论文提出了一种新型并行、区域自适应像素化框架，结合差分隐私理论严谨性和实际效率，解决了视频应用中隐私保护与任务保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 高分辨率视觉感知系统的广泛部署和基础模型的兴起加剧了视频应用中的隐私风险。现有差分隐私像素化方法虽提供数学保障，但在保持任务相关保真度、可扩展性和实时部署方面存在挑战。

Method: 设计一种并行区域自适应像素化框架，根据区域复杂度动态调整网格大小和噪声尺度；利用GPU并行性加速处理；通过仅存储必要噪声统计数据的轻量存储方案降低空间开销。在拉普拉斯机制和平行组合定理下提供形式化隐私分析。

Result: 在PETS、Venice-2和PPM-100数据集上实验显示，该方法在隐私-效用权衡方面表现优异，显著减少运行时间和存储开销。在CelebA上进行的人脸重识别攻击实验证实其能有效防止身份推断。

Conclusion: 该方法适合用于实时隐私关键应用场景，如老年护理、智能家居监控、驾驶员行为分析和人群行为监测。

Abstract: The widespread deployment of high-resolution visual sensing systems, coupled
with the rise of foundation models, has amplified privacy risks in video-based
applications. Differentially private pixelization offers mathematically
guaranteed protection for visual data through grid-based noise addition, but
challenges remain in preserving task-relevant fidelity, achieving scalability,
and enabling efficient real-time deployment. To address this, we propose a
novel parallel, region-adaptive pixelization framework that combines the
theoretical rigor of differential privacy with practical efficiency. Our method
adaptively adjusts grid sizes and noise scales based on regional complexity,
leveraging GPU parallelism to achieve significant runtime acceleration compared
to the classical baseline. A lightweight storage scheme is introduced by
retaining only essential noisy statistics, significantly reducing space
overhead. Formal privacy analysis is provided under the Laplace mechanism and
parallel composition theorem. Extensive experiments on the PETS, Venice-2, and
PPM-100 datasets demonstrate favorable privacy-utility trade-offs and
significant runtime/storage reductions. A face re-identification attack
experiment on CelebA further confirms the method's effectiveness in preventing
identity inference. This validates its suitability for real-time
privacy-critical applications such as elderly care, smart home monitoring,
driver behavior analysis, and crowd behavior monitoring.

</details>


### [5] [Data Certification Strategies for Blockchain-based Traceability Systems](https://arxiv.org/abs/2511.04409)
*Giacomo Zonneveld,Giulia Rafaiani,Massimo Battaglioni,Marco Baldi*

Main category: cs.CR

TL;DR: 本文探讨了在区块链上持续认证大量数据时面临的挑战，提出并对比了多种策略，以实现在保持去中心化验证可能性的同时对生产过程数据进行认证。


<details>
  <summary>Details</summary>
Motivation: 虽然区块链在数据认证和追溯中应用成熟，但持续产生的大量数据直接上链存在效率问题。需要先离线缓冲并组织数据（如使用Merkle树）以减少上链数据量。

Method: 针对基于区块链的生产过程追溯系统，提出多种数据认证策略（可能包括优化的数据结构或批处理机制），并进行了对比分析。

Result: 虽然具体结果未明说，但通过比较不同策略，应能得出在认证数据量、验证效率和去中心化程度等方面的权衡结论。

Conclusion: 针对持续产生的大规模数据，合理的缓冲和组织策略能有效平衡区块链认证的可行性与效率，同时保持去中心化验证能力。

Abstract: The use of blockchains for data certification and traceability is now well
established in both the literature and practical applications. However, while
blockchain-based certification of individual data is clear and straightforward,
the use of blockchain to certify large amounts of data produced on a nearly
continuous basis still poses some challenges. In such a case, in fact, it is
first necessary to collect the data in an off-chain buffer, and then to
organize it, e.g., via Merkle trees, in order to keep the size and quantity of
certification data to be written to the blockchain small. In this paper, we
consider a typical system for blockchain-based traceability of a production
process, and propose and comparatively analyze some strategies for certifying
the data of such a process on blockchain, while maintaining the possibility of
verifying their certification in a decentralized way.

</details>


### [6] [Adversarially Robust and Interpretable Magecart Malware Detection](https://arxiv.org/abs/2511.04440)
*Pedro Pereira,José Gouveia,João Vitorino,Eva Maia,Isabel Praça*

Main category: cs.CR

TL;DR: 本研究提出使用多种机器学习模型（树状、线性、核方法）结合图灵机（DFA）检测Magecart供应链攻击，通过对抗训练抵御攻击，提供模型解释性。实验证明模型在真实环境中高效且可解释。


<details>
  <summary>Details</summary>
Motivation: Magecart攻击威胁在线支付安全，需鲁棒性强且可解释的检测机制。

Method: 使用树状模型、线性模型和核方法模型，配合特征选择和超参数调优。结合行为图灵机分析脚本行为模式，并通过对抗训练增强模型可靠性。

Result: 模型展示高检测性能（高查杀率）和强鲁棒性（抵御对抗性攻击），并提供直观的解释支持信任。

Conclusion: 传统机器学习模型在真实网页安全环境中高效可靠，结合行为DFA和对抗训练可形成可解释的安全防御方案。

Abstract: Magecart skimming attacks have emerged as a significant threat to client-side
security and user trust in online payment systems. This paper addresses the
challenge of achieving robust and explainable detection of Magecart attacks
through a comparative study of various Machine Learning (ML) models with a
real-world dataset. Tree-based, linear, and kernel-based models were applied,
further enhanced through hyperparameter tuning and feature selection, to
distinguish between benign and malicious scripts. Such models are supported by
a Behavior Deterministic Finite Automaton (DFA) which captures structural
behavior patterns in scripts, helping to analyze and classify client-side
script execution logs. To ensure robustness against adversarial evasion
attacks, the ML models were adversarially trained and evaluated using attacks
from the Adversarial Robustness Toolbox and the Adaptative Perturbation Pattern
Method. In addition, concise explanations of ML model decisions are provided,
supporting transparency and user trust. Experimental validation demonstrated
high detection performance and interpretable reasoning, demonstrating that
traditional ML models can be effective in real-world web security contexts.

</details>


### [7] [Confidential Computing for Cloud Security: Exploring Hardware based Encryption Using Trusted Execution Environments](https://arxiv.org/abs/2511.04550)
*Dhruv Deepak Agarwal,Aswani Kumar Cherukuri*

Main category: cs.CR

TL;DR: 本文摘要探讨了云计算环境中数据安全挑战，并介绍了机密计算（Confidential Computing）通过可信执行环境（TEEs）解决数据使用中保护的问题。研究分析了Intel SGX和ARM TrustZone等TEE架构的安全特性、效能，以及实际应用中的挑战和潜力。


<details>
  <summary>Details</summary>
Motivation: 云计算发展带来了数据处理和存储能力的提升，但数据安全问题日益突出，尤其在数据使用过程中的保护成为关键挑战。传统安全实践（静态和传输加密）无法保护使用中的数据，导致暴露风险。因此，需要研究TEE技术在保障云数据安全中的作用。

Method: 研究采用文献综述方法，系统分析了Intel SGX和ARM TrustZone等可信执行环境（TEEs）的架构、安全特性、部署策略、性能指标及实际应用案例。同时讨论了TEE技术的实施挑战、潜在漏洞、可扩展性问题与集成难题。

Result: 研究表明TEE技术能有效提升云数据安全性，即使在操作系统或软件层遭恶意入侵时仍能保障数据的机密性和完整性。但同时也面临部署复杂性、性能开销、可拓展性限制等现实问题。

Conclusion: 可信执行环境（TEEs）在构建机密计算基础中扮演核心角色，是强化云安全体系的关键技术。未来需优化其缺陷以推动更广泛采用。

Abstract: The growth of cloud computing has revolutionized data processing and storage
capacities to another levels of scalability and flexibility. But in the
process, it has created a huge challenge of security, especially in terms of
safeguarding sensitive data. Classical security practices, including encryption
at rest and during transit, fail to protect data in use and expose it to
various possible breaches. In response to this problem , Confidential Computing
has been a tool ,seeking to secure data in processing by usage of
hardware-based Trusted Execution Environments (TEEs). TEEs, including Intel's
Software Guard Extensions (SGX) and ARM's TrustZone, offers protected contexts
within the processor, where data is kept confidential ,intact and secure , even
with malicious software or compromised operating systems. In this research, we
have explored the architecture and security features of TEEs like Intel SGX and
ARM TrustZone, and their effectiveness in improving cloud data security. From a
thorough literature survey ,we have analyzed the deployment strategies,
performance indicators, and practical uses of these TEEs for the same purpose.
In addition, we have discussed the issues regarding deployment, possible
weaknesses, scalability issues, and integration issues. Our results focuses on
the central position of TEEs in strengthening and advancing cloud security
infrastructures, pointing towards their ability to create a secure foundation
for Confidential Computing.

</details>
